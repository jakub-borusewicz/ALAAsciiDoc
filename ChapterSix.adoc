:imagesdir: images

== Chapter six - ALA compared with:

In this chapter, our perspective is to compare ALA with existing programming paradigms, principles, styles, and patterns in common usage.

The idea is to understand ALA in terms of similarities and differences with something you may already understand.

Each existing programming paradigm, principle, style, or pattern generally takes a long time for the average developer to get used to and master. It then generally only makes an incremental improvement to software quality, if any. ALA is a reference architecture that combines the best elements of these existing programming paradigms, principles, styles, and patterns into one coherent idea that makes a big difference. 

Some existing programming paradigms, principles, styles, or patterns are bad. The most prominent examples are the UML class diagram, the idea of 'decomposition' of a system (which includes all patterns like MVC), the idea that indirection is necessarily hard to trace, the idea of loose coupling, the idea of dependency management without distinguishing between good and bad dependencies, and the idea of layering patterns (sometimes called stacks) where the layers are driven by communication dependencies.

In this chapter we look at each of these good and bad patterns or styles in detail.


=== What are monads?

In chapter 3, we did a brief comparison of ALA and monads in which we assumed prior familiarity with monads. In this section we assume no familiarity with monads. So we start by explaining what monads are.

This section is necessarily long. Monads are notoriously one of the most difficult concept to understand in all of software engineering. But we will do it with tiny steps and a few examples built on real code. 

****
Often abstract concepts in programming are explained in terms of how they are syntactical sugar for a longer form of conventional imperative code. For example, lambda expressions can be explained as syntactical sugar for passing in a named function. This is hard to do for monads because there is code generated under the hood. So most explanations of monads do not attempt to explain them in terms of equivalent imperative code. They go for either an abstract mathematical explanation or some kind of abstract concept such as 'amplified' types or 'boxed' types instead. I personally don't find these types of explanations all that helpful. They only make sense once you already understand monads. Many developers are not so much mathematicians, but understand imperative, object oriented code just fine. My explanation is based on showing how monads are a refactoring pattern of ordinary imperative code.
****

We'll do four examples of imperative code along with the refactored code that we call monads. Only by doing multiple examples will we get the underlying pattern of what monads are.

We will start by doing the refactoring from conventional code to monads in several small steps. At each step we will point out the advantages over the imperative code.

So let's get started.

Often in imperative programming we find ourselves calling several functions in succession. What we are really doing is 'composing' functions. We would like to do this composing declaratively. By declaratively we mean that we would like to choose what functions and in what order, but not be concerned with any other details beyond that. It would allow us to think of the code as data flowing sequentially from operation to operation instead of imperative execution of statements. 

In imperative style, top layer code that calls functions needs to handle data for the functions. For example, data returned by one function is often passed to the next. This often involves creating local variables to hold data temporarily. When we _compose_ functions we want the output of one to be piped to the input of the next automatically without us having to do it explicitly. Looked at it in a different way, the functions' interfaces for input/output (the parameter and the return value) are exposed to the top layer when they don't need to be. We would rather think of this input and output as separate interfaces or ports. When the top layer composes two functions, these ports are connected so that data is passed directly from one function to the next.

We can of curse achieve that using code like this:

[source,C#]
....
int result = function3(function2(function1(42)));
....

(In our sample code, we will use the number 42 as the input into the first function. That way we will be able to see where the source value being fed into the chain of functions is.)


////
. Most programs use state. Using state is often the best way to express a computation. This is especially true when events coming into the system are asynchronous, for example coming from the outside world. The system essentially must be a state machine.
+
In pure functional programming, this state ends up essentially in the top layer. It is passed into the pure functions. Returned values are stored back in the state variable. The state structure itself may be immutable, so that if another thread has a reference to it, it does not see changing data. But the stateful reference to the structure must be stored in place while the system waits for the next external event. 
+
Passing this state data into functions is also a responsibility that the top layer should not have. The top layer's job should just be to compose functions.
+
Often there is some state that closely associates with a single function, or a small set of functions. Instead, good abstractions should be self-contained, including any state that really belongs only to it. That's what objects are in the object oriented world.   
+
Functions that would otherwise be good abstractions if they were self-contained with their state get broken by exposing their private parts. 

The problem of their mutable state should then be handled by treating each instance (or a local group of instances) as a unit running on a single thread. These groups can then _only_ communicate with one another asynchronously.tt
////

////
. Many times in imperative programming when using functions, the return value cannot be fed _directly_ into the next function. Some code is needed between function calls. For example, if the function could have an error, then _if_ or _try_ statements would be needed after every function call to check for the error. The if statements change the execution flow to skip the rest of the functions. These if statements create a lot of awkward nesting and indenting if we want to compose long chains of functions.
+
This type of common code should also not be the responsibility of the top layer. The top layer should just be about composing a chain of functions. This type of common code, which can take many forms, should be refactored out.

Monads allow the top layer to just _compose_ the functions. The monad takes care of passing data from function to function, and doing any common code that needs doing after each function call.
////
////
To accomplish all this, monads (usually) use objects under the covers. These objects can be delegates (object/function references), closures (objects of compiler generated classes that capture local scope variables), or specific under the hood classes. These objects are wired together to build a structure that can be executed in much the same way as ALA wires together domain abstraction objects to build a program that can be executed.
////


Composing functions in this way is not scalable because of the increasing levels of nested brackets every time we want to add a new function to the chain.

To get a scalable version, we would write it like this instead:

[source,C#]
....
int r1 = function1(42);
int r2 = function2(r1);
int result = function3(r2);
....

This form has the aforementioned disadvantage of handling the data that passes from function to function. Furthermore, those temporary local variables make the entire scope more complicated because anywhere in the scope can potentially use any variable. The variable can be immutable, but that doesn't help much. Nevertheless, this is representative of the basic style that a lot of imperative code follows.

Let's try to get to a style where we don't need to handle that data ourselves, and we don't have nested brackets. Let's try using a function called 'Compose' to compose the functions:

[source,C#]
....
int Compose(int x, Func<int,int> f)
{
    return (f(x));
}    
....

So now we can compose the functions like this:

[source,C#]
....
int result = Compose(Compose(Compose(42, function1), function2), function3);
....

Well there doesn't seem like there is any advantage to that. We got our nested brackets back, plus it looks even more complicated than our original bracketed code. But let's persevere just a little longer with the idea of using a 'Compose' function, because it's about to become really powerful.

First let's make the Compose function an extension method by adding a _this_ keyword:

[source,C#]
....
static class ExtensionMethods
{
    public static int Compose(this int x, Func<int,int> f)
    {
        return f(x);
    }
}
....


Now we can compose the three functions this way:

[source,C#]
....
int result = 42
    .Compose(function1)
    .Compose(function2)
    .Compose(function3);
....

This syntax is called fluent syntax. Fluent syntax is our first advantage of using a Compose function. We just solved the nested brackets problem, so the chain of functions is now scalable - we can easily add more functions to the chain. And, notice how the code using Compose is pure functional code. That's because we got rid of all those local variables. The Compose function is starting to look useful.

The code is now a declarative dataflow programming paradigm instead of an imperative programming paradigm. We are just specifying what functions we want to compose in what order instead of imperatively calling them ourselves, and passing the data between them ourselves. It describes a flow of data rather than a flow of execution. You make think you know how this executes, but be careful, because you don't know how Compose does the execution. And you will soon see that it can handle the execution in a variety of ways. 

This is our second advantage of using a Compose function - it's a pure dataflow programming paradigm where we are not concerned with how it executes.

The Compose function takes a function pointer (delegate in C#) as its parameter. If the functions being composed are specific to the application, i.e only ever used once, we can make them anonymous and put the function's code directly into the Compose call:

[source,C#]
....
int result = 42
    .Compose(delegate(int x){return x+1;)
    .Compose(delegate(int x){return x*10+1;})
    .Compose(delegate(int x){return 1/x;});
....

Doing it with delegates like that is somewhat verbose, so the next step is to change the syntax to lambda expressions.

[source,C#]
....
int result = 42
    .Compose(x => x+1)
    .Compose(x => x*10+1)
    .Compose(x => 1/x);
....

So that's our third advantage of using a Compose function. We can use lambda expressions right in the parameter of the Compose function instead of creating separate named functions.

****
Generally, 'named' functions are good only if the function is a good abstraction. But if a function is specific to a user story (only used once), it is not an abstraction. The name itself becomes just a symbolic connection between two points in the code. Symbolic connections are bad. It's indirection without abstraction. We would have to use an editor to search for the other point to find what the function does. Lambda expressions solve this problem because they are anonymous.
****
////
You can see that although this last form is just a refactoring of the original imperative code, it now looks even more like a dataflow programming paradigm. By dataflow programming, we mean that we are thinking of it in terms of a flow of data rather than a flow of execution. Indeed the flow of the data and the flow of the execution can now be different.
////

==== Deferred execution

In the example so far, we assumed, based on the imperative code, that the Compose function directly and immediately calls the functions. When we compose the functions as a dataflow in the top layer, we assume that under the covers in the Compose function, the execution flow will be the same as the dataflow.

However, it is quite possible for the execution flow implemented in the compose function to work entirely differently from the dataflow. We can, for example, implement deferred execution, where the Compose function builds an executable structure which can be run later. This separation of how it executes from the declarative composition of the functions as a dataflow is our forth advantage of using a Compose function. It allows us to build Compose functions that use deferred execution.

The Compose function we had in the previous section evaluated the functions immediately and returned a result directly. Let's write a deferred (or lazy) version of _Compose_. Instead of returning the actual result, this version will return a new function that represents the composed functions. This returned function can then be called later. Here is a deferred version of the Compose function:


[source,C#]
....
static class ExtensionMethods
{
    static Func<int> Compose(this Func<int> source, Func<int,int> f)
    {
        return () => f(source());
    }
}
....

It's the same as our previous Compose function except for the type of the first parameter and the return type. In the immediate execution version, the type of the first parameter to compose was an int, which comes from the execution of the previous function in the chain. And the return value was also an int. Now these two things are functions because we are not evaluating the functions as we go, we are composing the functions to return a new single function.

The _() =>_ syntax is a lambda expression for a function that takes no parameters. It creates a new function that calls the source function and then calls _f_. 

What the Compose function returns is actually an object structure made up of delegates and closure objects created by the compiler:

image::ComposeClosure.drawio.png[ComposeClosure.drawio.png, title="Object diagram of the structure returned by the deferred version of the Compose function",link=images/ComposeClosure.drawio.png]

The purple boxes are C# delegates. Delegates can be thought of as a pointer to a method. Because the method is in an object, a delegate is actually a pointer to an object together with a reference to the method in that object's class. Delegates themselves are objects. The delegate object has a pointer to another object (called Target) plus a reference to a method in that object (called MethodInfo).  

////
Note that in the imperative world we would say we are really passing in two pointers to functions, and returning a pointer to a function, but in the functional world this is said to be just composing functions. 
////
The yellow box is a closure object. A closure is an object made from a compiler generated class with a single method. It can have fields which are references to variables in the local scope. In this case, the closure object has two fields, which are both delegates. The closure's method calls the first delegate, and then calls the second delegate, passing the result returned by the first to the second. The structure is returned as a delegate that points to the method in the closure object.

The structure looks surprizingly complicated consisdering the code that generated it was just '() => f(source());' That doesn't matter because its all generated by the compilier. I wanted to show it so we can see all the code for this deferred version of the compose function.

Now that we have a deferred version of our Compose function, we can use it like this:

[source,C#]
....
Func<int> composedFunction = 42.ToFunc<int>
    .Compose(x => x+1)
    .Compose(x => 1000/x)
    .Compose(x => x*10+1);
....

That's just the same as our previous top layer code, except that we show how we can get a function back which we can save to be executed later. It's like we got a small program back.

When we want to execute the combined function, we can do it like this.

[source,C#]
....
int result = composedFunction();
....

We will usually prefer to build deferred versions of Compose functions, just because that gives us the versatility to execute them now or later, or even to execute them many times. In other words, Compose can build a program. 

Note that the deferred version of Compose takes a function as its first parameter, not a number like 42. So we couldn't pass 42 to it to start the chain. Instead we used another extension method called ToFunc to get a function that returns 42. 

Deferred function composition generally returns a surprisingly large object structure containing delegate objects and closure objects all generated by the compiler. This is one reason why monads are so hard to understand. Here is what the object structure for the composedFunction above looks like:

image::ThreeComposedFunctionsClosureDiagram.drawio.png[ThreeComposedFunctionsClosureDiagram.drawio.png, title=Object diagram of expression composing three functions using deferred Compose function,link=images/ThreeComposedFunctionsClosureDiagram.drawio.png]

You can click on the diagram to see it enlarged. On the left side of the diagram you can see the four closure objects that implement the 42 and the three lambda expressions. Each of these closure objects has a delegate object that is used to reference it. Then there are three other closure objects that were created by the Compose function. These closures call the other closures via their delegates in the correct order. The entire structure is returned as a single delegate on the right hand side.

There is a fifth advantage to using a Compose function. This advantage is big, and is what allows us to finally call it a monad. 


==== Composing functions that need logic between them

In imperative code we might typically need some extra code after every function call. A common example would be to check for errors returned by one function before calling the next function. If we have a compose function, we can put that extra code inside the Compose function instead. This refactoring is essentially what the monad pattern is.

We'll give four examples of imperative code that needs some extra common logic after every function call. In each case, the functions we are composing are not returning a simple value that can be fed directly to the next function. They are returning something else, so in every case we need a little bit of extra logic to handle what the function returns before calling the next function.

It's what this extra logic code does that distinguishes one monad from another.


==== Example 1

Composition of functions that can fail.

In this first example, we may need to allow for the fact that functions can throw an exception, or return null, or a Maybe object or even -1. For example, the function may be vulnerable to a divide by zero. In imperative code, we would commonly have to add if statements or try statements so that we don't call the rest of the functions in the chain when something goes wrong. That will likely create nesting, arrrgh.

In C code, returning -1 is often used for this purpose, so let's use that for our first example just because it's so simple. Here is the imperative code:

[source,C#]
....
// procedural composition of functions that can return -1 or null

int result1 = function1(42);
if (result1 != -1)
{
    int result2 = function2(result1)
    if (result2 != -1)
    {
        int result3 = function3(result2);
        if (result3 != -1)
        {
            DoSomething(result3);
        }
    }
}
// fall through means something returned -1
....

Note that, even though we are using intermediate variables, we got our nasty nesting back. Let's see how we do that the monad way by refactoring the _if_ statements into the Compose function:

===== The MinusOne monad

We simply factor out the if statements into the Compose function. When we create actual monads, we will name the composing function "Bind" instead of "Compose":


Application layer code
[source,C#]
....
int result = 42
    .Bind(x => x+1)
    .Bind(x => x==0 ? -1 : 1000/x)
    .Bind(x = x*10+1);
....

Note that this looks almost identical to the way we composed these functions previously. That's because our aim in the top layer is to just compose the functions, and nothing else.

One difference is that we have renamed Compose to Bind. That's because Bind is the common name used for the Compose function in the monad world.

The only other difference is that the lambda expressions are now allowed to return -1 to indicate failure and the whole thing still works. We have done this in the second lambda expression. If any of the composed lambda expressions returns -1, then the rest of the lambda expressions are skipped, and the final result is minus one.

Now let's see how that refactoring was done. Here is the Bind function:

Monad layer code
[source,C#]
....
static class ExtensionMethods
{

    public static int Bind(this int source, Func<int, int> function)
    {
        return source == -1 ? -1 : function(source);
    }
}
....

You can see that if any function in the chain returns -1, the rest of the functions are skipped and the final result is -1.

That's a pretty straightforward refactoring, and with it we have our first example of a monad. 

Note that this Bind function does immediate execution. We will do the deferred version soon.

(Most of the code snippets in this section are demonstrated by small executable projects on Github here: https://github.com/johnspray74[https://github.com/johnspray74]. The project names are MaybeMonad, IEnumerableMonad, and ContinuationMonad.)

To really 'get' monads, all we need is more examples of this type of refactoring.



==== Example 2

Composition of functions that return many values.

We may have functions that return many values, such as an array, a list, an IEnumerable or an IObservable. We then want to feed all the individual values into the next function, which will in turn return multiple values, and then recombine all the values nto a single array or list. In imperative code, we do this with nested _for_ statements. For example, the function may be given customers one at a time and returns a list of their orders, which we want to join back into a single list of orders.


[source,C#]
....
// imparative composition of functions that return a list

var results1 = function1(42);
List<int> combinedList1 = new List<int>;
foreach(result1 in results1)
{
    var results2 = function2(result1)
    List<int> combinedList2 = new List<int>;
    foreach (result2 in results2)
    {
        var results3 = function3(result2)
        combinedList2.Append(results3);
    }
    combinedList1.Append(combinedList2);
}
List<int> result = combinedList1;
....

Again note the nested levels of brackets and indenting for every foreach. 

===== The List monad

We simply factor out the code for the foreachs into a new Bind function:


Application layer code
[source,C#]
....
var result = List<int> result = new List<int>(){ 0 }
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....

The functions each return a list. So as we Bind each new function, the number of items in the list multiplies up. Here is the same application using lambda expressions instead of named functions:

[source,C#]
....
var result = new List<int> { 0 }  
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 });
....

Because we compose three functions, and each returns a list of three items, the result list at the end will contain 27 items. The output is:

image::ConsoleOutputListMonad.png[ConsoleOutputListMonad.png, title="Output of three Bind functions in a row", link=images/ConsoleOutputListMonad.png]


Here is the Bind function for the List monad:

[source,C#]
....
static class ExtensionMethods
{
    public static List<U> Bind<T, U>(this List<T> source, Func<T, List<U>> function)
    {
        List<U> output = new List<U>();
        foreach (T t in source)
        {
            var List<U> functionOutput = function(t);
            output.AddRange(functionOutput);
        }
        return output;
    }
}}
....


For this monad, Bind will receive a list as its input. It will feed all the values one by one to the function. Each call of the function will return a list. Bind appends all the lists together and returns the combined list. 

Let's say the List<T> input were a list of students. Bind uses a for loop to get all the students one at a time. It passes each student to the function. Each call of the function returns a List<U>. Let's say this is a list of courses for the student. The bind function then joins all the separate course lists together to make a single list of courses of type List<U>, which it returns.

****
Often when dealing with lists, we do a one-to-one operation on the values in a list. The composing function is called Select or Map. It takes a list and produces a new list with the same number of elements. 

Or, we do a many-to-one operation which aggregates the values in a list down to a single value. An example is a Sum operation.

Methods to do one-to-one and many-to-one operations are usually supplied in a library along with the actual monad.

The list monad itself just includes the one-to-many operation. Each value in the input becomes a list. So we then have a list of lists, which is then flattened to a single list. This operation is called Bind or flatmap in functional programming, or SelectMany in C#.

Sometimes the term 'monads' is loosely, and incorrectly used to refer to the whole set of one-to-many, one-to-one and many-to-one composing functions such as Select, Map, and Aggregate.  
****

Once again, the Bind function we gave above is the immediate version. We will soon do a deferred version, which uses IEnumerable<T> instead of List<T>. 


==== Example 3

Composition of asynchronous functions.

The functions that we want to compose may contain delays, or they may wait for input or output, or they may wait for processing occurring on a different thread or processor. In other words, the functions may be asynchronous - they will return a result later, not immediately. 

Because these type of function don't return a value immediately, we can't write an immediate execution monad. But we can still write a defered execution monad - a BInd function that will combine asynchronous functions, and return an asynchronous function. 

There are different estanblished ways to implement asynchronous functions. The oldest is the callback. The function receives a callback function as an extra parameter. When the result is ready later, the callback function will be called to pass back the result. 

More recently, asynchronous functions are implemented by returning a Task or future object. For our purposes here, a Task or future object are the same thing. They are an object that will have a result placed into it at a later time.

Here is the imperative version of the application layer code that composes functions that use callbacks. The common logic between the functions, function1, function2, and WriteLine is to create a callback function to be passed to the next, which is done using lambda functions: 



[source,C#]
....
static void ComposedFunction()
{
    function1(42, result =>
        {
            function2(result, result2 =>
                {
                    Console.WriteLine($"Final result is {result2}.");
                }
            );
        }
    );
}
....


Here is the imperative version of the application layer code that composes functions that return future objects. The common logic between the functions is to put a continuation function into the future object that was returned by the previous function: 


[source,C#]
....
static void ComposedFunction()
{
    function1(42)
    .ContinueWith(task1 =>
    {
        function2(task1.Result)
        .ContinueWith(task2 =>
        {
            Console.WriteLine($"Final result is {task2.Result}.");
        });
    });
}
....

In either case, notice the nasty indenting for every function we want to compose. In this case we could eliminate the indenting by using Unwrap() like this:

[source,C#]
....
static void ComposedFunction()
{
    function1(42)
    .ContinueWith(task => function2(task.Result))
    .Unwrap()
    .ContinueWith(task =>
    {
        Console.WriteLine($"Final result is {task.Result}.");
    });
}
....

But I want to show how monads simplify this even further.

(Note that both versions require lambda expressions (for example, the lambda expression starting with 'task1 =>" ). In the first implementation above, the lambda expression is an Action. In the second implementation the lambda expression is a function. So they are two different overloads of ContinueWith. In the second implementation, the lambda function returns the type returned by the function, which is a Task<T>. So ContinueWith returns Task<Task<T>>. The Unwrap discards the outer Task.) 

Of course, async/await also simplifies this particular example, but I want to show how monads can do it first. 

===== The Task monad


////
We did the imperative code that called the functions one after the other earlier in this section. You may remember that we attached a continuation action to Task objects returned by each function. In the first imperative version, each continuation had another level of nesting, and in the second version, an Unwrap was required. Also, if you look at the version on Github, the ContinueWith requires an additional parameter to cause everything to run on one thread.
////

For the Task monad, we simply factor out the ContinueWith logic into the Bind function. We can then use the Bind function like this in our top layer application code:


[source,C#]
....
// monad composition of functions that return Task objects

Task<int> CombinedFunction = 
    42.ToTask()
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....

The value that Bind takes and returns is Task<T>. So the starting value, 42, has to be converted to a Task<T> first before it can be passed to the first Bind. That's the purpose of the ToTask extension method.


Now let's write the Bind function for the Task<T> monad. There is a way of using the compiler to cheat to implement the Bind function:


[source,C#]
....
public static async Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    return await function(await source);
}
....

The async/await feature is indeed powerful, but our purpose is to see how Bind is a refactoring of the original imperative code. So here is the version that uses ContinueWith instead of async/await.


[source,C#]
....
public static Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    var tcs = new TaskCompletionSource<U>();
    
    source.ContinueWith(
        (t) => function(t.Result).ContinueWith(
            (t) => tcs.SetResult(t.Result)
        )
    );
    return tcs.Task;
}
....

The Bind function is passed a Task<T> that will contain the input in the future. It immediately creates a new Task<U> to return. It actually creates a TaskCompletionSource object, which contains a Task. The TaskCompletionSource object just provides a method for putting the value into the Task when it is ready later. A closure object is created for the first lambda expression and a delegate object is created to call that. The ContinueWith attaches this delegate to the source Task<T> as a (callback) Action. The Task<> that is returned by ContinueWith is discarded.

This is how the code works at runtime. When the source Task<T> produces a result, the first lambda expression will run. When it does, it receives the Task<T>, extracts the actual result from it, and passes it to the function. The function immediately returns a Task<U> (a different Task<U> from the one created earlier). When the Task<U> produces a result, the second lambda is called. It extracts the actual result from the Task<U> and puts it into the original Task<U> via the TaskCompletionSource object.

The Bind function can also be written using Unwrap, which eliminates the need for the TaskCompletionSource:

[source,C#]
....
public static Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    source.ContinueWith((t) => function(t.Result)).Unwrap();
}
....

When the lambda expression runs, it returns the Task<U> that is returned by the function, so the ContinueWith itself returns a Task<Task<U>>. The Unwrap discards the outer Task<>, leaving the Task<U> that is returned by the Bind function.

The async/await version generally runs everything on the same thread by default, which is great, but this is not the case for the ContinueWith version unfortunately. The example code on Github 
https://github.com/johnspray74/ContinuationMonad[https://github.com/johnspray74/ContinuationMonad]
shows a console application that passes a TaskScheduler.FromCurrentSynchronizationContext() parameter to the ContinueWiths so that everything runs on the Console UI thread. That thread is never blocked.

The functions that can be composed using this Bind function must return synchronously with a Task object, but can take as long as they want to put a value into the Task. In the examples below, we will use one function with a delay, and one that does I/O. Another case is a function that will do CPU bound work on another thread.

For completeness, here are two example functions we can use to compose applications. These two function could be used in the application code that we did earlier:

[source,C#]
....
    private static Task<int> function1(int x)
    {
        return Task.Delay(3000).ContinueWith(_ => x + 2);
    }
....



[source,C#]
....
private static Task<int> function2(int x)
{
    Console.WriteLine($"Value is {x}. Please enter a number to be added.");
    string line = null;
    return Task.Factory.StartNew(() => line = Console.ReadLine())
    .ContinueWith(_ => x + int.Parse(line));
}
....


The Task<T> monad was pretty heavy. We had to cover it because it's one of the most important and most useful monads. But don't worry if you didn't get all the details of how those implementations of the Bind functions worked. The important point that we could write a Bind function that allowed us to compose asynchronous functions, functions that return a future rather than an immediate return value.

Now for our forth example, let's do something much ligher. 


==== Example 4

Let's compose functions that return angles. 

The three examples of monads that we did so far, the MinusOne monad, the List monad, and the Task monad are common monads in the industry. (Well, not the MinusOne monad, I made that one up, but the industry version of that is the Maybe monad, which we shall switch to when we look at deferred versions.) 

For our last example, I wanted to do something custom, just to show that you really can create a monad to handle any type of intermediate logic you want between the functions you are composing. As long as we are always doing the same logic between all functions we compose, we can refactor that common logic into a Bind function.

Let's say we always want to do modulo 360 arithmetic. And let's throw in a total rotations counter as well, which we want to pass through the chain. Here is some imperative code:

[source,C#]
....
// procedural composition of functions that can return angles

int rotations = 0;
int result1 = function1(42)
rotations += result1 / 360;
result1 = result1 mod 360;
int result2 = function2(result1)
rotations += result2 / 360;
result2 = result2 mod 360;
int result3 = function3(result2)
rotations += result3 / 360;
result3 = result3 mod 360;
....

===== The Mod360 monad


This is not strictly speaking a monad because the function doesn't return the chaining interface type. That's because in this case the function didn't need to know anything about the rotations. However it still shows how the monad pattern can refactor arbitrary common code between composed functions.

Here is top layer application code to compose some functions handle angles. The second value in the Tuple is the number of rotations, which we initialize to 0.


Application layer code
[source,C#]
....

Tuple<int,int> result = new Tuple(42,0)
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....


Here is the Bind function:


[source,C#]
....
public static Tuple<int,int> Bind<T, U>(this Tuple<int,int> source, Func<int, int> function)
{
    int result = function(source.Item1);  // call the function
    return new Tuple<int,int> (
        result mod 360,   // normalize the angle
        source.item2 + result/360);   // count rotations
}
....


This time Bind takes a Tuple and returns a Tuple. The Tuple contains the angle between 0 and 359 and the rotations. Bind will do the mod 360 on the result returned by the function, and add any whole rotations. It returns a new Tuple with those two values in it.

Note that it was easy to get the starting 42 value into the Tuple needed by the Bind function by simply using 'new Tuple(42,0)'. So in this case we didn't need something like a ToTuple extension method.


==== The monad pattern

In all 4 of the above examples, the refactoring follows a pattern, which I will call the monad pattern. 

In each case, we were able to create a compose function (called Bind) that just composes functions in a declarative way. In each case we were able to refactor any common logic needed in the imperative code between function calls into the Bind function. That's pretty much what we are about with monads, composing functions using a Bind function and putting any common logic that is needed between each function into the Bind function as well. It is that common logic that distiguishes different types of monads.

The Compose function is often called _Bind_, but can go by other names such as the symbol =\=>. If the monad is the list monad or IEnumerable monad, it can be called flatmap or SelectMany. The most common monad you will come across is the IEnumerable monad, but many other types of monads are possible.

More formerly, a monad consists of three elements:

. a Bind function  

. a type that the Bind function takes as its first parameter and returns. This type is often an interface, or something we can think of as an interface in a general sense. We will refer to it as the chaining interface from now on. The chaining interfaces for the four monads we have done so far were int, List, Task and Tuple<int,int>. But often the type will be an actual interface such as IEnumerable as we will see soon. 
+
Because Bind both takes and returns the chaining interface, Bind calls can be chained with dot operators. That's why I call it the chaining interface.
+
The chaining interface is used in a third place in the monad pattern. It is the return type for the functions that can be composed. Although both the functions and Bind return the same type of interface, The object returned by the composed function is necessarily the one that is returned by Bind.

. a function to use at the start of a chain of bind functions to convert an ordinary value like 42 to the chaining interface type so that we can pass it to the very first Bind.  In monad land, this function is sometimes called _unit_ or _return_. For the four example monads we have done, we didn't need a unit function except for the Task monad, for which we created a ToTask extension method as the unit function. However in the upcoming deferred monads, we will generally need such an extension method.


To see how monads compare with ALA, we now want to do deferred versions of our 4 examples. Actually the Task<T> monad is already deferred, so we will just do the other three examples. 


For the minus_one example, we are going to switch to the IMaybe monad first, because that's the generally used solution to composing functions that may return no value. Skip this if you are already familiar with the IMaybe concept, unless you are interested to see how the IMaybe monad and its Bind function works. 


==== IMaybe monad

Composition of functions that can fail by returning IMaybe<T> or Nullable<T>.

Using minus one, as we did earlier to represent a 'no value', is not used outside the C world, and limits the data itself to positive integers. The more general solution in the monad world is the IMaybe<T> monad. It's called IMaybe because maybe it contains a value, or maybe it doesn't.

The IMaybe version of Bind is similar to the -1 version. However the chaining  interface is IMaybe<T>. Bind takes an IMaybe interface and returns an IMaybe interface, and the functions that we compose together also return an IMaybe interface.

We will have two classes that implement IMaybe. They are called Something and Nothing.

Here is example top layer application code composing functions that return IMaybe. 

Application layer code
[source,C#]
....
IMaybe<double> combinedFunctions = 42.ToMaybe()
    .Bind(x => new Something<int>(x+1))
    .Bind(x => x==0 ? new Nothing<double>() : new Something<double>((double)1/x) )
    .Bind(x => new Something<int>(x*10+1));
....

Something and Nothing are classes that implement IMaybe<T>, which we provide below for completeness.

The Bind function wont call the lambda expression if the result from the Bind is Nothing. But if the result from the previous Bind is Something, it takes the value out and gives it to the lambda function.

The Bind function takes an IMaybe as a parameter and returns an IMaybe. Notice that we need to convert the starting value, 42, to an IMaybe. That's because the first Bind in the chain must have an IMaybe. To be a monad, we generally need to supply this method which is always used at the start of a chain of Binds.

Here is the IMaybe interface:

[source,C#]
....
public interface IMaybe<T>
{
    bool HasValue { get; }
    T Value { get; }
}
....

IMaybe consists of two getters, one called HasValue() that returns a bool to find out if a value is there, and the other called Value to get the actual value out if there is one. 

You would normally use HasValue first and only if it returns true would you use Value. HasValue is analogous to the MoveNext method in the IEnumerator interface, which you also have to call first before retrieving a value. We will need two classes that implement IMaybe, one to represent a nothing, and one to represent something:


Monad layer code
[source,C#]
....
public class Nothing<T> : IMaybe<T>
{
    bool IMaybe<T>.HasValue { get => false; }
    T IMaybe<T>.Value { get { throw new Exception("No value"); } }
}


public class Something<T> : IMaybe<T>
{
    private T value;

    public Something(T value) { this.value = value; }

    bool IMaybe<T>.HasValue { get => true; }
    T IMaybe<T>.Value { get => value; }
}
....


The Bind function uses its input IMaybe<T> to see if there is a value present or not. If there is nothing it doesn't call the function. It just returns a new IMaybe<U> implemented by a Nothing object. If there is a value, it gets the value and passes it to the function. Then Bind returns the IMaybe returned by the function. Here is the ToMaybe and Bind functions:


Monad layer code
[source,C#]
....
static class ExtensionMethods
{
    public static IMaybe<T> ToMaybe<T>(this T value)
    {
        return new Something<T>(value);
    }


    public static IMaybe<U> Bind<T, U>(this IMaybe<T> source, Func<T, IMaybe<U>> function)
    {
        return source.HasValue ? function(source.Value) : new Nothing<U>();
    }
}
....


==== Deferred monad versions


All the monads we have done so far (except for the Task monad), were immediate or eager versions of the monads. This means that the Bind function calls the composed functions itself and passes the results(s) to the next function. We did the immediate versions because they are so simple.

However, we want to do deferred versions of all these monads because they are more versatile, and they create an object structure that is returned for later execution. We want to compare this object structure with the way ALA also creates an object structure composed of domain abstractions.

With deferred monads, we can do either pull versions or push versions.

For the pull version, we keep a reference to the last object in the structure. We call a method in that object when we want the result. That call pulls the data through the chain of objects. For the push version, we will keep a reference to the first object in the chain. When we want a result we will tell the first object to start, and the result will pop out of the other end.

In ALA, we generally default to programming paradigms that use pushing. To compare monads with ALA, we will therefore want to understand the push variations of the monads. However, pull monads are more common in the monad world. So we will do both. It gets pretty interesting to see the differences between the two in terms of how everything works in the code. 


The implemtation code for each of the deferred versions will obviously be a little more complicated than the immediate versions of these monads. It will involve using objects to build a structure that can be returned for deferred execution. However, for completeness, I have not shied away from including all the code for the three monad examples. I have done this for both pull and push versions. It's not necessary to read or understand all the code. But when you want to know exactly how something works, at least the code is there along with notes to explain it. I also include object diagrams explaining the object structure that is created beneath the covers by the Bind code.  


==== Forcing execution of a deferred monad

Once you have written top layer application code for composing functions using a deferred monad, you may be wondering how you would execute the returned structure of objects to get he actual value. Well, given an object, s, that was returned by the monad expression, here are examples of the ways of forcing it to execute for various types of common monads: 

[source,C#]
....
if (s.HasValue) { use s.Value }      // maybe monad, calling HasValue causes eveluation
s.ToList()                           // IEnumerable
foreach (var value in s) {...}       // IEnumerable
s.Subscribe((x)=>{....})             // IObservable (push version of IEnumerable)
s.Result                             // Task (blocking version)
await s                              // Task (non blocking version)
use r.Item0, use r.Item1             // tuple. Accessing either Item cause evaluation
....


////
==== MinusOne monad (deferred, pull version)

Composition of functions that can fail by returning -1.

For the deferred version of the MinusOne monad, we use Func<int> instead of an integer as the chaining interface. The Bind function takes a Func<int> and returns a Func<int>:


Here is top layer code that composes functions that can return -1:

[source,C#]
....
Func<int> CombinedFunction = 
    42.ToMinusOne()
    .Bind(x => x+1)
    .Bind(x => x==0 ? -1 : 1/x)
    .Bind(x = x*10+1);
}
....

This code is the same as we had previously for the immediate version except for the use of the ToMinuseOne method. However the chaining interface is different. The interface type is Func<int> instead of just <int>.



Here are the ToMinusOne and Bind functions for the deffered version of this monad: 

Pull version
[source,C#]
....
namespace Monad.MinusOne
{
    public static class ExtensionMethod
    {
        public static Func<int> ToMinusOne(this int source)
        {
            return () => source;
        }

        public static Func<int> Bind(this Func<int> source, Func<int, int> function)
        {
            return () =>
            {
                int value = source();
                return value == -1 ? -1 : function(value);
            };
        }
    }
}
....

You can see that the Bind function, instead of evaluating a reult, returns a lamba function that can be used later to evaluate the result.

The lambda function is turned into a closure object by the compiler. The returned object structure for the top layer code looks like the diagram below.

image::MinusOneDeferredPullMonadDiagram.drawio.png[MinusOneDeferredPullMonadDiagram.drawio.png, title=Object diagram of expression using deferred/pull version of MinusOne monad, link=images/MinusOneDeferredPullMonadDiagram.drawio.png"]

This structure is exactly the same as the one we showed above for the deffered Compose function that composed ordinary functions that couldn't return an error. The only difference is that for the three closures that are created by the Bind function, the closure method contains the common code, that is it checks for -1 from the source before calling the next function.

We got a little lucky with the implementation of the deferred MinusOne monad. That is that we were able to use Func<int> as the interface instead of using an actual interface with a function in it. That allowed us to use simple closures to implement the Bind and ToMinusOne functions, just as we did for the Compose function. From now on we won't be able to do that because the monads will be using an actual interface. We will need to create our own class to be used by Bind. Let's do a push verion of the Minusone monad to show how the Bind function needs a supporting class. 


==== MinusOne monad (deferred, push version)

With deferred monads, we can do either pull versions or push versions.

In ALA, we generally default to programming paradigms that use pushing. To compare monads with ALA, we will therefore show push variations of the monads.  

For the pull version, we keep a reference to the last object in the structure. We call a function in that object when we want the result. That call pulls the data through the chain of objects. For the push version, we will keep a reference to the first object in the chain so we can push values into it.

Here is the application code for the push version. 

[source,C#]
....
// deferred monad composition of functions that might return -1

IMinusOneObservable<int> result = 42.ToMinusOne()
    .Bind(x => x+1)
    .Bind(x => x==0 ? -1 : 1/x)
    .Bind(x = x*10+1);
}
....

This code is the same as we had previously, and even the same as the immediate version except for the use of the ToMinuseOne method. However the chaining interface is different. The chaining interface is IMinusOneObservable. Here it is:

[source,C#]
....
public interface IMinusOneObservable
{
    void Subscribe(IMinusOneObserver observer);
}
....

This may at first seem like a strange interface for a chaining interface. The chaining interface is always _implemented_ by the source object in the chain, and _used_ by the next object in the chain. That's what allows the Bind function to work. But in this case we are writing a push style monad that will push the data from the source at execution time. So we need a second interface that will go in the opposite direction to carry the data (although we could have chosen to use C# style events (observer pattern) instead). The chaining interface is not used to pull data like in our previous monads, but instead it is used to simply wire the second interface in the opposite direction.

This second interface we will call IMinusOneObserver. And yes, these two interfaces are exactly analogous to the IObservable and IObserver interfaces in reactive extensions.


[source,C#]
....
public interface IMinusOneObserver
{
    void Push(int value);
}
....

The IMinusOneObserver interface is wired in the same direction as the dataflow, so destinations implement the interface and sources will have a field of the type of this interface.

Bind can't be defined on the IMinusOneObsever interface because it's the wrong way around. Bind therefore uses the IMinusOneObservable interface for its first parameter and its return value.

For the push version we don't have the luck we had in the pull version that allowed us to implement it with closures because we had to use the IMinusOneObserver interface. The Bind function will instead use an explicit class that implements IMinusOneObserver, which we will call MinusOne. Here is that class, together with the ToMinusOne and Bind extension methods:


[source,C#]
....
namespace Monad.MinusOne
{
    static class ExtensionMethods
    {
        public static IMinusOneObservable ToMinusOneMonad(this int value) <6>
        {
            return new MinusOneStart(value);
        }

        public static IMinusOneObservable Bind(this IMinusOneObservable source, Func<int, int> function) <1>
        {
            MinusOne minusOne = new MinusOne(function);
            source.Subscribe(minusOne);
            return minusOne;
        }
    }




    class MinusOne : IMinusOneObservable, IMinusOneObserver <2>
    {
        private IMinusOneObserver observer; <3>

        private Func<int, int> function;

        public MinusOne(Func<int, int> function) <4>
        {
            this.function = function;
        }

        void IMinusOneObserver.Push(int value) <5>
        {
            if (value == -1)
            {
                observer.Push(-1);
            }
            else
            {
                observer.Push(function(value));
            }
        }

        void IMinusOneObservable.Subscribe(IMinusOneObserver observer)
        {
            this.observer = observer;
        }
    }




    class MinusOneStart : IMinusOneObservable <7>
    {
        private int value;
        private IMinusOneObserver observer;


        public MinusOneStart(int value) { this.value = value; }

        void IMinusOneObservable.Subscribe(IMinusOneObserver observer)
        {
            this.observer = observer;
        }

        public void Run()
        {
            observer.Push(value);
        }
    }
}
....

<1> The Bind method instantiates a class to do the work. The Bind function also wires up the IMinusOneObserver interface using the Subscribe method.  

<2> IMinusOneObservable is implemented by data sources. IMinusOneObserver is implemented by data destinations. Our MinusOne class, as part of a chain of operations, is both a source and a destination, so it implements both. 

<3> Once wired, the only reference between the objects is the reference from source to destination in the field called observer in the MinusOne class. 

<4> The constructor just needs to store the function we are composing.

<5> The Push method is the only part that runs when the monad object structure executes.

<6> The last thing to note is the usual method we need to get the 42 into the chaining interface type so that we can start using Bind. The method is called ToMinusOneMonad.

<7> ToMinusOneMonad needs a class that implements IMinusOneObservable. That class is MinusOneStart. The ToMinusOneMonad extension method simply needs to instantiate this class.

Here is the object diagram of the resulting structure of the top layer code:

image::MinusOneDeferredPushMonadDiagram.drawio.png[MinusOneDeferredPushMonadDiagram.drawio.png, title=Object diagram of expression using deferred/push version of MinusOne monad, link=images/MinusOneDeferredPushMonadDiagram.drawio.png]

You can see that the three delegate-closure pairs we had in the pull version are replaced with an object of class MinusOne. The three objects are wired together in the direction of the data flow (left to right) using the IMinusOneObserver interface. The IMinusOneObservable was only used by the Bind function to effect the wiring of IMinusOneObserver. It is unused when the structure runs. The IMinusOneObservable interface at the end can be used to wire to an output object that implements IMinusOneObserver.

The 42 is stored in the object of the MinusOneStart class. This class has a run function which is used to start the structure executing. We start it from the source end because it is a push monad we are using. (This differs from the reactive extensions, which starts executing on Subscribe, so execution is actually initiated from the destination end.) In ALAs push programming paradigms, we usually initiate dataflow at the source end.

You can start to see the ALA pattern to this structure. It is instantiating objects and wiring them together to build a structure to run later. IMinusOneObserver is the equivalent of an ALA programming paradigm.

All the deferred monads we do from now on have this same structure. The push ones will be wired in the direction of dataflow, left to right, like this one is. The pull ones will be wired in the opposite direction of the dataflow, right to left. As I said, we were just lucky that the deferred pull version of the MinusOne monad that we did above was able to be implemented with compiler gnerated closure classes because the monad type was Func<int> instead of a real interface. We will always need an explicit class from now on. 

Next well do a deferred pull monad that uses a real interface<T>, the IMaybe<T> monad.
////


==== IMaybe monad (deferred, pull version)


We will write a deferred version of Bind that composes functions that can fail by returning IMaybe<T> or Nullable<T>. It is deferred, so it returns an object that  implements IMaybe in a way that will evaluate the result when the Value is required.

Here is top layer code to use the deferred/pull implementation of the maybe monad.


[source,C#]
....
IMaybe<double> objectStructure = 42.ToMaybe()
    .Bind(x => new MaybeSomething<int>(x+1))
    .Bind(x => x==0 ? new MaybeNothing<double>() : new MaybeSomething<double>((double)1/x) )
    .Bind(x => new MaybeSomething<int>(x*10+1));
....

It looks the same as the immediate version. But it returns an IMaybe that's implemented by a large object structure instead of returning one of the two concrete IMaybe value objects. 

First we define the IMaybe interface, which is the same as for the immediate version above. The MaybeNothing and MaybeSomething classes are also the same as before. Here they are again.


[source,C#]
....
    public interface IMaybe<T>
    {
        bool HasValue { get; }
        T Value { get; }
    }

    public class MaybeSomething<T> : IMaybe<T>
    {
        T value;

        public MaybeSomething(T value) { this.value = value; }

        bool IMaybe<T>.HasValue { get => true; }
        T IMaybe<T>.Value { get => value; }
    }



    public class MaybeNothing<T> : IMaybe<T>
    {
        bool IMaybe<T>.HasValue { get => false; }
        T IMaybe<T>.Value { get { throw new Exception("No value"); } }
    }
....


The Bind function is different as it must build a structure that can be run later. 
[source,C#]
....
namespace Monad.MaybeDeferredPull
{
    static class ExtensionMethods
    {
        public static IMaybe<T> ToMaybe<T>(this T value)
        {
            return new MaybeSomething<T>(value);
        }

        public static IMaybe<U> Bind<T, U>(this IMaybe<T> source, Func<T, IMaybe<U>> function)
        {
            return new Maybe<T, U>(source, function);
        }
    }
....

As you can see, Bind simply instantiates new class called "Maybe" that implements IMaybe, which will do all the work at runtime.



[source,C#]
....
namespace Monad.MaybeDeferredPull
{
    class Maybe<T, U> : IMaybe<U>
    {
        // implement the constructor, which receives the Action function
        private Func<T, IMaybe<U>> function;
        private IMaybe<T> source;
        private IMaybe<U> result; // null if we haven't evaluated yet

        public Maybe(IMaybe<T> source, Func<T, IMaybe<U>> function) { this.source = source; this.function = function; }

        bool IMaybe<U>.HasValue 
        { get 
            {
                if (result == null)
                {
                    if (source.HasValue)
                    {
                        result = function(source.Value);
                    }
                    else
                    {
                        return false;
                    }
                }
                return result.HasValue;
            }
        }

        U IMaybe<U>.Value
        {
            get
            {
                if (result == null)
                {
                     result = function(source.Value);  // will throw exception if no value
                }
                return result.Value; // will throw exception if no value
            }
        }
    }
}
....

The code that runs later in the Maybe class is the HasValue and Value getters. They do all the work. 

This diagram shows the resulting structure from our little bit of application code above:


image::MaybeDeferredPullMonadDiagram.drawio.png[MaybeDeferredPullMonadDiagram.drawio.png, title=Object diagram of expression using deferred/pull version of IMaybe monad, link=images/MaybeDeferredPullMonadDiagram.drawio.png]

Because this is a pull implementation of the monad, the references go in the opposite direction of the dataflow - from destination to source or from right to left. When you want to run the combined function, you pull the value from the right end. 



==== IMaybe monad (deferred, push version)

Having done the deferred pull version, we will now do the deferred push version, which has an interesting analogy with the IObservable.

Here is the top layer code, which in this case returns a IMaybeObservable.

[source,C#]
....
IMaybeObservable<int> result = 42.ToMaybe()
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....

I've purposely left the lambda expressions out for now. Well get back to them in a minute.

For the push version we need two interfaces. One, which we will call _IMaybeObservable<T>_, is the chaining interface that Bind takes and returns. The other, which we will call _IMaybeObserver_ is for doing the actual pushing of data at runtime. The two interfaces work in opposite directions. That is _IMaybeObservable<T>_ is always implemented by the previous object in the chain . _IMaybeObserver_ is always implemented by the next object in the chain. 

Here are the two interfaces:

[source,C#]
....
    public interface IMaybeObservable<T>
    {
        void Subscribe(IMaybeObserver<T> observer);
    }
....


[source,C#]
....
    public interface IMaybeObserver<T>
    {
        void NoValue();
        void Value(T value);
    }
....


That _IMaybeObservable<T>_ implementation may at first seem a little strange. It has no way of getting the value out. That's because we are implementing a push style monad. The _IMaybeObservable<T>_ interface is used by Bind only to get a reference to the previous object in the chain. It then gives the previous object a reference to it's next object, which the previous object will use to push the data.  
This second reference will use an interface called _IMaybeObserver_. And yes, these two interfaces are exactly analogous to the IObservable and IObserver interfaces in reactive extensions.

_IMaybeObservable<T>_ is _used_ by the next object in the chain.

The _IMaybeObserver_ interface is used by the pervious object. (We could have chosen to use C# style events (observer pattern) instead of using _IMaybeObserver_, but it's easier to do it exactly the same way as IObservable and IObserver). 

Note that the _IMaybeObserver_ interface's methods are actions. They don't pull a value like in the pull version we did of this monad, they push. I am tempted to rename them PushValue and PushNoValue to make this obvious everywhere that Value and NoValue are used.

Normally with monads, the type that the composable functions return would be the same as the chaining interface. So all functions that are composable by this monad should return IMaybeObservable, like this type:

 Func<T, IMaybeObservable<U>>

Having all your functions return an IMaybeObservable would certainly work, but the functions would be a little complicated. They would all have to create an object that implements the IMaybeObservable interface to return. It would be far simpler if the functions were passed an IMaybeObserver instead of returning an IMaybeIObservable. So they would have this form:

 Action<T, IMaybeObserver<U>>
 
Now when the functions run, they don't need to create an object, they just directly push the result out via the IMaybeObserver<U>> interface that was passed to them. So that's what we will do in our example. It's a more loose interpretation of the definition of monad, but it's just more sensible to do it that way.

Note that the IMaybeObserver interface (listed above) could have been written with a single method like this:

 void Push(IMaybe<T> data)

However, to make it as easy as possible for the composable functions to use the interface (not have to create a Something or Nothing object), I have changed the interface to be two methods:

 void NoValue();
 void Value(T value);

So now we can write the application layer code using simple lambda expression syntax:

[source,C#]
....
IMaybeObservable<double> combinedFunction = 42.ToMaybe();
    combinedFunction
    .Bind((x,ob) => ob.Value(x+1))
    .Bind((x,ob) => { if (x==0) ob.NoValue(); else ob.Value((double)1/x); } )
    .Bind((x,ob) => ob.Value(x*10+1));
    
    combinedFunction.Start();
....

Note that we keep a reference to the source of the chain, not the end. That is the object returned by ToMaybe(). This object has a Run method. The structure starts executing when the Run method is called. This is a departure from the way IObservable and IObserver work. With IObservable, the Subscribe method both wires the IObserver in the opposite direction, and tells the source to start. So even though it's suppossedly a push style, execution is started from the destination end, which makes it look like a pull style. This loses some of the advantages of using a push style, for example, when it is the source that wants to initiate a push whenever the source changes, or when using asynchronous communication across a network. I really think the straightforward push system is conceptually purer and more useful. So that is what I have implemented. 

Here are the ToMaybe and Bind functions for the IMaybe deferred push monad:


[source,C#]
....
namespace Monad.MaybeDeferredPush
{
    static class ExtensionMethods
    {
        public static IMaybeObservable<T> ToMaybe<T>(this T value)
        {
            return new MaybeStart<T>(value);
        }

        public static IMaybeObservable<U> Bind<T, U>(this IMaybeObservable<T> source, Action<T, IMaybeObserver<U>> action) <1>
        {
            var maybe = new Maybe<T, U>(action);
            source.Subscribe(maybe);
            return maybe;           
        }
    }

}
....

<1> The Bind function just creates an object to do all the work at runtime. The object is defined by a class called Maybe (listed below). The Bind function takes an IMaybeObservable interface and returns that same interface. It composes Actions rather than functions. These actions take an IMaybeObserver.




[source,C#]
....

namespace Monad.MaybeDeferredPush
{

    class Maybe<T, U> : IMaybeObserver<T>, IMaybeObservable<U> <2>
    {
        private Action<T, IMaybeObserver<U>> action;

        public Maybe(Action<T, IMaybeObserver<U>> action) { this.action = action; }


        private List<IMaybeObserver<U>> subscribers = new List<IMaybeObserver<U>>(); <4>

        void IMaybeObservable<U>.Subscribe(IMaybeObserver<U> observer) <2>
        {
            subscribers.Add(observer);
        }

        void IMaybeObserver<T>.NoValue() 
        {
            foreach (var subscriber in subscribers)
            {
                subscriber.NoValue();
            }
        }

        void IMaybeObserver<T>.Value(T value) 
        {
            action(value, new ActionObserver<T, U>(this));
        }

        private class ActionObserver<T, U> : IMaybeObserver<U> <3>
        {
            private Maybe<T, U> outer;
            public ActionObserver(Maybe<T, U> outer) { this.outer = outer; }

            void IMaybeObserver<U>.NoValue() 
            {
                foreach (var subscriber in outer.subscribers)
                {
                    subscriber.NoValue();
                }
            }

            void IMaybeObserver<U>.Value(U value) 
            {
                foreach (var subscriber in outer.subscribers)
                {
                    subscriber.Value(value);
                }
            }
        }
    }




    class MaybeStart<T> : IMaybeObservable<T>
    {
        private T value;
        public ToMaybe(T value) { this.value = value; }

        private List<IMaybeObserver<T>> subscribers = new List<IMaybeObserver<T>>();
        void IMaybeObservabe<T>.Subscribe(IMaybeObserver<T> subscriber)
        {
            subscribers.Add(subscriber);
        }

        public void Run()
        {
            foreach (var subscriber in subscribers)
            {
                subscriber.Value(value);
            }
        }
    }
....

<2> The Maybe class implements both IMaybeObservable and IMaybeObserver. IMaybeObservable is only used by Bind. It's Subscribe method wires the IMaybeObserver in the opposite direction. IMaybeObserver is the one that is used at runtime to push the data through.

<3> Remember the 'composable functions' in the application layer are not Funcs but Actions that take a value and an IMaybeObserver<U>. So we need a class that implements IMaybeObserver so we can make observer objects to pass to the Actions when we call them at runtime. This class is implemented as an inner class called ActionObserver.

<4> The wiring of Maybe supports fanout or multiple subscribers (just like the observer pattern). We will do it for all deferred push style monads. It is normal for push monads to support fan out, in other words many observers can be subscribed to the one observable. It is another advantage of push style monads over pull style monads.


Here is an object diagram of the complete expression.

image::MaybeDeferredPushMonadDiagram.drawio.png[MaybeDeferredPushMonadDiagram.drawio.png, title=Object diagram of expression using deferred/push version of IMaybe monad, link=images/MaybeDeferredPushMonadDiagram.drawio.png]

You can see that although using the IMaybe monad Bind function from the top layer to compose three functions is extremely simple, the structure of objects that is generated under the covers is relatively complicated. It's no wonder that these monad things seem so hard to understand at first.  

The references between the objects, which use IMaybeObserver, go in the same direction as the dataflow. IMaybeObservable is only used for wiring the structure up.


So far we have done deferred pull and deferred push implementations of the IMaybe monad. Now lets do the deferred verson of the List monad, the IEnumerable monad


==== IEnumerable monad

Composition of functions that return many values, in this case an IEnumerable.

The IEnumerable monad is the deferred version of the list monad we did earlier. The IEnumerable monad is the most commonly used monad, and is what LINQ is based on.

The Bind function for the IEnumerable monad is called SelectMany in C#. SelectMany is not used as often as Select. Select takes a simpler function that returns U instead of IEnumerable<U>, so it doesn't expand the number of items, it just does a one-to-one mapping. While Select is used more often, it is the SelectMany function that makes it a Monad. Here in our example application we will use three SelectManys in a row. Each will expand in number by 3, so we will end up with an IEnumerable with 27 items in the end.  

Here is example top layer code that composes functions that return IEnumerable

[source,C#]
....


IEnumerable<int> result = 42.ToEnumerable()
    .SelectMany(function1)
    .SelectMany(function2)
    .SelectMany(function3);
....

Remember that for the IEnumerable monad, function1, function2, and function3 take a single value and return many values in the form of an IEnumerable.

In the immediate example above that returned lists, the lambda expressions looked like this:

[source,C#]
....
var result = new[] { 0 }  
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 });
....

While this will run fine when using the IEnumerable version of Bind, it's not really in the style of a deferred monad to create memory hungry arrays. So let's write functions that will do the same job in a deferred way:

[source,C#]
....
private static IEnumerable<int> MutiplyBy10AndAdd1Then2Then3(int x)
{
    yield return x * 10 + 1;
    yield return x * 10 + 2;
    yield return x * 10 + 3;
}
....

The _yield return_ keyword causes the compiler to generate an IEnumerable object, which it returns. The IEnumerable object contains a state machine where each state executes code till it hits the next yield return statement. 

Let's just reuse that function three times in our composed function:


[source,C#]
....
static void Application()
{
    var program = new[] { 0 }  
    .Bind(MutiplyBy10AndAdd1Then2Then3)
    .Bind(MutiplyBy10AndAdd1Then2Then3)
    .Bind(MutiplyBy10AndAdd1Then2Then3);

    var result = program.ToList();  // now run the program
    Console.WriteLine($"Final result is {result.Select(x => x.ToString()).Join(" ")}");
}
....

The Bind function (SelectMany) for this type of monad takes an IEnumerable<T> and returns an IEnumerable<U>. The Bind function doesn't use a for loop immediately as that would defeat the laziness. Instead the bind function uses an object that keeps state. Let's call this object the _output IEnumerable_. The output IEnumerable knows how to use the _source IEnumerable<T>_ to get the first value, which it gives to the function. The function returns an IEnumerable<U> which we will call the _function return IEnumerable_. The output IEnumerable then knows how to get the values from the function return IEnumerable<U> and return them one at a time. When it has exhausted all of them, the output IEnumerable<U> then gets the next value from the source IEnumerable<T>, and gives that to the function. The function again returns an IEnumerable<U>. This process continues until the source and function output IEnumerables are both exhausted. 

In C#, the Bind function is really easy to write because the compiler can build an IEnumerable for you using the _yield return_ syntax:

[source,C#]
....
namespace Monad.Enumerable
{
    static class ExtensionMethods
    {
        public static IEnumerable<U> Bind<T, U>(this IEnumerable<T> source, Func<T, IEnumerable<U>> function)
        {
            foreach (var t in source)
            {
                var enumerator = function(t);
                foreach (var u in enumerator)
                {
                    yield return u;
                }
            }
        }
    }
}
....

Note that the code in the function does not run when this Bind function runs. The compiler sees the _yield return_ and builds an object containing a state machine that implements IEnumerable<U>, and returns that.

Since our purpose is to show how the Bind function is a refactoring of imperative code, here is a version that doesn't cheat by using the yield return syntax:


[source,C#]
....
static class ExtensionMethods
{
    public static IEnumerable<U> Bind<T, U>(this IEnumerable<T> source, Func<T, IEnumerable<U>> function)
    {
        return new EnumerableMonad<T, U>(source, function);
    }
}
....
    
All Bind does is instantiate the class and return it. The class gets passed the source IEnumerable and the function. The class implements IEnumerable<U> for its output, which means it must be able to return an object implementing IEnumerator. The easiest way to do that is have the class implement IEnumerator<U> as well. Then the IEmumerable can just return 'this'.


[source,C#]
....
class EnumerableMonad<T, U> : IEnumerator<U>, IEnumerable<U>
{
    private readonly IEnumerable<T> source; 
    private readonly Func<T, IEnumerable<U>> function;
    
    public EnumerableMonad(IEnumerable<T> source, Func<T, IEnumerable<U>> function)
        { this.source = source; this.function = function; } <1>

    private IEnumerator<T> sourceEnumerator = null;

    IEnumerator<U> IEnumerable<U>.GetEnumerator()
    {
        sourceEnumerator = source.GetEnumerator();
        return (IEnumerator<U>)this;
    }

    IEnumerator IEnumerable.GetEnumerator()
    {
        sourceEnumerator = source.GetEnumerator();
        return this;
    }


    private IEnumerator<U> functionEnumerator = null;

    U IEnumerator<U>.Current => functionEnumerator.Current;

    object IEnumerator.Current => throw new NotImplementedException();

    void IDisposable.Dispose() { }

    bool IEnumerator.MoveNext() <2>
    {
        while (true)
        {
            if (functionEnumerator != null)
            {
                if (functionEnumerator.MoveNext())
                {
                    return true;
                }
            }
 
            if (sourceEnumerator.MoveNext())
            {
                functionEnumerator =
                    function(sourceEnumerator.Current).GetEnumerator();
            }
            else
            {
                return false;
            }
        }
    }

    void IEnumerator.Reset()
    {
        functionEnumerator = null;
        sourceEnumerator.Reset();  
    }
}
....

<1> The constructor is passed both the sourceIEnumerable and the function. It saves both of them in local variables.
 
<2> The IEnumerator MoveNext method does all the work of the class at runtime. It is called by the next object in the chain. It gets the first element from the source, and feeds it to the function. Then it stores the Enumerator it gets from the function so it can use it in subsequent calls. Then it gets the first element from the function's Enumerator and returns it. A while loop is necessary because when the Enumerator that is returned by the function runs out, it needs to go back and get the next element from the source and pass that to the function.

The class is completely lazy, so it doesn't even get the source IEnumerator from the source IEnumerable until the first call of MoveNext.

The two fields, sourceEnumerator, and functionEnumerator are the state. The first can have a state of null, which is the state before we got the first value. 

The object diagram for the program again shows three objects wired in a chain from right to left:

image::IEnumerableDeferredPullMonadDiagram.drawio.png[IEnumerableDeferredPullMonadDiagram.drawio.png, title=IEnumerable Deferred Pull Monad Object Diagram, link=images/IEnumerableDeferredPullMonadDiagram.drawio.png]


Bind just wires the IEnumerable interface. The IEnumerable GetEnumerator method then effectively wires the IEnumerator interface (in the same direction). So you might wonder if the IEnumerable interface could be considered redundant. We not just make Bind wire up the IEnumerator interfaces and dispensed with IEnumerable altogether? That would work, but I guess the reason IEnumerable exists is because IEnumerator is already implemented by many underlying library collections. When writing a new class that will support foreach, we need only provide a GetEnumerator method that simply returns the underlying collection instead of implementing the whole IEnumerator interface. However in our class above, this didn't help because we had to implement the whole IEnumerator interface because we were recombining multiple collections.


==== IObservable monad


The IObservable monad is the push version of the IEnumerable monad, sort of.

Once the flow of data begins, it is indeed pushed (source to destination). The data is pushed using the IObserver interface. But with the IObservable IObserver pair of interfaces, it the destination that initiates the transfer. The destination uses the Subscribe method in the IObservable monad to register to observe the data. This Subscribing is also what initiates the transfer in the source. Once a transfer is completed, another transfer can usually be started by unsubscribing and resubscribing. When used in this way, IObservable is sort of a pull programming paradigm when you consider which end initiatiates the data transfer.

Some writers equate IObservable with "asynchronous". However, a pushing interface like IObserver can be either synchronous or asynchronous. Data flows from the source object by calling a method in the IObserver interface, called OnNext. That method can execute synchronously all the way to the destination end of the chain, or it can return at any point along the chain, and the data flow can resume from that point at a later time, which is what we refer to as asynchronous. 

Pull communications can't be asynchronous or broken up in time, at least not in a straight forward way. It either requires blocking the thread (we don't want to go there) or using a Callback, or using a Task or future object (which we covered earlier). The IEnumerator interface, being a pull interface, can only work synchronously. With IEnumerator, the destination end pulls data by calling a method. The function must execute synchronously all the way to the source otherwise it would return without a result. 

The ability of push style programming to be either synchronous or asynchronous is a good reason to default to using it. It is the reason ALA defaults to using push. Sometimes there are good reasons to use pull, but where it doesn't matter, we prefer push. So it is worth looking at the IObservable monad for comparing with ALA, even though IEnumerable monads tend to be more common in practice, but only because they work well for database queries (pull data from the database). IObservable is the closest for comparison with the common ALA programming paradigms.


////
I think the reason the IEnumerable monad is more common may be because it seems more suited for database queries. After all, for this context it is the destination, not the source, that knows when it wants data. Or at least it's usually something nearer the destination end such as a button.

However, this doesn't mean that database queries should use pull. The system could well benefit from using push based communications even from a database. For example, this would allow for asynchronous data transfers of the results of a query over a network.

To use push for database queries, and initiate the transfer from the destination end, you need only invent a programming paradigm that has two push channels, one in each direction. A query push channel goes toward the database, and a response push channel comes back. In ALA, because you can easily implement programming paradigms, this is really easy to do, and should be the way database queries are done. A database adapter at the end implements this "push/push" programming paradigm and does the work of actually talking to the database with SQL.

The IObservable interface is apparently a push request/push response paradigm. In addition to wiring the IObserver interface, the IObservable.Subscribe method can also initiate the data transfer. But the Subscribe method can only communicate when we want the data, but can't take other details of an actual query. So IObservable is not that suited to databases without yet another push channel to handle the the query. So IQueryable, which is based on IEnumerable tends to be used with databases.
////

Unlike the IEnumerable/IEnumerator pair of interfaces which go in the same direction, the IObservable/IObserver interfaces go in opposite directions. The IObservable interface goes from destination to source whereas the IObserver interface goes from source to destination to carray the data. 

In the context of monads, the IObservable interface, being in the direction of destination to source, is the one that is used by Bind. IObserable is then used to wire and initiate the IObserver interface in the opposite direction. This is exactly what we did earlier with the IMaybe push monad. 

////
It is possible for the source to not initiate the transfer on subscribe, and wait until it receives a separate event. As discussed above, this destination initiated data transfer paradigm appears to what we want for databases. However, with database queries, we need to pass request data in the push channel toward the database, and the Subscribe method can't do that. The only information it can take is timing information, that is 'when' to it wants the data. So it turns out that IObservable is not suitable for databases after all.

TBD look at IQueryable.
////

In the context of ALA, it is a disadvantage to combine the 'wiring' and the 'start transfer' in the same Subscribe method call. In ALA we keep these two things separate because we want the code for these two things to be in two separate places. The wiring code represents a user story and so goes in a user story abstraction in the top layer. We wire up the entire program first and then set it running. The starting of a data transfer is a run-time event. It originates in the same layer, for example, from a button domain abstraction that is wired to it. However, because this is the IObservable monad and not ALA, the Subscribe method will do both functions - the wiring of the observer and then starting a single data transfer. 

Another thing we will do, like we did for the deferred/push version of the Maybe monad, is compose Actions instead of Funcs. When an Action is called at runtime, it will be passed an object that implements IObserver. The action will use the IObserver to output directly instead of having a function that retirns an IObservable. This greatly simplifies the code in the Actions, which is what we want because these Actions are application code. Instead the Bind function will take on extra work. It needs to create an IObserver object to pass to the actions. 

If you look at the SelectMany in the reactive extensions library for C#, you will see that it takes a Func. But there are two overloads. In one, the Func returns an IObservable object as expected. For the other, it returns an IEnumerable. It's a shame that the second overload doesn't take an Action that takes an IObserver. That would have truly simplified things. Anyway that's what we will do in our example here.

Here is an action to use in our example applicaton:

[source,C#]
....
static void MutiplyBy10AndAdd1Then2Then3(int x, IObserver<int> observer)
{
    observer.OnNext(x * 10 + 1);
    observer.OnNext(x * 10 + 2);
    observer.OnNext(x * 10 + 3);
    observer.OnCompleted();
}
....

It takes a single integer as input and outputs a stream of three integers. The output goes to the IObserver that is also passed to the Action.


Here is our top layer application code.

[source,C#]
....
static void Application()
{
Observable.Create<int>(
    observer => {
        observer.OnNext(0); 
        observer.OnCompleted();
        return Disposable.Empty; 
    })
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Subscribe((x) => Console.Write($"{x} "),
                (ex) => Console.Write($"Exception {ex}"),
                () => Console.Write("Complete")
                );
}
....

We start with a single integer with value zero. We conver it to IObservable using the reactive extensions Observable.Create method. Then we can use Bind on that to compose the action. We do that using the same action for all three times. Finally we send the output to the Console. We use an overload of Subscribe that creates a destination object.

Now let's write the Monad's bind function. As usual, C# (in this case the reactive extensions library) provides us with a shortcut way to implement Bind by using Observable.Create and Observer.Create. This shortcut method obscures the way the Bind function is a refactoring of the imperative code, which is our purpose. However, for reference, here is the shortcut version first:


[source,C#]
....
static class ExtensionMethods
{

    public static IObservable<U> Bind<T, U>(this IObservable<T> source, Action<T, IObserver<U>> action)
    {
        return Observable.Create<U>(outputObserver => <1>
        {
            source.Subscribe( <2>
                x => { action(x, Observer.Create( <3>
                        value => outputObserver.OnNext(value), <4>
                        ex => outputObserver.OnError(ex), <4>
                        () => { } <4>
                    ));
                }, <5>
                ex => outputObserver.OnError(ex), <3>
                () => outputObserver.OnCompleted() <3>
            );
            return Disposable.Empty;
        });
    }
....

If you find this version hard to read, just skip forward to the next version.

<1> Bind must return an IObservable, so the first thing we do is create a new IObservable to be returned.
+
The Observable.Create method in the reactive extension library will create an object that implements IObservable. You pass it a Subscribe function. It does nothing more than create an object that implements IObservable, and uses the Subscribe method you gave it as the implementation of the IObservable. In this case we pass in a lambda (anonymous function) as the Subscribe method. 
+
Remember a Subscribe method is passed an IObserver, so that's the 'outputObserver' part of the lambda expression. The lambda expression takes up the entire rest of the code starting from 'outputObserver =>'. 

<2> When the Subscribe lambda expression gets called at runtime, it must subscribe to the source.

<3> In subscribing to the source, we supply three functions for the source to call, OnNext, OnError and OnCompleted. The OnError and OnCompleted are routed directly to the outputObserver. The OnNext is routed to the action.

<4> The action must in turn be given an observer for it to output to. Observer.Create creates an object that implements IObserver. You provide the three functions, OnNext, OnError, and OnCompleted that the IObserver interface needs. 
+
If the action outputs data it is passed directly to the outputObserver. If the action outputs an error, it too is passed directly to the outputObserver. But if the action outputs OnCompleted, it is discarded. This is ecause the monad must combine the streams from multiple calls of the action into a single stream. 

You may think we do not need the extra observer. Why not just pass outputObserver to the action like this:?


[source,C#]
....
x => action(x, outputObserver);
....

That would indeed correctly pass the multiple outputs of the action to the outputObserver. However, the action may call OnCompleted at the end of each of its sequences. If it does we need to intercept it and remove it because otherwise it will terminate the outputObservable sequence prematurely. This removal of the OnCompleted from the function's output is effectively what 'flattens' the output.

Removing the OnCompleted call is the reason we use Observer.Create(). 

Now we do a version that does not use either Observable.Create or Observer.Create. Although the code is longer, this will be easier to understand since our purpose is to show how we can refactor the original imperative code. This shows more clearly that the Bind function works by instantiating an object that will do all the work at runtime, and then simply wires that object to the previous one. 

[source,C#]
....
public static IObservable<U> Bind<T, U>(this IObservable<T> source, Action<T, IObserver<U>> action)
{
    return new Observable<T, U>(source, action);
}
....

The bind function simply instantiates an object from an explicit class called Observer. This class is listed below.


[source,C#]
....
private class Observable<T, U> : IObserver<T>, IObservable<U> <1>
{
    private readonly IObservable<T> source;
    private readonly Action<T, IObserver<U>> action;
    
    public Observable(IObservable<T> source, Action<T, IObserver<U>> action) { this.source = source; this.action = action; } <2>


    private IObserver<U> output;
    private InnerObserver<U> innerObserver;

    IDisposable IObservable<U>.Subscribe(IObserver<U> observer) <3>
    {
        output = observer;
        innerObserver = new InnerObserver<U>(output);
        source.Subscribe(this);
        return Disposable.Empty;
    }

    void IObserver<T>.OnCompleted() <4>
    {
        output.OnCompleted();
    }

    void IObserver<T>.OnError(Exception ex) <4>
    {
        output.OnError(ex);
    }

    void IObserver<T>.OnNext(T value) <5>
    {
        action(value, innerObserver);
    }
    
    // Observer that simply interceps OnCompleted
    private class InnerObserver<U> : IObserver<U> <6>
    {
        public Observable(IObserver<U> output) { this.output = output; }

        IObserver<U> output;

        void IObserver<U>.OnCompleted() { } // discard

        void IObserver<U>.OnError(Exception ex) { output.OnError(ex); }

        void IObserver<U>.OnNext(U value) { output.OnNext(value); }    
    }
}
....


<1> The objects of this class implement both IObserver and IObservable. IObserver allows the object to be used to subscribe to the source. IObservable allows the next object in the chain to subscribe to it.

<2> The class's constructor stores the source and the action.

<3> The class's Subscribe method saves the output observer. It also Subscribes this object to the source, which usually starts the transfer of data.

<4> The OnCompleted and OnError methods, (which are called by the source) simply pass through to the output observer.

<5> The OnNext method, (which is called by the source) calls the action, and passes it the InnerObserver object to output to. The InnerObserver passes OnNext and OnError through to the output, but discards any OnCompleted produced by the action. This discarding of OnCompleted from the action is what joins all the sequences produced by the calls to the action together.

<6> The InnerObserver's only function is to remove OnCompleted calls from the action getting to the output so that the sequences get joined. (Note: We could have used Observer.Create instead of having the InnerObserver class. However, we would have had to use Observer.Create in the OnNext method to get a new instance to pass to the action every time. This is because the observer object created by Observer.Create will stop working when it gets a OnCompleted.) The explicit InnerObserver class makes it a little clearer what is going on.



==== Mod360 monad

Finally, let's do a deferred version of the mod360 monad that we used as one of our original examples. You'll remember that we had imperative code that was doing mod 360 after every function call. We already did a simple immediate version of the monad. Let's skip the deferred/pull version and go straight to the deferred/push version. 

Here is a suitable interface for the monad:

[source,C#]
....
interface IMod360Observer
{
    void Push(Tuple<int,int> value);
}
....

Item0 in the Tuple is the angle, and Item1 in the tuple is the rotations.

And we will need a chaining interface for the Bind function to use:

[source,C#]
....
interface IMod360Observable
{
    void Subscribe(IMod360Observer observer);
}
....


Here is the application example code using the monad:

Application layer code
[source,C#]
....
var program = 42.ToMod360();
program.Bind(function1).Bind(function2).Bind(function3);

program.Run()
....


Here is the Bind function and ToMod360 function. Both use explicit classes to do the actual work. 

Monad layer code
[source,C#]
....
static class ExtensionMethods
{
    public static IMod360Observable ToMod360(this int value)
    {
        return new Mod360Start(value);
    }

    public static IMod360Observable Bind(this IMod360Observable source, Func<int,int> function)
    {
        var mod360 = new Mod360(function);
        source.Subscribe(mod360);
        return mod360;           
    }
}
....


The Bind function just instantiates a Mod360 class, configures it with the function being composed, and wires it to the previous object using the Subscribe method of its observable interface. The Subscribe method effects wiring in the opposite direction using the observer interface, which is needed because it is a push monad.

The class that does the work for the Bind function is below. It implements IMod360Observer for use by the previous object, and IMod360Observable for use by the next object.


[source,C#]
....
class Mod360 : IMod360Observer, IMod360Observable
{
    private Func<int,int> function;

    public Mod360(Func<int,int> function) { this.function = function; }


    private List<IMod360Observer> subscribers = new List<IMod360Observer>();

    void IMod360Observable.Subscribe(IMod360Observer observer)
    {
        subscribers.Add(observer);
    }


    void IMod360Observer.Push(Tuple<int,int> value)
    {
        int functonResult = function(value.Item1);
        Tuple<int,int> result = new Tuple<int,int> (
                functionResult mod 360,   // normalize the angle
                value.Item2 + functonResult/360) // count rotations
            );
        foreach (var subscriber in subscribers)
        {
            subscriber.Push(result);
        }
                
    }
}
....

The Observer.Push function does all the work at runtime. It first calls the composed function, and then creates a result Tuple using the source Tuple and the Tuple that is returned by the function.


This is the class used by ToMod360, which is straightforward.


[source,C#]
....
class Mod360Start : IMod360Observable
{
    private int value;
    public Mod360Start(int value) { this.value = value; }

    private List<IMod360Observer> subscribers = new List<IMod360Observer>();
    void IMod360Observabe<T>.Subscribe(IMod360Observer<T> subscriber)
    {
        subscribers.Add(subscriber);
    }

    public void Run()
    {
        foreach (var subscriber in subscribers)
        {
            subscriber.Push(new Tuple<int,int> {value,0});
        }
    }
}
....

Note that previously with the IObservable monad, the Subscribe method in the IObservable interface had two function, to wire the IObserver interface, and to start the data being pushed from the source. I kept that behaviour because that how reactive extensions works. However I prefer that push programming paradigms are true push style. 

So in this Mod360 monad, I have deliberately gone to a purely push paradigm. Calling the Subscribe method from the destination end does not intiate the dataflow. Instead I keep a reference to the source, which has a Run method. This makes an object structure that is more purely a push system, because the initaition of the dataflow is not done by a pull call from the destination end. This is much closer to how ALA works for its default programming paradigms. If you look at the top layer application code above, you will see that we kept a reference to the first object in the chain instead of the last. We called it program. To make the program run, we called program.Run().

That completes our four examples of refactoring imperative code using the monad refactoring pattern to defffered push versions of monads. We are now in a position to understand the general monad refactoring pattern.


==== The monad pattern

In the examples of Bind above, the type that Bind takes and returns is generally a class or interface. A class is like an interface with only one implementation, so we are generally going to think of it as an interface. We did have one example where it was an integer, and one where it was a Func, but these too can be thought of an interface in a broad sense.

The interface can be anything we want for the refactored code to communicate along the chain. It can be an actual interface, such as IEnumerable<T>, or IMaybe<T>, or it can be a class such as Task<T>. Or it can be a complex interface that we write to get any common information we want through the chain.

Bind always takes this interface and returns the same interface. You can therefore chain Bind calls together using fluent syntax (dot operator). 

The interface is usually generic, so takes a type as a parameter, e.g. Interface<T>. The Bind function takes an Interface<T> and returns an Interface<U>. So the generic type can change as it goes along the chain.

The pattern is about composing functions. These functions generally take a T and return an Interface<U>. 

Here is an application that composes three functions using a Bind function:

[source,C#]
....
var I4 = source
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....

When composing functions like this, you can't explicitly see the type of the interface that's being used. While debugging, I sometimes insert a decorator to write the type to the console like this:

[source,C#]
....
var I4 = source.PrintType()
    .Bind(function1).PrintType()
    .Bind(function2).PrintType()
    .Bind(function3).PrintType();
....


[source,C#]
....
public static T PrintType<T>(this T source) { Console.Writeline(typeof(T)); }
....

Here is pseudo code showing the actual types:

[source,C#]
....
Interface<T> I1 = source;
Interface<U> I2 = I1.Bind(func<T, Interface<U>>);
Interface<V> I3 = I2.Bind(func<U, Interface<V>>);
Interface<W> I4 = I3.Bind(func<V, Interface<W>>);
....

As you can see, while Bind always takes an interface and returns the same interface, the generic type may change along the way. In our examples above we didn't change the type much, but normally you can.

Here is a diagram of the monad pattern.


image::MonadPattern.png[MonadPattern.png, title=The monad pattern, link=images/MonadPattern.png]


As you can see, monads are a 2-layer pattern. The two layers correspond roughly with ALA's application and programming paradigms layers. The code that uses Bind to compose functions, and the lambda functions themselves are in the application layer. The Bind function and the Interface<T> are in the programming paradigms layer. Often monads come with a set of more specialized functions such as Sort, Filter and Sum. These would go in the equivalent of the domain abstractions layer. These functions either use Bind, or do the equivalent logic as Bind themselves.

The functions that are being composed take a T and return an Interface<U>. It is tempting to think that the Bind function simply returns the Interface<U> that is returned by the function, because they have the same type. But that is not usually the case. Bind usually creates a new object that implements Interface<U>, and then combines information from both the input Interface<T> and the output of the function to provide the output Interface<U>. That's what the diagram is trying to convey.

In many explanations of monads, they call the interface the _monad type_, or a _wrapped type_, or a _container type_, or a _type in a box_, or an _amplified type_, or just the notation _M T_. I don't think any of these terms are helpful in understaning monads. The _wrapped_, _container_ and _box_ terms don't work well for deferred monads, which don't actually contain a value. They contain a means of getting a value. For example, the deferred version of a list is IEnumerable. If our function returns an IEnumerable, that's not really a container or box.

The term _amplified_ just introduces another seemingly abstract concept which is unnecessary. And the term Monad type or the notation M T seems a bit circular - let's not explain monads in terms of monads. So I prefer to think of the thing that the Bind function takes and returns as simply a chaining interface. It sometimes has one implementation, such as Task or List, but often it has more than one implementation such as IMaybe or IEnumerable. Usually the Maybe monad uses IMaybe with two implementations, one for when there is a value and one for when there is no value. 

So generally I just think of it as _Interface<T>_.

The monad pattern requires three things: 
* an Interface<T> (the chaining interface)
* a constructor or method for making ordinary values of type T into an object that  implements Interface<T>
* a Bind function that takes an Interface<T>, returns an Interface<U>, and is passed a function of the form Func<T, Interface<U>>.

The constructor or method for getting ordinary values into Interface<T> form is required to get started at the beginning of a chain.

For push style monads, we didn't exactly follow this definition because the functions didn't always return the chaining interface, but they did something equivalent.

The chaining interface and the Bind function can pipe through any extra information or capability we want through the interface. We could, for the sake of a silly example, pipe through an audio stream if we really wanted to. We could compose functions to modify the stream.

===== SelectMany vs Select

The LINQ opertors such as Select and SelectMany use IEnumerable as their _chaining interface_ - they take an IEnumerable and return an IEnumerable. This allows them to be composed in chains using dot operators.  

Select is like Map. It takes a function that maps inputs to outputs in one to one correspondence. Aggregating operators such as Sum produce a single output from many inputs. SelectMany is the opposite - it produces many outputs from a single input.  

Select is probably the most common operator used in LINQ statements. So why is SelectMany the fundamental Bind operator of the IEnumerable monad and not Select?

It's because SelectMany is the one that strictly fits the monad pattern as described in the previous section. For a monad, the function being composed generally returns the same interface as the _chaining interface_. SelectMany is the one that does that. Select takes a function that returns a value, not an interface. 

So while we sometimes think of the whole LINQ library as being monadic, strictly speaking only SelectMany is part of the monad.  



===== Summary of monad benefits.

* Monads allow us to simply compose functions declaratively in the top layer to implement a user story. How everything executes is handled by the Bind function in a more abstract lower layer.

* The declarative code in the top layer is a different programming paradigm from imperative. It's called dataflow, because we are directly composing a flow of data from functon to function, irrespective of how the underlying execution will work.

* Monads make it possible for the application code to concentrate on expressing user stories, and not be concerned with execution details.  

* Monads take care of passing data from function to function, without the application layer code needing to handle it.

* We can compose as many functions as we like in chains of arbitrary length without any nesting of brackets or indenting.

* The execution code in the Bind function can handle many different cases of logic that would otherwise have been messy imperative code between function calls.

* Monads make it possible for application code itself to be pure functional code, even though the structure of connected objects that is built is not. 

* The application code examples that use the deferred versions of Bind look much the same as the immediate versions. That's because at the application level, we are still just declaratively composing functions. 

* We prefer to implement deferred versions of Bind because then we have the option of executing them straight away as if it was immediate, or use them as part of a larger program for later execution. 

* Deferred monads make it possible to separate all code that expresses user stories from code that implements computing details.


=== ALA compared to monads

Now that we have an understanding of monads, and deferred/push monads in particular, we are in a position to compare them with ALA.

* In the application layer, monads compose functions whereas ALA composes objects with ports.

* Composing functions is a dataflow programming paradigm, whereas composing objects with ports is a multi programming paradigm.

* Composing functions creates mostly a chain structure whereas composing objects with ports creates an arbitrary network structure. Monads _can_ form networks as when two streams are merged, but in practice most functions have a single input and single output.

* Both deferred monads and ALA build a structure of objects which is subsequently executed in a second phase. This separates declarative application code from execution model code.

* Both monads and ALA use pure functional code for the application code in the top layer. In this respect ALA and monads achieve the same job by putting the dirty computational work inside a pre-written Bind function in the case of monads or classes in the case of ALA. This dirty work can include private state and I/O side-effects.

* ALA's domain abstraction objects are more versatile than functions because they can more naturally have many ports, and the ports can use different programming paradigms. This allows for abstractions suitable for composing all aspects of user stories, such as UI, schema, business rules, etc.
+
For example, you can have a single domain abstraction with a UI port (to be attached somewhere in the UI) multiple event driven ports (for mouse clicks) and a dataflow port (for binding to a data source).

* Dataflow ports can each use either push or pull as appropriate in each particular case, whereas monads tend to encourage you to use only one type or the other as a programming style, e.g. LINQ or reactive extensions. 

* 'Push' dataflow interfaces can be used for either synchronous or asynchronous dataflows. So in ALA we default to using push style dataflows unless 'pull' has a particular advantage in a particular case. This allows instances of abstractions to be wired either synchronously or asynchronously. In other words the choice of synchronous or asynchronous is deferred until the application user stories are written. Asynchronous can be chosen, for example, when two instances of abstractions will communicate over a network, or on differnt threads, and synchronous can be chosen when the user story knows that the two will always communicate on the same thread.
+
'Push' style dataflows (reactive extensions) appear to be less popular in the industry. I don't understand why. Perhaps it's because the IObservable interface isn't a true push style since the destination usually starts the flow of data by Subscribing (cold observables)? This mix of pull and push behaviour in the IObservable/IObserver pair is confusing and not easily amenable to network or miltithreaded systems that would otherwise suit push programming paradigms. Hot observables do not need the pull to initiate the data flow, but they have to avoid using both OnCompleted and OnError, otherwise the whole chain must be resubscribed. So they don't use the full benefits of the IObserver interface.

* ALA programming paradigms, which are usually interfaces, are analogous to monad chaining interfaces. ALA programming paradigm interfaces can use any of the chaining interfaces such as IMaybe, IEnumerable, or Task or futures. 

* A monad's Bind function is partially analogous to ALA's WireTo function, because it implements the wiring. However the Bind function is different for every different monad type because it includes the deferred, run-time, common, execution code of the monad. ALA's WireTo function only does the wiring. It does not normally include any common run-time code, although it can sometimes be overridden to do special wiring. Instead, in ALA, that common code goes into the programming paradigm, which may use intermediary objects. WireTo is generally the same WireTo for all programming paradigms and therefore all wiring up of an entire application is done using it.

* Monads usually use deferred execution and ALA always uses deferred execution, so in this respect they are similar. Both build an object structure which you then run after the wiring up is completed. They both have two phases, the wiring up phase and the run-time execution phase. However, in ALA, we always separate out all the wiring code for the entire application and then set the whole application running. Deferred monads are often wired up as short chains and then executed in the same code statement or nearby.
+
By building the entire application first, ALA completely separates code into a top layer at the abstraction level of specific user stories, and a second layer that consists of domain abstractions that contain all the code that executes at run-time. In this way the top layer has _all_ the declarative code that expresses the application and the second layer has _all_ the imperative code that knows how to do general computation work at runtime.

* ALA's application layer corresponds loosely with functional code that composes functions. ALA's programming paradigms correspond loosely with Bind functions. And ALA domain abstractions correspond loosely with the set of methods that generally come with a monad library such as Select or Where.


==== Composing with plain objects instead of functions.

By using plain objects the barrier to understanding seems lower than for monads, at least for developers already familiar with objects. Functional programming, and monads in particular, seem to have quite a high barrier to entry unless you are a mathematician. The world needs the programmers who are able to understand objects but do not necessarily understand mathematical notation. I'm not sure what would happen if all universities only taught functional programming so that everyone is introduced to pure functions first. Perhaps then it would be objects which have a barrier to entry. 

ALA's domain abstraction objects are easier to understand than monads because they are plain objects. The mental model of composition in ALA is wiring instances of  domain abstractions by their ports, which is conceptually just a component model. Monads compose functions so the mental model is primarily oriented to composing a chain of functions as a dataflow. To make an analogy with electronics, ALA is like composing ICs (integrated circuits with many pins with many functions) and monads is more like composing two-port components such as resistors, capacitors, inductors and transistors.

There seems to exist computing problems that are best described using state. Objects are the language feature that provides for this. Monads end up using objects with state anyway - they are just hidden beneath the covers. 

The only slightly difference between ALA's domain abstraction objects and plain object oriented objects is the use of _ports_. Port are used for all run-time input and outputs. Any programmer with familiarity with dependency injection can understand that a port is just an implementiion of dependency injection. A _port_ is implemented simply as a field of the type of an interface, or is an implemented interface. As with normal dependency injection, the field is assigned a reference to another object that implements the port interface. 

Unlike conventional dependency injection, the field is not assigned by the constructor or any setters. Instead the field is always assigned through use of WireTo or WireIn. 

The difference between ALA and conventional dependency injection is that the interface used must be more abstract than either of the classes. It cannot be thought of as an abstract base class. It is even more polymorphic than that. This type of interface is called a programming paradigm, and can be implemented by many disparate classes. Therefore, the dependency injection cannot be container based. Instead the application code must explicitly instantiate the required objects and then wire them together.

Because ALA uses plain objects, and plain interfaces as their ports, ALA developers can add new domain abstractions and programming paradigms themselves. In the functional world, developers can certainly write new monad types, but it doesn't seem that easy, and seems generally left to library developers. The abstraction level of these libraries is therefore generally not as close to the domain, and does not make a DSL. In ALA, the set of domain abstractions and programming paradigms that you write is a DSL.


==== ALA vs monad syntax

Although ALA supports multiple programming paradigms, the dataflow programming paradigm is quite a common one. So we will have many domain abstractions like those that come with monad libraries like Select, Where and Sum. It is worth comparing the syntax of ALA using dataflows with monad syntax.

Here we are comparing the code in the top layer, the code that describes a user story. Both monads and ALA use fluent style with dot operators.Here is the syntax for monads: 

[source,C#]
....
source.Filter(x=>x>=0).Select(x=>sqrt(x))
....

And here is the syntax for ALA:

[source,C#]
....
source.WireIn(new Filter<int,bool>(x=>x>=0)).WireIn(new Select<int,int>(x=>sqrt(x))
....

In the monad version, the Filter and Select functions do both the wiring and specify the operation to be wired, whereas in the ALA version these are kept separate. Keeping them separate has advantages that we will discuss shortly.

The ALA code can be generated from a diagram. However, there is nothing stopping us achieving exactly the same syntax as the monad version if we really want to. We just create extension methods that both create an instance of, and wire up, each abstraction such as Select and Filter:


// in Select.c
[source,C#]
....
namespace DomainAbstractions
{
    static class ExtensionMethods
    {
        public static IChainable Select<T, U>(this IChainable source, Func<T,U> function)
        {
            var select = new Select<T, U>(function);
            source.WireIn(select);
            return select;
        }
    }
}
....


// in Filter.c
[source,C#]
....
namespace DomainAbstractions
{
    {
        public static IChainable Filter<T>(this IChainable source, Func<T,T> function)
        {
            var filter = new Filter<T>(function);
            source.WireIn(filter);
            return filter;
        }
    }
}
....

The code for these extension methods would be located in the same abstractions as the Select and Filter classes respectively.

Note that IDataFlow is the type of the ports being wired. IDataflow is a push interface (similar to IObserver). So IDataFlow goes in the forward direction (the same direction as the data flows). The Select and Filter extension methods can't be defined on IDataFlow. We need an interface on which to define Select and Filter. This interface must go in the reverse direction, from destination to source. So that's what IChainable is for. IDataFlow and IChainable are analogous to the IObserver and IObservable interfaces respectively. Note, though, that IChainable only exists to give us an interface on which to define the extension methods. It doesn't do anything else, so it contains no methods:

[source,C#]
....
interface IChainable {}
....

It doesn't have a Subscribe method because the Select and Filter extension methods did the wiring up of the IDataFlow ports of the instances of the abstractions.

 Note: normally IChainable would have a type parameter: IChainable<T>. That would allow type inference to be used for the type parameter of methods that are defined on it such as Select<T,U> and Filter<T>, etc. However, the compiler can't always successfully use type inference for that second type parameter, U. It can if the second parameter passed to Select is a function that returns a certain type. But it can't if the second parameter is an action, which is the case for the ObserverPushAction domain abstraction. Therefore I have removed the type parameters from IChainable so that its less confusing, and Select etc will always need to have its types passed in explicitly.


////

===  Monads (old, needs review)

==== Monad syntax


Let's assume for the ALA case, that the instanceB being wired converts objects from one type to another, the same as a function binded to monad does. So in both cases, we have a source of TAs and we want to wire in an operation that will convert them to TBs. 

Both bind and WireIn have an object as their first argument. That object is the source for TAs. Both bind and WireIn can be written using the dot operator style:

.Monad wiring code
[source,C#]
....
objectA.bind(...)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(...) 
....


_bind_ and _WireIn_ are different in their second argument. _bind_ requires a function whereas WireIn requires an object. The function takes a TA and returns an MTB (a TB wrapped in a monad container). The object has an input port of type TA and an output port of type TB.

.Monad wiring code
[source,C#]
....
monadA.bind((a)=>(func<TA,Monad<TB>>)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(instanceB) 
....


In the monad case, the bind function returns a new monad object. 
In the ALA case, the WireIn function returns instanceB.
Therefore, in both cases you can now chain additional operators using fluent style:

.Monad wiring code
[source,C#]
....
monadA.bind(func<TA,Monad<TB>>).bind(...)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(instanceB).WireIn(...)
....

In the monad version, we often want to specify the function to return a TB instead of a Monad containing a TB. That is what Select is for in C#. Select uses bind under the covers but does the wrapping of the TB into a monad for you:

.Monad wiring code
[source,C#]
....
monadA.Select(func<TA,TB>)
....

In the ALA case, we will usually use a prexisting domain abstraction to perform the operation. For example, we might use the domain abstraction OffsetAndScale. This allows code to generally be inside domain abstractions layer, and only configuration constants (that come directly from requirements) to be in the application layer. But to get closer to the same problem that monads solve, let's assume we have no domain abstraction that does what we need, and we really do want to specify the mapping function in the application layer right in amongst the wiring. In other words we want a domain abstraction that is configured with a lambda function. In this case we can invent a domain abstraction called Lambda which takes a lambda function when it is constructed: 

.ALA wiring code
[source,C#]
....
instanceA.WireIn(new Lambda<TA,TB>(funct<TA,TB>))
....


Just as _Select_ is a more specialized version of bind that changes the type, _Where_ is also a more specialized version that removes records from the stream. It requires a predicate function that returns a bool:

.Monad wiring code
[source,C#]
....
monadA.Where(funct<TA,bool>)
....

.ALA wiring code
[source,C#]
....
instanceA.WireIn(new Where<TA>(funct<TA,bool>))
....


You can see that the ALA syntax for solving this particular problems is now more verbose. It requires the additional use of WireIn and the _new_ keyword. The tradeoff for the extra words is versatility. We could consider using the less verbose Monad syntax for all ALA wiring. What would we lose if we did that:

For example:

.ALA wiring code
[source,C#]
....
    adc.WireIn(new LowPassFilter(10)).WireIn(new OffsetAndScale(0,0.5));
....


.consider monad style ALA wiring code
[source,C#]
....
    adc.LowPassFilter(10).OffsetAndScale(0,0.5);
....

To accomplish this syntax, we would have to provide methods with the same names as the domain abstractions. These methods would perform the new operation and then the wiring operation.

We would briefly consider defining these methods directly on the domain abstractions such as ADC, but that would pollute ADC with knowledge of LowPassFilter. Since there are many ways of wiring things, every abstraction would need methods for every other abstraction to which it could be wired. That would be ridiculous. 

Instead we might make every domain abstraction implement an _IWireable_ interface. I think this inerface would be empty. Then all the wiring methods would be extension methods on _IWireable_. They would all return an _IWireable_ ready for fluently calling the next wiring method. Now the code for ALA would look like:

[source,C#]
....
    (adc as IWireable).LowPassFilter(10).OffsetAndScale(0,0.5);
....

which is pretty much the same as the Monad code.


The methods would be fairly simple:

[source,C#]
....
static class LowPassFilterExtensonMethod
{
    static IWireable LowPassFilter(this IWireable instanceA, int strength)
    {
        return instanceA.WireIn(new LowPassFilter(strength));
    }
}    
....


Note that IWireable is kind of analogous to IEnumerable in the monad examples we have been looking at. We give it the more abstract name _IWireable_ because domain abstractions can have more than one output port, and we could be wiring any one of them, whereas monads generally only have one output such as IEnumerable.
////

In ALA we keep the WireIn and new operators separate for the following reasons:

* In ALA, Domain abstractions are generally at a slightly more specific level of abstraction than monad library functions (specific to the domain to support the construction of user stories). So, domain abstractions are written by the application developer much more frequently than new monads are written. They are extremely simple to write once the concept of ports is understood, because the ports make them zero coupled with one another and with the application layer above. The only difference from plain classes is that you have to know that input ports must use implemented interfaces from the programming paradigms layer, and output ports must be plain private fields of the types of these same interfaces. We don't want the extra burden of adding a corresponding extension method.

* In ALA we can choose between WireIn and WireTo depending on whether we want to chain instances of abstractions or do fanout wiring. Monad library functions alway return the next object in the chain, so only naturally wire up chains.

* The mental model of components with ports that you explicitly wire up is more versatile than the mental model of composing functions as a dataflow chain. Functions can be thought of as have multiple ports, for example the merge function can have two input streams, but the fluent syntax of combining monadic functions does not suit it.

* Composing monad functions is only a dataflow programming paradigm. In ALA many diverse programming paradigms can be used. The diverse programming paradigms represent different meanings of composition. For example, we can compose the UI. The code below puts a Button, TextBox and Grid inside a window.  
+
.ALA wiring code
[source,C#]
....
    window.WireTo(new Button().WireIn(...))
          .WireTo(new TextBox().WireIn(...))
          .WireTo(new Grid().WireIn(new DynamicDataSource().WireTo(...)));
....
+
The button can be further wired using an event driven programming paradigm. The Textbox can be further wired to its data using dataflow. The Grid can be wired using a dynamic dataflow programming paradigm to a dynamic data source, which could itself be wired using a schema programming paradigm.

* Deferred monads look like operations on data, but obscure the fact that they build a structure of objects for later execution. This is confusing until you get used to it. The _WireTo_ and _WireIn_ operators together with the _new_ operator make it explicit that you are building a structure of objects as a program that you can then set running.  

* Because domain abstractions can have multiple ports, _WireIn_ and _WireTo_ allows us to specify which port we want to wire when it could be ambiguous.

* Inherent in the requirements of a typical application is really a network of relationships. This network is often best represented by a diagram. Explicit WireIn and WireTo operators allow us to directly translate a diagram to code. Also, diagramming tool can automatically generate the wiring code containing using _WireTo_ and _new_.



=== Using monads in an ALA application
 
Although composing with objects is generally more versatile than composing with functions, if you already have a monad library containing functions such as SelectMany, Select, Where, Sort, Aggregate, etc, we would certainly want to make use of it in ALA applications. There would be no sense in reinventing that functionality as 2-port classes. You can use the monad library for some dataflow parts of the program.

In this section we discuss two methods to use monads within an ALA application: 

. The first method is to use IObservable as the interface for some of the ports of your domain abstractions. Then two instances of these domain abstractions can be wired with a reactive extension expression inbetween. Although n IEnumerabe version is possible, we will only show an example using the IObservable interface because that is more compatible with how ALA programming paradigms gnerally work (push by default). We will give examples for both static and dynamic type dataflows.

. The second method is to write a general purpose domain abstraction that can be configured with a monad expression. The domain abstraction has input and output ports using ALA's DataFlow interface.  We will do both an IEnumerable and an IObservable version of this domain abstraction.


==== Domain abstractions with IObservable ports

===== Statically typed 

The first way to use monads with ALA is to use the chaining interface, such as IObservable, for the ports on some domain abstractions. For example, we could have a domain abstraction for a CSV file reader that has an output port of type IObservable<DataType>. Then we can have a domain abstraction called ObservableToSerial that has an input port of type IObservable. 

We can then wire there two end instances via some _.Where_ or _.Select_ functions inbetween using monad functions that already exist in the reactive extension library. Here is some example application code:

[source,C#]
....
class Program
{

    static void Main()
    {
        var outputer = <6>
        ((IObservable<DataType>)new CSVFileReaderWriter<DataType>() { FilePath = "DataFile1.txt" }) <1>
        .Select(x => new { Firstname = x.Name.SubWord(0), Number = x.Number+1 } ) <3>
        .Where(x => x.Number>48) <4>
        .WireInR<T>(new ObservableToSerial<T>(Console.Writeline)); <5>
    
        var program = new StartEvent().WireTo(outputer); <7>
        program.Run(); <8>
    }

    private class DataType <2>
    {
        public string Name { get; set; }
        public int Number { get; set; }
    }
}
....

<1> We start the chain by instantiating a CSVFileReaderWriter and providing it with a filepath. 

<2> We also give CSVFileReadWriter a type, DataType, which corresponds with the fields in the CSV file we are going to read. (This is not a dynamic CSV file, so we are going to do this program completely with compile-time type checking using type inference.)

The CSVFileReaderWriter domain abstraction can have multiple output ports of different types, but the one we are going to wire is an IObservable<DataType>. CSVFileReaderWriter implements this interface. To specify which port we are wiring we simply cast the CSVFileReaderWriter to IObservable<DataType>. It's a shame we had to have DataType appear twice in the program.

<3> We wire the CSVFileReaderWriter's IObservable port to a _Select_ function. Like a monad, _Select_ returns another IObservable, with a different type. The compiler can use type inference to generate this type. 

<4> We wire the output of Select to a _Where_ function. _Where_ returns yet another IObservable with a type using type inference.

<5> We wire the output of _Where_ to a new domain abstraction called ObservableToSerial. (The type inference doesn't work here, but we will fix that soon.)

<6> We store the ObservableToSerial in a local variable called outputer because we need to wire to it in another place. 

<7> outputer has an IEvent input port which is used to start the transfer. With IObervables, the data transfer is started from the destination end. We wire a StartEvent domain abstraction to the outputer. StartEvent has an IEvent output port and can be used to set a program running. We store the StartEvent in a variable called program.

<9) To start the program running we call program.Run(), which is a method in the StartEvent.

The line labelled 5 in the listing doesn't compile. It's what we would like to have written to get the type inferencing working starting from the CSVFileReaderWriter right through to the outputer. The reason it doesn't compile is that _new ObservableToSerial<T>_ needs a type to be specified for T. The WireInR<T> knows the type from its _this_ parameter. But you can't get the compiler to transfer that type to the second parameter of WireInR, the _new ObservableToSerial<T>_.

The solution is to use an extension method to do the WireInR and the _new ObservableToSerial<T>_. Here is a suitable extension method:

[source,C#]
....
public static ObservableToSerial<T> ToConsole<T>(this IObservable<T> observable) where T : class 
{ 
    var o = new ObservableToSerial<T>(Console.WriteLine); 
    observable.WireInR(o);
    return o; 
}
....

Using this extension method, here is the application again:


[source,C#]
....
    static void Application()
    {
        var outputer = 
        ((IObservable<DataType>)new CSVFileReaderWriter<DataType>() { FilePath = "DataFile1.txt" })
        .Select(x => new { Firstname = x.Name.SubWord(0), Number = x.Number + 1 })
        .Where(x => x.Number > 48)
        .ToConsole();

        var program = new StartEvent().WireTo(outputer);
        program.Run();
    }
}
....

Type inference now works all the way through the dataflow chain. We only had to specify the type of the data in the CSV file. 


===== Dynamically typed

This next example does the same functionaility as the previous example, that is demonstrating mixed use of domain abstractions with IObservable ports and reactive extension monads. However, this time it does not statically define the data type at compile-time. In other words, it makes no assumptions about the data schema in the CSV file. Instead, it determines everything at run-time. If any code tries to access specific data that doesn't exist or has the wrong type, run-time exceptions are thrown rather than compiler errors.

Since the CSV file is now considered dynamic, it has two header lines, one to name the columns and one that defines the types of the columns. Knowledge about these header lines is contained in the CSVFileReaderWriter abstraction. The first half of the code writes some data to the CSV file to ensure header lines are created.


[source,C#]
....
static void Application()
{
    var csvrw = new CSVFileReaderWriter() { FilePath = "DataFile2.txt" }; <1>
    
    // First write some data to the file
    
    IObserverPush<ExpandoObject> writer = csvrw; // writer port <2>
    writer.OnStart(); <3>

    dynamic eo = new ExpandoObject(); <4>
    eo.Number = 47; <5>
    eo.Name = "Jack Up";
    writer.OnNext(eo); <6>

    eo.Number = 48; <7>
    eo.Name = "Wynn Takeall";
    writer.OnNext(eo);

    eo.Number = 49;
    eo.Name = "Rich Busted";
    writer.OnNext(eo);

    writer.OnCompleted(); <8>

    // Now wire the output port of the CSVFileReaderWriter via a Select and a Where to an outputter.

    var outputer = new ObservableToSerial<ExpandoObject>(Console.WriteLine); <9><10>

    ((IObservable<dynamic>)csvrw)  <11>
        .Select(x => new { Firstname = ((string)x.Name).SubWord(0), Number = x.Number + 1 })
        .Where(x => x.Number > 48)
        .WireInR(outputer);

    var program = new StartEvent().WireTo(outputer); <12>
    program.Run(); <13>
}
....

<1> First we instantiate a CSVFileReaderWriter domain abstraction. Notice how this abstraction is not generic like we had before. Instead its ports use the ExpandoObject class.

<2> Get a reference to the input port of the CSVFileReaderWriter. This input port has type IObserverPush<ExpandoObject>. The IObserverPush programming paradigm is like IDataFlow, but can handle batches of data:
+
[source,C#]
....
interface IObserverPush<T> : IObserver<T>
{
    void OnStart();
}
....
+
As you can see it is a standalone version of IObserver. It doesn't need a corrsposnding IObservable interface. It operates by itself. It is explained in detail later.


<3> Calling OnStart on the input port causes CSVFileReaderWriter to create a new file.

<4> Create a temporary ExpandoObject. This is a usefull class when using dynamic typing which can have properties added at run-time.

<5> Add fields to the ExpandoObject.

<6> Give the ExpandoObject to the input port of the CSVFileReaderWriter, which will write the data to the CSV file.

<7> Write more records in the same way.

<8> Complete writing the CSV file.

<9> Instantiate an ObservableToSerial for the end of the chain. ObservableToSerial has an IEvent input port called trigger that is used each time we want the program to go (by subscribing to its data source). 

<10> Configure the ObservableToSerial to output to the console.

<11> Wire the chain up starting from the CSVFileReaderWriter through to the ObservableToSerial via two LINQ operators. IObservable ports are used the whole way. The IObservable output port of the CSVFileReaderWriter is selected by the cast.
+
One unusual thing you may notice about this ALA program is the use of WireInR instead of WireIn that we would normally use to wire things in a chain. A.WireInR(new B()) actually wires in the reverse direction from normal, that is from B to A. You use it like you would use WireIn, in the same direction as the dataflow, but it actually wires in the opposite direction. This is because IObservable, the programming paradigm interface being used, must be wired in the opposite direction as the dataflow, like a _pull_ interface. The A object implements IObservable and the B object has a field of type IObservable. So the wiring must go in the reverse direction of the data flow. WireInR is implemented simply as WireInR(this object A, object B) {WireIn(B, A);}  

<12> Wire an instance of a StartEvent to the ObservableToSerial _Trigger_ input port. 

<13> Make the program run by telling the StartEvent to output an event.




==== Domain abstraction configured with monads  

This is the second method of using monads in an ALA application.

It uses a domain abstraction that can be configured with a monad expression. This domain abstraction uses your normal ALA dataflow programming paradigm forits its input and output ports. We will do two versions, one configured with an IEnumerable chain and one configured with an IObservable chain.

===== Configuring with IEnumerable monads


Let's call the domain abstraction EnumerableQuery. You configure an instance of EnumerableQuery with a LINQ expression.  

Here is an example program using EnumerableQuery. EnumerableQuery uses IDataFlow as the programming paradigm for its ports. We chain up three of them and configure them all with a similar query:

[source,C#]
....
static void Application()
{
    var proxySource1 = new EnumerableProxySource<int>(); <1>
    var query1 = proxySource1.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 1); <2>
    var proxySource2 = new EnumerableProxySource<int>(); <1>
    var query2 = proxySource2.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 2); <2>
    var proxySource3 = new EnumerableProxySource<int>(); <1>
    var query3 = proxySource3.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 3); <2>

    var userStory = new StartEvent(); <3>
    userStory
    .WireIn(new ValueToDataFlow<int>(0)) <4>
    .WireIn(new EnumerableQuery<int, int>(proxySource1, query1) { instanceName = "Query1" }) <5>
    .WireIn(new EnumerableQuery<int, int>(proxySource2, query2) { instanceName = "Query2" }) <6>
    .WireIn(new EnumerableQuery<int, int>(proxySource3, query3) { instanceName = "Query3" })
    .WireIn(new DataFlowToSerial<int>(Console.Write)); <7>

    userStory.Run(); <8>
}
....

<1> To build a LINQ expression, you need to start with a source that implements IEnumerable. Since we don't have an actual source, we will use a proxy for the source. That's what the EnumerableProxySource is.

<2> An example LINQ expression consisting of a SelectMany and a Select.

<3> Instantiate a StartEvent domain abstraction, which we will use to tell the user story to run.

<4> Instantaite a domain abstraction that represents a simple scalar value and will output that value to its output IDataFlow port when told to by its IEvent input port.

<5> Wire in the first of the three EnumerableQuery domain abstractions. EnumerbaleQuery has an input IDataFlow port and an output IDataFlow port. Configure it with the LINQ expression. To do that we give it both the proxySource object and the LINQ expression object. EnumerableQuery will receive data pushed to its input port, apply the LINQ expression to it, and push the result out its output port.

<6> We chain up three of the EnumberableQuerys to demonstrate normal ALA wiring up of this abstraction. 

<7> We wire the final output to the console using an instance of a DataFlowToSerial domain abstraction configured to give its serial stream to the Console.

<8> Tell the user story to run.

Here is the output of the program:

image::ConsoleOutputListMonad.png[ConsoleOutputListMonad.png, title="Output of demo code using EnumerableQuery domain abstraction", link=images/ConsoleOutputListMonad.png]

The initial value of zero expands to 27 numbers because of the SelectMany in each of the LINQ expressions.

Internally, what EnumerableQuery does is every time an input data arrives, it executes a foreach on the query. When the query asks for for data from the proxySource, the proxySource returns the data that came into the input port. 

Here is the EnumerableQuery domain abstraction: 

[source,C#]
....
class EnumerableQuery<T, U> : IDataFlow<T>  // input port <1>
{
    private readonly EnumerableProxySource<T> proxySource;
    private readonly IEnumerable<U> query;
    
    public EnumerableQuery(EnumerableProxySource<T> proxySource, IEnumerable<U> query) { this.proxySource = proxySource; this.query = query; proxySource.Enumerable = getIEnumerableForInputData(); } <3>

    private IDataFlow<U> output;  // output port <2>

    private T inputData; 

    private IEnumerable<T> getIEnumerableForInputData() <4>
    {
        yield return inputData;
    }


    void IDataFlow<T>.Push(T data) <5>
    {
        this.inputData = data;
        foreach (var x in query) output?.Push(x);
    }
}
....

<1> The input port is an IDataFlow<T>

<2> The output port is an IDataFlow<T>

<3> The constructor takes a LINQ expression (both its proxySource object and the query itself) and saves them to local variables. The constructor also sets up proxySource to get its data from an IEnumerable.

<4> The IEnumerable is returned by getIEnumerableForInputData. This IEnumerable simply returns the data that has come in on the input port. The IEnumerable is implemented with a method that contains a yield return.

<5> The implementation of the input port is what drives the domain abstraction. It first saves the incoming data so that the query can use it as its source, then enumerates the LINQ query. The results are given to the output port.

The code above can be found in a working example program on Github in the IEnumerableMonad repository here: https://github.com/johnspray74[https://github.com/johnspray74]




===== Configuring with IObservable monads

In the previous example, we created a domain abstraction that can be configured with a LINQ query. In this next example, we create a domain abstraction that can be configured using reactive extensions.

When all else is equal, I prefer reactive extensions over LINQ because it can do asynchronous and synchronous. 

We could have done this example using IDataFlow ports just as we did in the previous example. However, the IObserverPush programming paradigm that we briefly introduced earlier is more appropriate. IDataflow handles an open-ended stream of data, whereas IObserverPush can handle open-ended batches of data. 

Here is a user story example of using this domain abstraction. 


[source,C#]
....
    static void Application()
    {
        var subject1 = new Subject<int>(); <1>
        var query1 = subject1.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 1); <2>
        var subject2 = new Subject<int>();
        var query2 = subject2.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 2);
        var subject3 = new Subject<int>();
        var query3 = subject3.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 3);

        var userStory = new StartEvent(); <3>
        userStory
        .WireIn(new ValueToObserverPush<int>(0)) <4>
        .WireIn(new ObservableQuery<int, int>(subject1, query1)) <5>
        .WireIn(new ObservableQuery<int, int>(subject2, query2))
        .WireIn(new ObservableQuery<int, int>(subject3, query3))
        .WireIn(new ObserverPushToSerial<int>(Console.Write)); <6>

        userStory.Run(); <7>
    }


    static IObservable<int> MutiplyBy10AndAdd1Then2Then3(int x) <8>
    {
        return Observable.Create<int>(observer =>
        {
            observer.OnNext(x * 10 + 1);
            observer.OnNext(x * 10 + 2);
            observer.OnNext(x * 10 + 3);
            observer.OnCompleted();
            return Disposable.Empty;
        });
    }
....

<1> First we need a proxy source object that implements IObservable on which to build our reactive extensions expression. The RX library provides a suitable class that we can use for this called Subject. 

<2> Create the RX expression consisting of a SelectMany and a Select.

<3> The user story will consist of three ObServableQuerys wired up in a chain. Data transfers are intitaited at the source. So we instantiate a StartEvent domain abstraction to give us a way of starting (or restarting) the dataflow.

<4> The StartEvent instance is wired to the start port of an instance of ValueToObserverPush using an IEvent programming paradigm. ValueToObserverPush is a simple domain abstraction that is configured with a single value. It has an IObserverPush output, and will output its value when it gets a signal on its start port.

<5> The ValueToObserverPush is wired to an ObservableQuery using the IObserverPush programming paradigm. ObservableQuery is configured with an RX expression. Both the subject and the expression itself must be passed in. 

<6> After the three ObservableQuerys are wired, the output is wired to an instance of ObServerPushToSerial, where it is converted to text to be displayed on the Console.

<7> Now that the user story is all wired up, we can run it. It can be run more than once.

<8> The function passed to the SelectMany is implemented using the Observable.Create method, which is a convenient way to do it for our purposes here.



Here is the code for ObServableQuery:

[source,C#]
....
class ObservableQuery<T, U> : IObserverPush<T>  // input port <1>
{
    private readonly Subject<T> queryFrontEnd;
    private readonly IObservable<U> query;
    public ObservableQuery(Subject<T> queryFrontEnd, IObservable<U> query) { this.queryFrontEnd = queryFrontEnd; this.query = query; } <3>

    private IObserverPush<U> output;  // output port <2>


    private IDisposable subscription = null;

    void IObserverPush<T>.OnStart() <4>
    {
        output.OnStart(); <5>
        subscription?.Dispose(); <7>
        subscription = query.Subscribe( <6>
            (data) => output.OnNext(data),     
            (ex) => { output.OnError(ex); terminated = true; }
            () => output.OnCompleted());
    }

    void IObserver<T>.OnNext(T data) <8>
    {
        queryFrontEnd.OnNext(data);
    }

    void IObserver<T>.OnError(Exception ex) <9>
    {
        queryFronEnd output.OnError(ex);
    }

    void IObserver<T>.OnCompleted() <10>
    {
        queryFronEnd.OnCompleted();
    }

}
....

<1> The input port is an IObserverPush

<2> The output port is an IObserverPush

<3> The constructor configures the domain abstraction with an IObservable expression. Both the front end Subject object and the RX expression object itself are passed in. These are saved as local variables.

<4> An OnStart call prepares for a new batch of data.

<5> The OnStart signal is propagated to the output port so it goes right through the chain to prepare the entire chain for the data sequence.

<6> The query that we were configured with is subscribed to.  This does not cause data to flow from the RX expression yet. Outputs from the RX expression are routed directly to the domain abstraction's output port. The subscribe must be done here rather than in the constructor because if OnStart is called again for a subsequent batch of data, Subscribing needs to be done again to 'reset' the RX expression if it had completed.

<7> If the query had previously been subscribed to, it probably had an OnCompleted or OnError which would prevent it working until it is subscribed to again. But we don't want to subscribe to it twice, so we first unsubscribe.

<8> When data arrives at the input port, it is given to the query via the Subject object.

<9> Any exception coming in from the input is passed through to the output via the query. If the query has already generated an exception it will likely discard it.

<10> The OnCompleted from the input is also passed through to the output via the query.

That completes our examples of how you can use monads within an ALA application.


This has been a long section contrasting monads and ALA. In summary ALA solves the same problem that monads solve, that of composing more abstract computational units to create more specific computational units. But where monads are about composing functions, ALA composes objects. While pure functions are _mathematically_ simpler than objects, many _computations_ are more naturally expressed using state. That's why ALA is object oriented. In other words, sometimes objects just make better abstractions than functions. 

But if you already have an existing monad library, it makes sense to use it within an ALA application.  


==== IObserverPush interface

We used the programming paradigm interface _IObserverPush_ a couple of times in the examples previously.

Here it is again:

[source,C#]
....
interface IObserverPush<T> : IObserver<T>
{
    void OnStart();
}
....

Nothice that it is the IObserver interface with one added method: _OnStart_.

Now we can explain the reasoning behind this programming paradigm, and compare it with the IObserver/IObservable pair.

IObserverPush<T> is similar to IDataFlow<T>, but with the ability to handle batched data and to propagate errors down the data flow.

This interface is the 'pure push' version of the IObservable/IObserver pair. Remember that while IObserver is a push style interface, IObservable is not. The Subscribe method of IObservable is more of a pull style that usually gets the flow of data started. So its hard to use IObservable asynchronously or over a network.

Data transfers using IObserver are usually triggered from the destination end. It does so via IObservable. For example, ObservableToSerial in the previous section must subscribe to 'pull' the data. So Subscribe does two things: 1) it wires the IObserver interface in the opposite direction, and 2) it (usually) starts the data transfer. The source will then push the data back using the IObserver interface.

Sometimes Subscribe only wires the IObserver, and thereafter the source initiates the data transfer whenever it likes. This is called a hot observable. OnCompleted and OnError cannot really be used with hot observables because they usually stop everything. If the source does use OnCompleted or OnError, then the source must really send the data in response to the Subscribe. If OnCompleted or OnError are called, the detsination must unsubscribe and resubscribe to get the next batch of data. The Subscribe method, therefore, is not just used for wiring - it is usually used to start the transfer.  

I find this behaviour of IObservable/IObserver doesn't suit permanently wired user stories like we do in ALA. Besides, IObservable and IObserver seems to be a weird mix of 'push' and 'pull' styles. What I want is a purely push programming paradigm, that can be permanently wired, can batch the data, and can propagate errors down the dataflow chain. 

The other problem with the IObservable interface is that the destination wires itself to the source. The destination of a communication should never wire itself to the source if its in the same layer. It's fine if the source is in a lower (more abstract) layer. But general wiring up within an abstraction layer should always be done by a higher layer.

So to fix all these problems with the IObservable/IObserver pair, I use IObserverPush as an ALA programming paradigm. 

The OnStart method effectively takes the place of the Subscribe method in that it will allow data to flow again after an OnCompleted or OnError. In other words, we can permanently wire IObseverPush, and it will work for ongoing batches of data even after OnCompleted or OnError occurs in each batch. The wiring aspect of the Subscribe method is not needed. In ALA the layer above will wire up the IObserverPush interface. The IObservable interface is therefore completely redundant.

In summary, IObserverPush

* is used instead of IObserver/IObservable
* is a pure push programming paradigm
* like IObserver, goes in the direction of the dataflow
* requires the layer aobve to wire it up
* is designed to be permanently wired, but can still handle batches of data using OnCompleted, or OnErrors.




=== Encapsulation, polymorphism and inheritance

ALA replaces encapsulation with abstraction.

ALA removes associations and inheritance and instead uses composition (provided the composition uses a more abstract abstraction).

ALA replaces polymorphism with zero coupling.

The first two we know as fundamental principles in ALA, and have already been discussed in chapter three.

The third statement requires some elaboration.

In the meme pool of software engineering we have at least five memes for the one concept. These are polymorphism, information hiding, protected variations, dependency inversion principle and open closed principle. 

I shall argue in their individual discussion later that none of them is a principle.
All five are just a simple pattern. The motivation is that if you have code that couples knowledge of different 'things', you extract the knowledge into their own modules. Now when the 'thing' changes, you can change it or swap it out without affecting the client module. Switch statements were a smell in traditional code that different things were mixed.

You may already have separated out one implementation of a thing. So now your client code talks to a concrete thing. The conical example is a particular database. But now you need to use a different thing. Instead of putting in a switch statement everywhere to talk to different databases, you use the polymorphism / information hiding / protected variations / dependency inversion / open closed pattern. 

The pattern itself consists of an interface. That's it. All those memes all trying to tell you to use an interface. Oh, and another one - if you have heard the phrase "program to interfaces".

On top of that, single responsibility also pretty much forces the use of an interface. Referring to a peer concrete object is always a second resposibility.

ALA does not use this pattern.

To understand why, lets call the client module B and the modules that implement the interface, C1, C2 etc. B doesn't know which of the C modules it is talking to at run-time. If we want it to be C2 for a particular application, we have higher level code that injects C2 into B.   

It's important that we realize that in this pattern the interface is owned by B. It describes what B _requires_. It is cohesive with B. It is part of abstraction B. This still the case even if the interface is split out into a module or even a different compilation unit of its own. 

Therefore C1, C2 etc have a dependency on B. They implement B's requirements. They collaborate with it. The dependency in the design is just inverted from what it might have been. C1 & C2 are coupled with B. 

So this is illegal in ALA (assuming B and C1, C2 etc are all at a similar level of abstraction, which they likely are. That's why for ALA I have stated that the equivalent is zero coupling. ALA replaces the dependency with nothing at all between A and C1, C2 etc.

We have talked about how ALA still works in Chapters three and four. It does still use an interface but it is not owned by B (or C1 or C2). It is at a much more abstract level, the level of a programming paradigm. For example if abstractions B, C1 and C2 know about the event-driven programming paradigm, then instances of them may be wired together.

ALA further requires that the higher level code that does the injecting is also an abstraction. It is just one that is specific to a user story. Let's call it A. A needs to cohesively do all the wirings of all the instances of domain abstractions to implement a whole user story in a cohesive way.

These five memes don't have anything to say about that. They are redundant with respect to ALA. By just using ALA the job is done in a better way.

The SRP, DIP amd OCP are discussed further in the sections below.


=== SOLID Principles

The SOLID principles collated by Robert Martin are confusing. Their one or two sentence descriptions don't describe them very well, so you have to go a read a lot to understand them. Unfortunately they are collected up into the catchy acrostic "SOLID" with a meaning that is undeserved. This has made the collection more well known than it deserves, as we shall explain.  


====  Single Responsibility Principle

The SRP strangly worded differently from it's name. It states that a module (function, class or package) should have only one reason to change. I find this s strange formulation of the name.


By using abstractions, the SRP is complied with in terms of reasons to change. However, some abstractions arguably have more than responsibility. I often use the question "What do you know about?" to an abstraction. It is always one thing it knows about, but it may have multiple responsibilites for that thing.

Examples:

* An ADC driver (analog to digital converter hardware) knows all about a particular ADC chip. It has the responsibilies of initializing it and getting the readings from it. It changes only if the HW chip changes.

* A protocol abstraction knows about a protocol. It has the responsibility to send data using the protocol and to receive it. It changes only if the protocol changes.

* A file format abstraction, such as CSVFileReaderWriter knows about a file format. It has the responsibility to both read it and write it. It changes if the file format changes.

My advice is that the SRP is made redundant by thinking in terms of abstractions, which accomplishes the intention of the SRP better. 


====  Open Closed Principle

Talk about confusing. Firstly Betrand Meyer coins the phrase, which is impossible to understand without further reading. On further reading you find that Robert Martin has a completely different principle by exactly the same name. Then he has two verions of that, one for modules in the same compilation unit and one for when the client is in a different compilation unit and is already published. By the way, being already published was also the context of Meyers OCP.

None of them are principles - they would need to be used in the right conext at best. They have associated patterns anyway (or anti-patterns relative to ALA).

===== Martins version

The sources of knowledge about the meanings of these memes are:

Craig Larman
Kevlin Henny





==== Liskov Substitution Principle

TBD

====  Interface segregation principle

TBD

==== Dependency Inversion Principle

The DIP is stated:

A.   High-level modules should not import anything from low-level modules. Both should depend on abstractions (e.g., interfaces).

B.   Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions.

This sounds the same as the ALA fundamental rule that all dependencies must be on abstractions that are more abstract. 

The Dependency Inversion Principle, and its associated pattern goes some way toward ALA in one respect and far too far in another respect.

Firstly ALA uses the word abstraction for the unit of code. The DIP really only uses the word abstraction as a synonym for interface – e.g. abstract class. The essence of the difference is that when ALA allows a dependency on an abstraction, it means more abstract than what DIP does. In both cases an interface is introduced. But in DIP, that interface is owned by the first module, and expresses what that module requires, so it’s highly coupled with the module, not really more abstract than it. ALA’s interfaces don’t belong to domain abstractions but go all by themselves in a lower layer. They are so much more abstract that we call them programming paradigms.

To be more precise, the DIP (as its name suggests) reverses a dependency used for communication between two classes, but ALA completely removes it. But the ALA wiring pattern also adds other dependencies. It adds a dependency on each module from a higher layer for dependency injection and it adds dependencies from each module to a programming paradigm interface in a lower layer for ports.

Let’s start with conventional code where B talks to C. It uses a dependency:

B ----> C

DIP does this:

B < --- C

ALA does this:

B ---- > I

C ---- > I

Those who know the DIP might immediately say “no the DIP has a version where the interface is put into its own separate package like that as well”. The DIP allows for the interface to be placed in a different compilation package than B. Lets call it IB. Theoretically this allows C (the implementer of IB) to be reused without B. However, this is a superficial change from the point of view of abstraction level. Simply moving IB doesn't make it more abstract. That interface is still owned by B - it represents what B requires. So as it still just a part of the B abstraction.

With DIP, you get to choose a specific implementation, C, to satisfy what B requires. In ALA you get a port with a programming paradigm that will take any domain abstraction instance with a compatible port of the same programming paradigm. 

Both DIP and ALA require dependency injection. So let’s draw the injection dependencies as well:

Conventional code version:

B ----> C

DIP version:

A ---> B

A ---> C

C <--- B

ALA version

A ----> B

A ----> C

B ---- > I

C ---- > I

DIP effectively moves the interface from C to B. B gains an interface that does a similar job to C. C then implements it and B uses it.  

Because the new interface is owned by B, it may be different from the one in C because now it’s about what B requires rather than what C provides.

Because of this, it might often be an adapter that implements the interface, and then the adapter uses the original interface of C.

TBD

Think of B as being some business logic and C being the database. B no longer depends directly on a specific database. But the databases do now depend on B. To avoid changing the databases, you would use adapters. The pattern is designed to increase the reuse potential of B, the business logic, because different databases can be plugged into it. But it likely decreases the reuse potential of the things around the business logic unless adapters are used. The DIPs application is primarily around making business logic reusable, and leads to hexagonal architecture, which has the business logic in the middle, and all the peripherals are plugged into its interfaces.

 

 

Returning to the sentence in the DIP that states: “High-level modules should not import anything from low-level modules.”.

 

The 2nd  ALA dependency rule is in a way less constraining than the DIP here. If a low-level module is much more abstract, ALA allows to keep the dependency. This is what allows the dependencies between the application user stories and the domain abstractions. It comes down to what is meant by high-level and low-level in Martin’s writings. I think by ‘low-level’ he refers to what would have been depended on in conventional code. Things like the database, middleware for communications, and frameworks.(e.g. for supporting asynchronous events.)

 

In ALA, yes you would wire the specific database adapter and the specific middleware adapter (and the specific UI), but you wouldn’t wire in the framework. It doesn’t matter that the abstraction depended on is low level. I want to commit to only one implementation of the framework. It would be silly to have to use ports on every single domain abstraction so I can wire in a framework of my choice, and have to wire it to every single domain abstraction, when I want to commit to using one. This becomes more obvious as you get to even lower levels such as math libraries. I don’t need to allow for swapping out the math library implementation. So ALA allows dependencies on more abstract abstraction even if they are low-level modules. In fairness, Martin probably doesn’t mean to include all low-level modules in the DIP, just certain ones that should be decoupled.


===  Dependency injection pattern

By now we know that ALA uses dependency injection. It uses it for wiring up all instances or all domain abstractions.

We have favoured using reflection to do the injection in our examples, but that is just a syntactic shortcut that allows domain abstractions to have many ports without also having many setters. It also allowed us to keep the ports private from direct access by the application layer. It allows ports to be implemented very simply, without the need for setters at all. It allows some other interesting things to be done. For example, after an instances port has been wired, there may events in the interface of the port that need internally wiring to event handler methods. The wireTo method can look for and call a method in the instance to do this immediately after wiring.

ALA always uses explicit wiring. This is one of the most important aspects of ALA. It's usually in the form of a diagram, because the wiring is usually an arbitrary graph. ALA never does dependency with automatic wiring. Having a dependency injection container means that the wiring itself is implicit in the interface types. If one module requires an interface, and the container has a module that implements it, that means these two modules get wired together. This type of implicit wiring is indirect and obfuscated and illegal in ALA. 

In ALA, abstraction pairs don't have their own interfaces for their instances to communicate. So we don't have the situation where class A has a dependency on class B, and so an object of class B (or one of its subclasses) is injected into class A. Similarly, we wouldn't have the situation where class A requires an interface that is implemented by class B.

In ALA the interfaces must be programming paradigm interfaces, which are a whole abstraction layer more abstract. So we need to be thinking that if class A accepts or implements a certain programming paradigm interface, there could be any number of other abstraction instances that could be wired to it. Furthermore, we could build arbitrarily large compositions. Some abstractions will have some ports that don't need to be wired to anything. So it doesn't really make sense to call what we are injecting 'dependencies'. We just think of it as wiring things up. You wouldn't describe what an electronics engineer does as dependency injecting components into each other.

In ALA, the explicit wiring should not be XML or JSON. I do not consider these readable programming languages. They are data languages. 

Usually user stories contain a graph structure of relationships. So the wiring should be a diagram to best show that structure. 

However, if the graph is mostly a tree structure (with relatively few cross connections), then it may still make sense to avoid the weight of a diagramming tool, and represent the wiring in text form. But in this case I still much prefer the readability of code written in a programming language than XML or JSON. An argument can be made for the declarative nature of say XAML and that UI designers could learn this declarative language more easily than a programming language. But I would maintain that a the subset of the programming language needed to the equivalent of XML is declarative style. That's what most of the wiring examples in this website are: declarative composition.

Besides, its not just about UI. For a given user story there will likely be UI, business logic, data transformations, and data storage. These should all be expressed togther cohesively. They should all be composed inside one abstraction. To handle the sometimes non-trivial configuration of the abstraction instances, normal code is sometimes needed, for example for lambda expressions or delegates. If we have a UI designer on the team, great, just teach him the subset of domain abstractions that are used for the UI, how to configure them, and how to compose them. Languages like XAML are not particularly easy just because they are declarative.





===  Physical boundaries

I was listening to a talk by Eric Evans where he said that Microservices works because it provides boundaries that are harder to cross. We have been trying to build logical boundaries for 60 years, he said, and failed. So now we use tools like Docker that force us to use say REST style interfaces in oder to have physical boundaries. I have also heard it suggested that using multiple MCUs in an embedded system is a good thing because it provides physical boundaries for our software components. And I think, really? Is that the only way we can be create a logical boundary? I can tell you that multiple MCUs for this reason is not a good idea if only because all those MCUs will need updating, and the mechanisms and infrastructure needed to do that make it not worth it. Unless there is a good reason, such as to make different parts of your code independently deployable, the extra infrastructure required for physical boundaries that are just logical boundaries is not necessary. Furthermore, physical boundaries, like modules do not necessarily make good abstractions. The only boundary that works at design-time is a good abstraction. So ALA achieves it's design-time boundaries by using abstractions.

===  Test Driven Development

It is said that TDD's main advantage is not so much the testing, but the improvement in the design. In other words, making modules independently testable makes better abstractions. This is probably true, but in my experience, TDD doesn't create good abstractions nearly as well as pursuing that goal directly. The architecture resulting from TDD is better but still not great.


===  Observer pattern

TBD




===  Layer patterns

==== MVC

TBD

==== Application, Services, Drivers, Hardware

TBD

===  Factory method pattern

The Factory Method pattern in both the GOF book and in online examples has multiple variations. The only thing they seem to have in common is that the client doesn't use "new ConcreteProduct()". It just wants an object that implements an interface, IProduct. For any reason it doesn't want to be the one who will decides at design-time what that concrete product will be. 

Here are some of the variations. 

* Several ConcreteCreators exists to encapsulate knowledge of how to use the ConcreteProduct constructor which has many parameters, in a consistent way to make a valid ConcreteProduct. The common example is different named pizzas or sandwiches. 

* The Client finds out at run-time what ConcreteProduct is needed (usually a string name). We want to move the switch statement out of the client and into a Creator class.)

* The client knows when the objects are needed, but needs to be more stable. Which product is needed changes more often (although still known at design-time). So it goes into a class that changes. 

In all cases we end up with two objects wired together through the IProduct interface. These two objects we will refer to as the Client and the ConcreteProduct (from the pattern terminology). To get them wired using the Factory Method pattern requires the use of a FactoryMethod. The FactoryMethod typically goes in an abstract class called ICreator, which may do the creating itself, or maybe overridden by one or more ConcreteCreators.

In the context of abstraction layers, ALA gives more insight into the FactoryMethods pattern. Remeber we expect lower layers to more stable. The IProduct and ICreator interfaces are in the ProgrammingParadigms layer (lowest layer). The Client and all the different ConcreteProducts are in the DomainAbstractions layer (middle layer). The ConcreteCreator is in the Application layer and wires one of the ConcreteProducts to the client. So now when we want to change the ConcreteProduct, only the ConcreteCreator in the application layer has to change.

But in ALA we typically accomplish that in a far simpler way. We commonly let the application code instantiate the right concrete class (that implements the interface, IProduct), and wire it to the Client object using the WireTo() method. This is nothing more than static wiring, but can only work when the required ConcreteProduct is known at design-time.


==== case 1

Now to the case in ALA where we have a client that needs a concrete product creating later than design-time, that is at run-time. Such a client is the Multiple Abstraction. It's job is to make many instances of a Domain Abstraction. But it is an abstraction so can be used to make instances of any object. They don't even have to implement a specific interface such as IProduct, because Multiple doesn't interact with these instances itself.

==== case 2

Let's say you have a Table domain abstraction that stores a table of data. In your application, you want to instantiate many Tables. Now lets suppose that we want these Table instances to persist their data. A database must be attached via an IPersistance interface. We don't want the Table class to know about concrete Databases. We want the application layer at the top to do that. But we don't want the application layer to have to wire the database to every instance that requires an IPersistance. We want the Application to be able to just use a Table as if it is a self-contained abstraction. We want the Table instances to take care of themselves for Persistence. So we make a Peristence abstraction in the Programming paradigms layer. The concept of Persistence is at the right abstraction level to go in this layer. The Table class can use this persistence abstraction through a FactoryMethod. A variable in the Persistence abstraction stores the IPeristence object. The application instantiates which database it wants to use and passes it to the Peristence abstraction.


=== Decorator pattern

TBD

===  Bridge pattern 

TBD


===  Architecture styles

I am not an expert at these so called 'Architectural styles'. Any feedback about the accuracy of the following comparisons would be appreciated.


==== Components and connectors

David Garlan and Mary Shaw in their paper titled "An Introduction to Software Architecture" 1994 use components and connectors as a framework for viewing architectural styles. Depending on the style, the connectors can be a procedure call, event broadcast, database query, or pipe (which we call dataflow).

*Similarities*

ALA follows this idea closely. 


*Differences*

In ALA we call the styles programming paradigms, and it is emphasised that multiple programming paradigms can be used in the one user story. The reason not to call them 'styles' in ALA is that the word style tends to imply using a single style throughout the program.

In ALA 'components' becomes 'abstractions' and 'connectors' becomes 'ports and wirings'. This change in terminology is to emphasis that the wiring is distinct from the abstractions themselves. The term components and connectors can (albeit not necessarily)) refer to an effectively monolithic system that is just separated into pieces and the pieces connected back together in a fixed rigid arrangement. This is especially true if the design methodology is decomposition of the system into elements and their relations. Such a system is loosely coupled at best. In ALA you can't do that. Systems must be composed of instances of abstractions wired together by a higher layer abstraction that directs the wiring. Abstractions are necessarily zero-coupled with one another. They use ports that have the types of a small number of programming paradigms so that instances of them can be composed in (generally) an infinite variety of ways. The style where components being filters and connectors being pipes works this way. 

I suspect that most components and connector systems use interfaces that are specific to the components. 

Examples using the UML component diagram, even though it uses the term ports, show interfaces that rigidly couple their components to one another, for example, interfaces with names such as CustomerLookup. This would mean that only components that are implementations of that specific interface could be substituted. Usually there appears to be only one, making the components effectively just modules. In UML, components appear to be just containers. They are the first level of decomposition of a system, and themselves just contain connected classes. This type of architecture is incompatible with ALA.   



==== Component Based Software Engineering

// TBD, some of this may be repeated

ALA uses many of the same methods found in component based engineering or the Components and Connector architectural style.


===== Similarities

* Components are Abstractions.

* Reusable software artefacts.

* Connection ports for I/O.

* Composability

* Both instantiate components, specialize them by configuration, and compose them together to make a specific system.

* ALA's 3rd layer has interfaces used to wire abstractions in the 2nd layer, so at a lower level (more abstract) level. They represent something more like programming paradigms. The equivalent pattern in components engineering is "Abstract Interactions".  

* The architecture itself is composed of a generic part and a specific part. The general part is the ALA reference architecture itself and the components or the connectors architectural style. The specific part is the wiring diagram of the full system.

===== Differences

* Component based engineering technologies such as CORBA primarily solve for platform and language interoperability in distributed system whereas ALA brings some of the resulting concepts and properties to everyday small-scale, non distributed development as well, where the only separation is logical.

* In ALA there is perhaps more particular emphasis on making components clearly more abstract than the systems they are used in, and making the interfaces clearly more abstract than the components. The components are pushed down a layer and the interfaces down to a layer below that. Then all dependencies must be strictly downwards in these layers. In component based engineering, this structure is not necessarily enforced. If the components are just a decomposition of the system, then the system, components and interfaces may all be at the same level of abstraction, making the system as a whole complex.

* ALA depends on the 'abstractness property' of components to get logical separation, and so calls them 'Abstractions' and not components to help them retain that property. Even if there will only be one use and one instance, it is still called an abstraction. This keeps them zero coupled and not collaborating with other abstractions they will be wired to.

* ALA layers are knowledge dependency layers.  Components may still be arranged in layers according to run-time dependencies, such as communication stacks. In ALA run-time dependencies are always implemented as explicit wiring inside another higher layer component.

* ALA's top layer must be a straight representation of the requirements, whereas components may tend to be decomposed pieces of the system.

* ALA's 2nd layer of components are designed for expressiveness of user stories or requirements, and provide DSL-like properties. ALA puts emphasis on the 2nd layer of components having the scope of a domain as the means of explicitly controlling the expressiveness of the pallet of components.

* ALA is not fractal. In ALA the components of components are abstractions that become more abstract and thus ubiquitous and reusable. ALA therefore uses abstraction layers rather than hierarchies.

* ALA forces decisions about which abstraction layers the software artefacts go into, and then controls knowledge (semantic) dependencies accordingly.

* ALA tries to make the abstraction layers discrete and separated by a good margin. 

* ALA puts greater emphasis on wiring being able to represent any programming paradigm that suits the expression of requirements, and the use of many different paradigms in the same wiring diagram.

* ALA emphasises the cohesion of functional parts of a system such as UI, logic and Data, by bringing them all together in one small diagram using domain level components

* Instead of 'required' interfaces, in ALA they are called 'accepts' interfaces. This is because the abstractions are more abstract and composable, so, as with Lego blocks, there isn't necessarily a connection to another instance.





==== Presentation, Business, Services, Persistence, Database

TBD

==== Presentation, Application, Domain, Infrastructure

The middle two layers appear to be the same as ALA's. The Presentation (UI) only has run-time dependencies on the Application, and the Domain layer only has run-time dependencies on the Infrastructure (Persistence etc), so these layers are not present in ALA. 

Instead Presentation is done in the same way as the rest of the application, by composing and configuring abstractions in the domain. The meaning of composition for UI elements (typically layout and navigation-flow) is different from the meaning of composition in the use-cases (typically workflow or dataflow).

In ALA, the foundation layer is also done in the same way as the rest of the application, at least a little. Domain abstractions that represent say a persistent table are in the Domain layer. The composition and configuration of them again goes in the Application layer. This time the meaning of composition is, for example, columns for the tables and schema relations.  

If the implementation of any domain abstraction is not small (as is the case with the persistent Table abstraction mentioned above, which will need to be connected to a real database), it will be using other abstract interfaces (in the Programming Paradigms layer) connected to its runtime support abstractions in a technical domain, the same as in Hexagonal Architecture.

==== Object Oriented Programming

From my reading, it seems that the most characteristic feature of OOP is that when data and operations are cohesive, they are brought together in an object. Others may see it as enabling reuse, inheritance, and still others may see it as polymorphism. New graduates seem to be introduced to polymorphism in inheritance and not be introduced to interfaces at all, which is a shame because the concept of interfaces is much more important. 

I have never been an expert at Object Oriented Design as I found the choice of classes difficult and the resulting designs only mediocre. But I think the most fundamental and important characterising feature of OOP is under-rated. That is the separation of the concepts of classes and objects. This separation is not so clearly marked when we use the terms modules or components. The separation is fundamentally important because it's what allows us to remove all dependencies except knowledge dependencies. In the way described earlier in this article, you can represent the knowledge of most dependencies as a relationship between instances completely inside another abstraction. What OOP should have done is represent relationships between objects completely inside another class. The problem is that OOP doesn't take advantage of this opportunity. Instead, it puts these relationships between objects inside those objects' classes, as associations or inheritance, thereby turning them into design-time dependencies, and destroying the abstract qualities of the classes. Abstractions, unlike classes, retain their zero coupling with one another.

ALA addresses the problem by calling classes abstractions and objects instances. Abstractions differ from classes by giving us a way to have logical zero coupling, as if they were on different physical platforms. Instances differ from objects by having ports because their classes give them no fixed relationships with other objects.

Of course, when you are writing ALA code, abstractions are implemented using classes, but you are not allowed associations or inheritance. Instances are implemented as objects but with ports for their connections. A port is a pair of interfaces that allow methods in both directions. The interfaces are defined in a lower layer.
 
In ALA, the UML class diagram completely loses relevance. Because classes have no relationships with each other, bar knowledge dependencies, a UML diagram in ALA would just be a lot of boxes in free space, like a pallet of things you can use. You could show them in their layers and you could even draw the downward composition relationships that represent the knowledge dependencies, but there would be no point to this except in explaining the concepts of ALA. When you are designing an actual system, the real diagram is the one inside of an abstraction, especially the uppermost one, the application. It shows boxes for instances of the abstractions it uses, with the name of the abstraction in the box, the configuration information for those instances, and of course the lines showing how they are wired together. The names inside the boxes would not even need to be underlined as in UML, because the boxes in such diagrams would always be instances. 

Such a diagram is close to a UML object diagram. However, a UML object diagram is meant to be a snapshot of a dynamic system at one point in time. In ALA, any dynamic behaviour is captured in a static way by inventing a new abstraction to describe that dynamic behaviour. Thus the design-time view is always static. So the object diagram is static. The application class specifies a number of objects that must be instantiated, configured, and wired together to execute at run-time. Since the structure is always static, ideally this would be done by the compiler for best efficiency, but there is no such language yet. So, in the meantime, it is done at initialization time. The object diagram can be fairly elegantly turned into code using the fluent coding style shown in the XR5000 example.

===  DSLs

We briefly discussed ALA as a DSL in the structure chapter <<DSL1, here>> 

ALA includes the main idea of DSLs in that the fundamental method "represent[s] requirements by composition of domain abstractions". It shares the DSL property that you can implement a lot more requirements or user stories in a lot less code. 

But ALA only tries to be a light-weight way of telling ordinary developers how to organise code written in your underlying language. Although the domain abstractions do form a language and the paradigm interfaces give it a grammar, ALA doesn't pursue the idea of a language to the point of textural syntactic elegance. Instead, you end up with explicit wiring methods to combine domain entities, or plain old functional composition, or some other form of composition in the wider sense of the word. Often, the text form is only a result of hand translation of an executable diagram. ALA certainly doesn't overlap with DSLs to the extent of an external DSL, nor does it try to sandbox you from the underlying language. It therefore does not require any parsing and doesn't need a language workbench, things that may scare away 'plain old C' developers.

Like DSLs, ALA can be highly declarative depending on the paradigm interfaces being used to connect domain abstractions. It is better to have the properties of composition and composability in the your domain language even if they may not be in a perfectly elegant syntactic form. ALA may end up composing abstractions with calls to wireTo methods instead of spaces or dots. But often a diagram using lines is even better than spaces and dots.  

In DSLs, it is important that different languages can be combined for different aspects of a problem. For example, a DSL that defines State machines (the state diagram) and a DSL for data organisation (Entity Relationship Diagram) may be needed in the same application. You don't want to be stuck in one paradigm. ALA recognises this importance by having paradigm interfaces that are more abstract than the domain abstractions. 

DSLs probably work by generating a lot of code from templates whereas ALA works by reusing code as instances of abstractions. Both of these methods are fine from the point of view of keeping application specific knowledge in its place, and domain knowledge in its place. Howver, the distinction between ALAs domain layer and programming paradigms layer is probably not so as clearly made in the implementation of the templates.   

It is an advantage of DSLs that they can sandbox when needed. An example from the wiring pattern earlier is that the ports of instances do not need to be wired. Therefore, all abstractions need to check if there is something wired to a port before making a call on it. Enforcing this is a problem I have not yet addressed.

A possible solution, albeit inferior to a real DSL that would tell you at design-time, might be that when there are tools that generate wiring code from diagrams, they automatically put stubs on all unwired ports. These stubs either throw an exception at run-time, or just behave inertly. 

ALA is different from external DSLs. ALA is just about helping programmers organise their code in a better way. It doesn't try to make a syntactically elegant language, as a DSL does. Certainly an external DSL will end up representing requirements in a more elegant syntax. But that is not the most important thing in ALA. The most important thing is the separation of code that has knowledge of the requirements, which will cause the invention of abstractions that have zero coupling (because the coupling was really in each requirement - that is why a requirement is cohesive). ALA also avoids taking the average imperative language programmer out of their comfort zone. It does not require a language workbench and does not sandbox you from the underlying language.

ALA probably does fit into the broadest definition of an internal DSL. However, again, it does not target syntactic convenience in the expression of requirements so much as just separating the code that knows about those requirements from the code that implements them. An internal DSL usually aims to have a mini-language that is a subset of the host language, or it tries to extend the host language through clever meta-programming to look as if it has new features. ALA is about abstraction layering. It is about this design-time view of knowledge dependencies: what abstractions in lower layers are needed to understand a given piece of code.







===  Multi-tier Architecture

TBD


===  Clean Architecture

Clean architecture is initially viewed as concentric circles which are in effect layers. Entities are innermost, with business logic next, and the external system consisting of things like database, UI and communications on the outer. These layers are allowed to have dependencies going inwards. 

In conventional code, dependencies tend to follow communications, and communications, when implemented in the form of direct function or method calls, flow from the initiator of the communications.  

This gives rise, for example, to dependencies from the UI to the business logic, and then from the business logic to the database. In clean architecture, these are referred to as primary and secondary I/O with respect to the business logic. The idea in clean architecture is to invert the secondary dependencies so that all communications dependencies are now toward the business logic.

In this way the business logic at the core is reusable, and perhaps more importantly understandable without knowing details of a concrete database, middleware, or UI. It also facilitates easier testing of the business logic.

The business logic uses interfaces to communicate with the outside world. The primary communications have interfaces that the business logic _implements_ (unchanged from conventional code). The secondary communications have interfaces which the business logic _requires_. The concrete implementations of database, etc are passed in or injected in. This wiring is specific to a unique application, so in ALA terms, it goes in the top layer.

From the point of view of the business logic only, this is compliant with ALA, except for the dependencies on entities, which is discussed below. The elements of the business logic, which in clean architecture are called use cases, can be considered abstractions that know about the business use cases and nothing else.


==== Adapters

In the clean architecture, dependencies, such as those between business logic and database, are reversed (following the dependency inversion principle) from what it would have been in conventional code. These reversed dependencies do not comply with ALA. I think most implementations recognise these as bad dependencies, and solve it by removing the dependencies altogether using adapters. This is now a lot closer to ALA compliance. 

Something must pass-in or inject the adapters into each of the business logic use cases. If this logic is thought of as being in a higher layer, then this is also ALA compliant.

In terms of ALA abstraction layers, the use cases, the database, the UI, and other IO are all about the same level of abstraction. They all know about different types of details. While the use cases know about the domain and it's requirements, the database knows about how to efficiently store data. They are all abstractions that are zero coupled with one another. The adapters go in a layer above, and are specific to a use case / external IO pairing. The main() (or a function it delegates) goes in a layer above that and wires everything up using (usually) constructor dependency injection on the use cases.

==== Entities

Clean architecture allows dependencies of use cases on entities. This is incompatible with ALA.  

Entities typically hold all sorts of domain details, for example various informations about customers. When the requirements change, these will change. We expect requirements to change - that's why we have agile.

Entities are an easy place to just add all fields to do with an identity. They will tend to hold some fields that, although they associate with an identify, really belong to separate use cases. These fields should be cohesive with their use cases. If entities hold information that is not significantly abstract with respect to use cases, such as the customer's address, which is primarily used by one or two use cases only, then it is not ALA compliant. The customer identity abstraction's responsibility should not be to know all data that can be associated with a customer, but to know about the idea of identity. It should not be used as the carrier of information between two use cases, which would expose all entity data to all use cases. Instead, use cases should all know about the abstraction, _customer identity_. A particular use case should only know about it's own data, and only store it against a customer identity.


In other words, a user story should be able to have private data that is associated with an identity and still ultimately stored with all other data for that identity in the database. The only idea that is abstract enough to go in a layer below the use cases is the customer identity, which is likely to be reused by most new use cases. Subclassing, so that every use case has its own subclass may solve the problem in one way, but I expect would cause other problems.

Even if some customer detail needs to be shared with another use case, communicating this via a shared entity is bad. For example, consider a use case in a system that knows about the address that customers enter into the system. It could have an output port called 'address' that can be used to wire it to other use cases. This port will probably have a DTO type that belongs to it. The DTO cannot be shared with other features in the same layer without violating ALA constraints. A feature such as frieghtcost may need an address to calculate freight. Remember it is written separately from the address feature so is not coupled with it.  It cannot know about the address feature. It can't know the DTO of the address. Nor does it need the entire address. So it may be written, for example, to have input ports for country and zip code. Yet another feature is shipping. It needs an address for a shipping label. It may have an input port that takes a string for of address, because it isn't interested in the content of the address, only in faithfully printing it. So these three ports are incompatible. The wiring layer, which knows that it needs to wire these three together also knows how to adapt them, which can be done quite simply by passing in a lambda expression into the WireTo method (analogous to a Select clause in LINQ).

More generally in ALA, such applications are best viewed primarily in terms of dataflows rather than abstracted entities. Dataflows to/or from the database, for example. It flows to particular use cases, and only the data that is needed by the use case. At any point in the flow, the flow has a type. It is still nice to have a compiler generated, anonymous, fully type checked class at each point in the flow. But nowhere do we want to create an explicit class for sharing a whole entity, or even a part of an entity.

The identity of a customer itself is probably an abstract concept that can be used by all features. We therefore want a shared abstraction for the identity (just knowing about a unique internal or external number or key). 

It should be possible to add a feature that needs a new private field (private to the feature). The data can still be associated with an identity and be stored in the database. Adding this field should cause a database migration, but not changes to other use cases. 

So the way entities should be handled is quite different in ALA.

TBD do a simple 'task list' application on Github in both ALA and clean architecture to show how entities are handled in ALA. Then add a feature such as e-mail notification on due date to show how a new feature can have it's own private data stored against the task identity (the e-mail sent status) and communicate via a port with an existing feature (the due date feature).



==== Primary separation

There is a second major difference between clean architecture and ALA. In clean architecture, the UI and other externals IO such as the database are considered to be separated first. That is how it is shown on an architecture diagram, almost as if they are separate packages. You hear of being able to switch between a GUI or CLI based UI. 

This view of primarily separating UI from business logic will likely lead to coupling. It is unlikely that the UI is so generic that it knows nothing about the business logic. It will need to specific to the data the business logic needs or produces. Similarly, the design of the UI will usually influence the way the business logic works. For example, the UI may be designed so that you enter all data first (like a form) and then submit, or it may be designed so that you select generally what you want to do, and then wizards guide the user through. The choice is likely to affect the way the business logic works.

In ALA, the primary separation is by features first. The UI and the business logic for a particular feature is considered to be cohesive with respect to that feature abstraction. The use case will wire up both the elements of the business logic and the elements of the UI (and those for the necessary database queries, etc). The UI elements used can still be swapped out for different ones, but that is an operation on the feature. 

In the case that the UI design is not changing, but its implementation is, that involves swapping out the implementations of the UI domain abstractions. The abstraction themselves do not change, so the use cases wont change. But the new UI abstractions can shift to a different technology, shift from desktop to cloud, or the like. 


==== DTOs

DTOs have two different uses.

- part of an interface to group together related data that is sent through the interface at one time. 
- to collect data together to be transported together to cut down on the overhead of messaging.

===== interface DTOs

In ALA, DTOs are not generally abstractions in themselves. Therefore, they may not be put in a lower layer and shared by two abstractions to communicate. That would couple the knowledge inside the two abstractions. If many abstractions want to know about the same DTO, this is likely to be the case as new abstractions are added, then maybe it is sufficiently abstract to be in a lower layer and shared. 

Otherwise in ALA, you need to use adapters. This can be as simple as a lambda expression passed to the WireTo operator, in the same way that you would pass a lambda expression to a .Select clause in LINQ.

Although this is ALA compliant, in ALA we generally prefer not to use adapters. Instead we use interfaces that are a significantly more abstract that are not owned by the business logic core. These are of course at the abstraction level of programming paradigms. These types of interfaces are heavily reused, allow composability in the wiring, and help tremendously to keep all abstractions from being implicitly coupled.

If a DTO can be avoided by, for example, having two dataflow ports that use primitive types, this will increase the abstraction level, reusability and composability of your abstractions. 

===== transport DTOs

In ALA you wouldn't use DTO for transport purposes. Instead, invent an abstraction say called multiplexer_demultiplexer for packing/unpacking (or serializing/deserializing) multiple input or output ports. Then instances of any two abstractions A and B, that would normally be compatible for wiring together, and which use asynchronous communications, can be physically deployed to opposite sides of the transport system. The wireTo operator, knowing they are in different physical locations, defers to a version that wire each of them to the respective multiplexer_demultiplexer instances.

==== Stability of wiring/adapter/feature layers

A system built from a wiring layer at the top, then an adapters layer below that, and then a layer below that for independent features, use cases, databases, UIs etc is ALA compliant. This is because the abstraction layers are more abstract as you go down. The top layer abstraction is a specific application. The second layer adapters are specific to pairs of things in the third. The third is the layer of fully reusable things. A database, even though we call it concrete, is a lot more reusable than a particular application, or a particular adapter.

An ALA application using these three types of layers is a little different from the layers we normally talk about, which uses domain abstractions that are wired directly together using compatible ports instead of via adapters in the layer above. To enable the ports to be compatible, there must be a layer below that provides abstract interfaces, which is what we call the programming paradigms. This latter arrangement has compositionality. For example, two domain abstractions currently wired together can have another domain abstraction, which is a decorator such as a filter, wired between them.

The two styles of layering can be used together.

==== Swapping out technology

In clean architecture, part of the reason for avoiding dependencies from business logic to things like a particular database or framework is to allow swapping out the technology. The database in the third layer can be exchanged for a completely different type - the coninical example is changing it from a relational database to a simple file. The business logic does not change. Only new adapters are needed, one for each use case. The top layer wiring of course also needs to change to use the different adapters.

An ALA application that uses the preferred layering scheme of application layer, domain abstractions layer, programming paradigms layer can also have its technologies swapped out. Let's again use the canonical example of swapping a relational database for a simple file. The domain abstraction that implements persistence using a database will have a port that implements a suitable programming paradigm. Usually this port has a type like ITableDataflow. You only need to substitute this domain abstraction with one that uses the same programming paradigm, but implements it as a simple file. Effectively these domain abstractions are wrappers, not adapters. 

The wiring again needs to change in all the places that were instantiating the database implementation. This is probably the only practical way to do it, as the database implementation probably needs different application specific configuration than what a simple file implementation would.

Now let's consider swapping out the UI. Let's say we are changing the UI from a desktop windowed application to a browser, or from a PC window to a CLI (Command Line Interface).

In the original PC application, the wiring instantiates UI GUI domain abstractions. These domain abstractions are wrappers for, say, WPF UI elements. The wrappers have ports which the wiring uses to connect them to the corresponding parts of the business logic. These ports are, or course, abstract interfaces from the programming paradigms layer.

To swap out the UI involves changing the wiring to instantiate from a different set of these UI domain abstractions. They will have the same ports that are still wired to their relevant place in the business logic as before.

In the case of the browser, these new domain abstraction work by changing elements of the HTML that will be returned by an initiating HTTP request. Just as the windowed domain abstractions were wired to their containing window, browser domain abstractions will be wired to their containing page. The containing page will request their content when it is time to send the response to the HTTP request.

The case of the CLI is more interesting. Whenever there is a case of either a GUI or a CLI user interface in conventional architecture, the business logic is tied to the CLI commands, and the GUI then uses the CLI. But in ALA we have the option to do this without coupling the design of the business logic to the design of the CLI commands.  

This is how it could work. Imagine we have previously built the application as a desktop windowed application, just as we did before. Now we change the wiring to use a set of CLI domain abstractions instead. Actually we need only two abstractions, one called command and one called response. Instances of the command abstraction are configured with the command that they handle. The command has an output event port which fires when the command is entered. If there are parameters, the abstraction can have other output ports for them, which are output before the event port fires. Alternatively you could chain up a series of parameter abstractions, each with a single output port. The response abstraction has an input port, and just prints any input data it receive. Optionally it could have a configuration name so it can identity itself when it prints.

Just as there are containing domain abstractions that describe layout for the GUI types of UI domain abstractions, CLI domain abstractions would also connect to a common domain abstraction that receives commands in a general form and passes them to the handler that is configured for that command. It would also collate the responses, add newlines to the output, etc.  

There is one other possibility. In the above cases of swapping out the UI, we changed the names of UI domain abstraction instantiated by the wiring. That was potentially all we needed to change.

It is possible that the configuration of the domain abstractions did not need to change. For example, CLI command abstractions need to be configured with the actual command string they will respond to, whereas their GUI equivalents, which are buttons, need to be configured with a button name. These could potentially be the same. If other configuration information of UI domain abstractions, such as style, is implemented in a generic way such as having a style port wired using WireMany, then it is possible that the wiring only needs to specify the UI domain abstraction names. 

In this case we could name all equivalent UI domain abstraction with the same name. Then by which set of classes we include in the project, it will be built for different technologies. I'm not really proposing it be done this way, just exploring the idea.




===  Onion Architecture

TBD



===  Hexagonal Architecture (Ports and Adapters)

ALA includes the basic idea of hexagonal architecture, but with modification using the Bridge Pattern to keep cohesive knowledge belonging to the application from being split. 

In a previous section we intimated that the sideways chains of interfaces going out in horizontal directions were the same as hexagonal architecture. While ALA shares this aspect of hexagonal architecture, there is still an important difference.

ALA retains domain abstractions of the UI, Database, communication and so on. For instance, in our XR5000 example, we had a domain abstraction for a persistent Table. We had domain abstractions for UI elements such as Page, Softkey etc. We don't just have a port to the persistence adapter, we have an abstraction of persistence. We don't just have a port for the UI to bind to, we have abstractions of the UI elements. The implementation of these abstractions will then use ports to connect to these external system components. Why is it important that we have domain abstractions of these external components?

. The Database and the UI will have a lot of application specific knowledge given them as configuration. Remember the creativity cycle. After instantiation of an abstraction comes configuration. The database will need a schema, and the knowledge for that schema is in the application. The Softkey UI elements will need labels, and that knowledge is in the application. By making domain abstractions for persistence and UI, the application can configure them like any other domain abstraction as it instantiates and wires up the application. To the application, these particular domain abstractions look like wrappers of the actual database and UI implementations, but they are more like proxies in that they just pass on the work. 
+
The Persistence abstraction then passes this configuration information, via the port interface to the actual database. The Softkey abstraction then passes its label, via the port interface, to the softkeys. Otherwise the Application would have to know about actual databases and actual softkeys.
+
If you need a design where the UI can change, you just make the UI domain abstractions more abstract. A softkey may be a command abstraction. It is still configured with a label. But it may be connected to a softkey, a menu item, a CLI command, a web page button, or a Web API command.

. From the point of view of a DSL, it makes sense to have concepts of UI and persistence and communications in the DSL language. The application is cohesive knowledge of requirements. The UI and the need for persistence are part of the requirements. In fact, for product owners communicating requirements, the UI tends to be their view of requirements. They talk about them in terms of the UI. Many of the product owners I have worked with actually design the UI as part of the requirements (with the backing of their managers, who are easily convinced that software engineers can't design UIs. PO can't either, but that is another story.). The point here is that the UI layout, navigation, and connection to business logic is all highly cohesive. We explicitly do not want to separate that knowledge. 
+
As a restatement of an earlier tenet of ALA, it is much better to compose the application with abstractions of Business logic, UI and persistence than to decompose the application into UI, persistence and business logic.

. We want the application to have the property of composability. We have previously discussed how that means using programming paradigm interfaces for wiring up domain abstractions. By using domain abstractions to represent external components, the abstractions can implement the paradigm interfaces and then be composable with other domain abstractions. For example, the Table domain abstraction which represents persistence may need to be connected directly to a grid, or to other domain abstractions that map or reduce it. Indeed, the Table abstraction itself can be instantiated multiple times for different tables and be composed to form a schema using a schema programming paradigm interface. I have even had a table instance's configuration interface wired to a another Table instance. (So its columns can be configured by the user of the application.)     

. The fourth reason why it is important for the application to not directly have ports for external components of the system is that we don't want the logical view of the architecture to become just one part of the physical view. If there is a communications port that goes to a different physical machine where there is more application logic, the application's logical view should not know about that. It may be presented as an annotation on the application (lines) connecting certain instances, but it shouldn't split the application up. At the application level, the collaboration between parts instantiated on different machines is still cohesive knowledge and belongs inside one place - the application.  

=== Domain Driven Design

Domain Driven Design's "Bounded Contexts" and ALA's Domain Abstractions layer have the same goal, that of encapsulation of the domain specific knowledge.

Domain driven design appears to concentrate on common languages to allow  pairs of elements to communicate, which ALA explicitly avoids. ALA tries to abstract the languages so that they are more abstract and fundamental than the domain, and more like programming paradigms.

// TBD Discuss with a DDD expert the comparison between ALA and DDD.




===  Microservices

TBD




===  Architecture evaluation methods

Methods such as ATAM tell us how to evaluate an architecture for quality attributes such as maintainability, for instance by giving it modification scenarios to test how difficult the modifications would be to implement. There are several scenarios based methods to do this such as ATAM. Using this we could, theoretically, iteratively search over the entire architecture design space to find a satisfactory solution. It's a bit analogous to numerically solving for the maxima of a complex algebraic formula. In contrast, ALA is analogous to an 'algebraic solution'. If the desired quality attributes, and all the software engineering topics listed above are the equations, ALA is the algebraic solution. It simplifies them down into a parameterised template architecture, ready for you to go ahead and express your requirements.


anchor:Monads[]


===  Reactive Extensions

TBD 




===  WPF & XAML

TBD

===  Functional programming

TBD

===  Functional programming with monads

TBD

===  Functional Reactive Programming

TBD

===  Example project - Game scoreboard

For the example project for this chapter, we return to the ten-pin bowling and tennis scoring engines that we used in Chapter two, and add a scoreboard feature (well a simple ASCII scoreboard in a console application rather than real hardware).

As the requirement, say we want a console application that displays ASCII scoreboards that look like these examples:

....
Ten-pin

 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
|   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |    10  |
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
| 1| 4| 4| 5| 6| /| 5| /|  | X| -| 1| 7| /| 6| /|  | X| 2| /| 6|
+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+--+
|   5 |  14 |  29 |  49 |  60 |  61 |  77 |  97 | 117 |   133  |
 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
....

....
Tennis

 -----++----+----+----+----+----++--------
|   1 ||  4 |  6 |  5 |    |    ||    30  |
|   2 ||  6 |  4 |  7 |    |    ||  love  |
 -----++----+----+----+----+----++--------
....



As usual in ALA, our methodology begins with expressing those requirements directly, and inventing abstractions to do so. So, we invent a 'Scorecard' abstraction. It will take a configuration which is an ASCII template. Here are the ascii templates that would be used for ten-pin and tennis:

....
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-----------
|   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |   9   |     10    |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|
+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+---+
|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-------------
....

....
 -----++----+----+----+----+----++--------
| M0  ||S00 |S10 |S20 |S30 |S40 || G0---  |
| M1  ||S01 |S11 |S21 |S31 |S41 || G1---  |
 -----++----+----+----+----+----++--------
....

The scorecard ASCII template has letter place-holders for the scores. (A single letter is used so it doesn't take up much space on the template design.) Different letters are used for different types of scores. Digits are used to specify where multiple scores of the same type are arranged on the scoreboard. They are like indexes. Either 1-dimensional or 2-dimensional indexes can be used in the scoreboard template. For example, the frame scores in ten-pin bowling have scores for each ball for each frame, F00, F01 etc, as shown in the example above.

The scorecard abstraction needs functions it can use to get the actual scores. The functions are configured into little 'binding' objects that we then wire to the scoreboard. The binding objects are configured with the letter that they return the score for. 

==== Ten-pin

Having invented the Scorecard and Binding abstractions, we can now do the ten-pin application diagram:
 

[plantuml,file="diagram-bowling-3.png"]
----
@startdot
digraph foo {
rankdir=LR

#note rankdir does not work inside subgraphs
subgraph cluster_C {
fontsize=20
label="Ten-Pin Bowling                                                            "
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter number of pins\""]

scoreboard [fontsize=14,label=<
<table border='0' cellborder='1' cellspacing='0'>
<tr><td colspan="21" sides="B"><font point-size="14">Scorecard</font></td></tr>
<tr><td colspan="2">1</td><td colspan="2">2</td><td colspan="2">3</td><td colspan="2">4</td><td colspan="2">5</td><td colspan="2">6</td><td colspan="2">7</td><td colspan="2">8</td><td colspan="2">9</td><td colspan="3">10</td></tr>
<tr><td sides="LTR">F00</td><td>F01</td><td sides="LTR">F10</td><td>F11</td><td sides="LTR">F20</td><td>F21</td><td sides="LTR">F30</td><td>F31</td><td sides="LTR">F40</td><td>F41</td><td sides="LTR">F50</td><td>F51</td><td sides="LTR">F60</td><td>F61</td><td sides="LTR">F70</td><td>F71</td><td sides="LTR">F80</td><td>F81</td><td sides="LTR">F90</td><td>F91</td><td>F92</td></tr>
<tr><td colspan="2" sides="LBR">T0</td><td colspan="2" sides="LBR">T1</td><td colspan="2" sides="LBR">T2</td><td colspan="2" sides="LBR">T3</td><td colspan="2" sides="LBR">T4</td><td colspan="2" sides="LBR">T5</td><td colspan="2" sides="LBR">T6</td><td colspan="2" sides="LBR">T7</td><td colspan="2" sides="LBR">T8</td><td colspan="3" sides="LBR">T9</td></tr>
</table>
>]

framebind [label="Binding|F"]
totalbind [label="Binding|T"]
game [label="Frame|\"game\"|nFrames==10"]

node [shape=record]
function1 [label="GetSubFrames()\n.Select(sf =\> sf.GetScore()[0])\n.Accumulate()"]
function2 [label="GetSubFrames()\n.Select(f =\> f.GetSubFrames()\n.Select(b =\> b.GetScore()[0])"]
translate [label="Translate\nX,/,- etc"]

console -> game  [label = "IConsistsOf"]
console -> scoreboard [constraint=false, label = "IPullDataFlow"]
scoreboard -> framebind -> translate -> function2 -> game
scoreboard -> totalbind -> function1 -> game

{rank=same console scoreboard}
{rank=same framebind totalbind}
{rank=same function1 function2}

}
}
@enddot
----

An abstraction we didn't mention yet is the ConsoleGameRunner. Its job is to prompt for a score from each play, display the ASCII scoreboard, and repeat until the game completes. 

The 'game' instance of the Frame abstraction on the right of the diagrams is the scoring engine we developed in Chapter Two. Together with this engine, we now have a complete application. 

The rounded boxes in the diagram are instances of domain abstractions as usual for ALA diagrams. The sharp corner boxes are instances of Application layer abstractions. They are the mentioned functions for the Bindings. That code is application specific so goes in the application layer. They just do a simple query on the scoring engine.

Now tranlate the diagram into code. Here is the entire application layer code for ten-pin:
....
consolerunner = new ConsoleGameRunner("Enter number pins:", (pins, engine) => engine.Ball(0, pins))
.WireTo(game)
.WireTo(new Scorecard(
"-------------------------------------------------------------------------------------\n" +
"|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|\n" +
"|    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+----\n" +
"|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |\n" +
"-------------------------------------------------------------------------------------\n")
.WireTo(new ScoreBinding<List<List<string>>>("F", 
    () => TranslateFrameScores(
        game.GetSubFrames().Select(f => f.GetSubFrames().Select(b => b.GetScore()[0]).ToList()).ToList())))
.WireTo(new ScoreBinding<List<int>>("T", 
    () => game.GetSubFrames().Select(sf => sf.GetScore()[0]).Accumulate().ToList()))
);
....

....
....
If you compare this code with the diagram, you will see a pretty direct correspondence. 
Remember 'game' is the reference to the scoring engine project in the previous chapter.

That's pretty much all the code in the application. Oh there is the 'translate' function, but it is pretty straight forward once you know the way a ten-pin scorecard works. For completeness here it is.

....

/// <summary>
/// Translate a ten-pin frame score such as 0,10 to X, / and - e.g. "-","X".
/// </summary>
/// <example>
/// 7,2 -> "7","2"
/// 7,0 -> "7","-"
/// -,3 -> "-","7"
/// 7,3 -> "7","/" 
/// 10,0 -> "",X
/// 0,10 -> "-","/"
/// additional ninth frame translations:
/// 10,0 -> "X","-"
/// 7,3,2 -> "7","/","2"
/// 10,7,3 -> "X","7","/"
/// 0,10,10 -> "-","/","X"
/// 10,10,10 -> "X","X","X"
/// </example>
/// <param name="frames">
/// The parameter, frames, is a list of frames, each with a list of integers between 0 and 10 for the numbers of pins.
/// </param>
/// <returns>
/// return value will be exactly the same structure as the parameter but with strings instead of ints
/// </returns>
/// <remarks>
/// This function is an abstraction  (does not refer to local variables or have side effects)
/// </remarks>
private List<List<string>> TranslateFrameScores(List<List<int>> frames)
{ 
    // This function looks a bit daunting but actually it just methodically makes the above example tranlations of the frame pin scores 
    List<List<string>> rv = new List<List<string>>(); 
    int frameNumber = 0;
    foreach (List<int> frame in frames)
    {
        var frameScoring = new List<string>();
        if (frame.Count > 0)
        {
            // The first 9 frames position the X in the second box on a real scorecard - handle this case separately
            if (frameNumber<9 && frame[0] == 10)
            {
                frameScoring.Add("");
                frameScoring.Add("X");
            }
            else
            {
                int ballNumber = 0;
                foreach (int pins in frame)
                {
                    if (pins == 0)
                    {
                        frameScoring.Add("-");
                    }
                    else
                    if (ballNumber>0 && frame[ballNumber]+frame[ballNumber-1] == 10)
                    {
                        frameScoring.Add(@"/");
                    }
                    else
                    if (pins == 10)
                    {
                        frameScoring.Add("X");
                    }
                    else
                    {
                        frameScoring.Add(pins.ToString());
                    }
                    ballNumber++;
                }

            }
        }
        rv.Add(frameScoring);
        frameNumber++;
    }
    return rv;
}
....


==== Tennis


So now that we have these domain abstractions for doing console game scoring applications, let's do tennis:


////
[plantuml,file="diagram-bowling-4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
#subgraph cluster_C {
label="Ten-Pin Bowling"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
game [label="Frame|\"game\"|nFrames==10"]
bonus [label="Bonus||score\<10 \|\| plays==3"]
frame [label="Frame|\"frame\"|frameNum\<9 && (balls==2 \|\| pins==10)\n \|\|\ (balls==2 && pins\<10 \|\| balls==3)"]
ball [label="SinglePlay"]
game -> bonus -> frame -> ball
}
}
@enddot
----
////


[plantuml,file="diagram-tennis-3.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label="Tennis"
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter winner of play\""]

scoreboard [label="Scoreboard| -----++----+----+----+----+----++--------\n\| M0  \|\|S00 \|S10 \|S20 \|S30 \|S40 \|\| G0---  \|\n\| M1  \|\|S01 \|S11 \|S21 \|S31 \|S41 \|\| G1---  \|\n -----++----+----+----+----+----++--------\n"]

gamebind [label="Binding|G"]
setbind [label="Binding|S"]
matchbind [label="Binding|M"]
match [label="Frame|\"match\"|score.Max()==3"]

node [shape=record]
function1 [label="GetScore()"]
function2 [label="GetSubFrames()\n.Select(sf =\> sf.GetSubFrames().First())\n.Select(s =\> s.GetScore()).ToList()"]
function3 [label="GetGameOrTieBreakScore\n(see function)"]

console -> scoreboard [constraint=false, label = "IPullDataFlow"]
console -> match [label = "IConsistsOf"]
scoreboard -> setbind -> function2
scoreboard -> matchbind -> function1
scoreboard -> gamebind -> function3
function1 -> match
function2 -> match
function3 -> match

{rank=same console scoreboard}

}
}
@enddot
----

////
[plantuml,file="tennis4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
// subgraph cluster_C {
label="Tennis scoring"
style=rounded
#node [style=rounded]

node [shape=Mrecord]
match [label="Frame|\"match\"|score.Max()==3"]
wtp1 [label="WTP"]
set [label="Frame|\"set\"|score.Max()\>=6 && \nMath.Abs(score[0]-score[1])\>=2"]
wtp2 [label="WTP"]
game [label="Frame|\"game\"|score.Max()\>=4 && \nMath.Abs(score[0]-score[1])\>=2"]
play [label="SinglePlay"]
switch [label="Switch||(setNumber\<4 &&\n score[0]==6 && score[1]==6"]
wtp3 [label="WTP"]
tiebreak [label="Frame|\"tiebreak\"|score.Max()==7"]
play2 [label="SinglePlay"]
match -> wtp1 -> switch -> set -> wtp2 -> game -> play
switch:s -> wtp3:w
wtp3 -> tiebreak -> play2
{rank=same set wtp3}

// }
}
@enddot
----
////

I left the code out of the GetGameOrTieBreakScore box as it is a little big for the diagram here. It is similar to the other queries but it must first determine if a tie break is in progress and get that if so. Also it translates game scores from like 1,0 to "15","love".

And here is the code for the Tennis diagram:
....
consolerunner = new ConsoleGameRunner("Enter winner 0 or 1", (winner, engine) => engine.Ball(winner, 1))
.WireTo(match)
.WireTo(new Scorecard(
        "--------------------------------------------\n" +
        "| M0  |S00|S10|S20|S30|S40|S50|S60|  G0--- |\n" +
        "| M1  |S01|S11|S21|S31|S41|S51|S61|  G1--- |\n" +
        "--------------------------------------------\n")
    .WireTo(new ScoreBinding<int[]>("M", () => match.GetScore()))
    .WireTo(new ScoreBinding<List<int[]>>("S", () => 
        match.GetSubFrames()
            .Select(sf => sf.GetSubFrames().First())
            .Select(s => s.GetScore())
            .ToList())
    .WireTo(new ScoreBinding<string[]>("G", () => GetGameOrTiebreakScore(match)))
);

....

If you compare this code with the diagram, you can see a pretty direct correspondence. match comes from the scoring engine project in Chapter two.

==== Concluding notes

Although the diagrams must be turned into text code to actually execute, it is important in ALA to do these architecture design diagrams first. They not only give you the application, they give you the architectural design by giving you the domain abstractions and programming paradigms as well. If you try to design an ALA structure in your head while you write it directly in code, you will get terribly confused and make a mess. Using UML class diagrams will make it even worse. Code at different abstraction levels will end up everywhere, and run-time dependencies will abound. Our programming languages, and the UML Class diagram, are just not designed to support abstraction layered thinking - it is too easy to add bad dependencies (function calls or 'new' keywords) into code in the wrong places.

Note that at run-time, not all dataflows have to go directly between wired up instances of domain abstractions. The data can come up into the application layer code, and then back down. This was the case when we did the functional composition example in Chapter One. In this application we are doing that with the code in the square boxes that get the score from the engine. The important thing is that all the code in the application is specific to the application requirements.  




////


////


////
Now let's have a look at some of the code in the two of the new domain abstractions. Here is the essence of the Scoreboard domain abstraction (remember we are down a layer now, so it has no knowledge of bowling):

....
public string GetScorecard()
{
    var matches = Regex.Matches(ASCIITemplate, "(([A-Z][0-9][0-9])|([A-Z][0-9])|([A-Z]))-*"); // The regular expression matches e.g. A, B1, C12, D-, E00--
    var rv = ASCIITemplate;
    foreach (Match match in matches)
    {
        char id = match.Value[0];
        foreach (IScoreBinding sg in scoreGetters)
        {
            if (id == sg.Label[0])
            {
                if (match.Length>=2 && char.IsDigit(match.Value[1]))
                {
                    if (match.Length >= 3 && char.IsDigit(match.Value[2])) // e.g. A11
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0'), Convert.ToInt32(match.Value[2]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                    else // e.g. A1
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                }
                else // e.g just A, no index
                {
                    rv = rv.Replace(match.Value, sg.GetScore().PadLeft(match.Length));
                }
            }
        }
    }
    return rv;
}
....

The ScoreBinding domain abstraction has three overloads of GetScore - one for two indexes, one for one index, and one for zero indexes. Here is the code for the one that has one index. The other two are similar. Because we are given one index, we expect the function that we have been wired to will return a one dimensional something. It could be a List or array, of type int or string. T tells us what type it is. Our job is to index into whatever it is, and return it as a string:

....
public string GetScore(int x)
{
    object temp = function();
    if (typeof(T) == typeof(List<int>))
    {
        List<int> list = (List<int>)temp;
        if (x < list.Count) return list[x].ToString();
    }
    if (typeof(T) == typeof(int[]))
    {
        int[] array = (int[])temp;
        if (x < array.Length) return array[x].ToString();
    }
    if (typeof(T) == typeof(List<string>))
    {
        List<string> list = (List<string>)temp;
        if (x < list.Count) return list[x];
    }
    if (typeof(T) == typeof(string[]))
    {
        string[] array = (string[])temp;
        if (x < array.Length) return array[x];
    }
    return "";
}
....


////

That completes our discussion of the console applications for ten-pin and tennis. The full project code can be viewed or downloaded here:

https://github.com/johnspray74/GameScoring[GameScoring code]

