:imagesdir: images


== Chapter six - The philosophy behind ALA


=== The human brain

In this perspective of ALA, we look at the problem of complexity in software in the context of how the human brain works.

Software design involves our intelligence or brain power. Understandability, readability, complexity are all things very closely related to the brain. Yet in the field of software engineering we pay little attention to how the brain understands our complicated world in order to understand how we should do our software.

Our brains do it primarily through one mechanism which we have come to call 'abstraction'. We learn abstractions from the commonality of multiple examples, and we then use abstractions without those examples cluttering up the common notion that was learned.

image::Paintings_from_the_Chauvet_cave.jpg[Paintings_from_the_Chauvet_cave.jpg,400, title="Paintings in the Chauvet cave", float="right"]

Our ancestors could use a word like 'bring your spear' and it had a simple meaning to them only because all the detail and knowledge that went into building a spear was replaced with the abstraction 'spear'. Without the abstraction, the sentence would have had to be more like "bring the object that we made by joining the object we made by applying blows to the hard material we found at the place..., with the long material we cut in the place with the tall..., by tying it with the long grass material using the gooey stuff we found at the...". Even this sentence was only made possible by other abstractions: joining, material, blows, hard, long (twice), cut, tall, tying, gooey, and found. If we expanded all of them until we were only using a few basic concepts like 'object' and 'place', we would have a sentence so long that we could never communicate at all. That's what abstractions do, and how our brains make use of them. The word spear, in turn can be used to create a new abstraction, a hunting plan, while all of that other detail remains hidden from that new context.

The problem with software engineering is we are not making use of this way that the brain works. Simply put, we are not creating good abstractions. This lets the complexity inside one 'module' spill out into other modules. Abstractions, not modules, are the only mechanism that allows us to hide details at design-time. 

image::neuron.svg[neuron.svg, 300, title="", float="left"]

As software engineers we do learn and use many abstractions. For example if we want to protect simultaneous access to the resource, our brain should conjure up 'mutex'. 

If the brain already 'knows about' an abstraction, the abstraction is like any other single line of code, such as a mutex. We can make use of a mutex without having to deal with the details and complexities of how it works. We don't have to think about the fact that we may have to wait for the resource. Nor that another thread may start running if we have to wait. Nor that if a higher priority thread preempts us while we have the resource, we may have it for a long time. Nor that if a still higher priority thread needs it during that long time, we will be given temporary priority to finish our use of it. We can just simply use the abstraction for protecting a resource.

Abstractions like mutex, regex, SQL are already invented by the 'culture' of software engineering, much like memes in the real world have been passed down to us. Where we fall down is when we get into a particular domain where the abstractions have not yet been invented, and we need to invent them. It is not easy to invent new abstractions, but invent them we must, at a rate far higher than is normal for cultural evolution.

Good domain abstractions, introduced and learned by new developers in the domain, then appear to them as normal program elements - things they can use with extraordinary convenience like any other line of code.



=== Abstraction

Of the overwhelming list of engineering topics that we listed in Chapter One, this topic that is the most fundamental to ALA, and the one most needed for explaining it. It's also probably the vaguest and most misunderstood topic in software engineering, so we will spend some time understanding it.

Abstraction will be the king. The short reason why we start with abstraction is that our quality attributes, complexity and understandability are very much to do with how our brains work, and for 100,000 years at least, our brains have worked with abstractions to understand our world. Abstractions are the only mechanism our brains use for dealing with otherwise complex things. 

As in a chess game, winning is only about protecting the king. But this Abstraction king is benevolent. If he is destroyed, you do not lose the game immediately. It will take time, but you will lose.

There are other contenders to be king in the engineering topics list. For example, it is said that the best thing about TDD is not the testing but the emergence of better abstractions. TDD is like a lord that serves the king. It usually serves the king, causing you to make better abstractions. But sometimes it just serves its own purpose and makes the abstraction worse. It just produces code that works where it passes and no more.

Another contender is microservices. It is popular because it improves your abstractions by making them harder to destroy with cross coupling. But it too is just a lord. Because it provides physical boundaries that in normal software would be crossed, it serves the king. But by serving the abstraction king directly we can have logical boundaries, and all their benefits, even in 'monolithic' code.

Another contender to be king is 'no side effects' used by the functional mathematical purity guys. There are those who talk as if disobeying this king is absolute treason. But again, this lord is only effective because he usually serves the abstraction king. But, again, there are times when he doesn't, and 'no side effects' is not enough to make a good abstraction.

ALA always follows the one true king.

==== Classes, Modules, functions and encapsulation. 

Classes, Modules, functions and encapsulation are artefacts of the language and do their thing at compile-time. They are not necessarily abstractions. They have been around for about 60 years, not enough time for our brains to see them in the same way as the compiler does. Although abstractions are implemented using these artefacts, ALA needs them to also be abstractions. In ALA "abstraction" is the term we use for the artefacts of our design instead of classes, modules, functions, or components, all of which are extremely fragile as abstractions.  

==== Wikipedia on abstraction

"Thinking in abstractions is considered by anthropologists, archaeologists, and sociologists to be one of the key traits in modern human behaviour, which is believed to have developed between 50 000 and 100 000 years ago. Its development is likely to have been closely connected with the development of human language, which (whether spoken or written) appears to both involve and facilitate abstract thinking."

In the real world, new abstractions come along infrequently, and are conceived of by few. People quickly begin using them to understand new insights or compose new things. They become so natural to us that we forget that they are abstractions. In no other field do we need to create them as fast as in software engineering. It is the most important skill a developer needs to have.

==== Defining abstraction

The term abstraction is arguably one of software engineering's vaguest or most overloaded terms. Because it is the most fundamental concept in ALA, we try to provide a definition. I find the easiest way to define it is to provide a set of 'statements about', 'properties of', or 'what it is nots':

* Etymology: 'to draw out commonality'

* The concept or notion drawn out of what is common in multiple instances

* Because it is a 'commonality', it is inherently reusable. Kruger says that  abstraction and reuse are two sides of the same coin.

* Has inherent stability - as stable as the concept itself

* The only mechanism that separates and hides _design-time_ knowledge

* Its concept or notion is easier to remember than its implementation. For a good abstraction, it is much, much simpler. 

* Abstractness increases with scope of reuse

* Knows nothing about peer abstractions

* use ports (instances or interfaces) for IO instead of directly calling other abstractions.  

* Abstractness decreases with more ports

* Abstractness decreases as you get closer to your specific application

* Abstractness is not how far you are above physical hardware

* An ability our brains evolved understand the world

* The only way we have of dealing with complexity 


==== The three stages of creativity

image::creativity.jpg[creativity.jpg, title="The creativity cycle", width=80%, align="center"]

A good abstraction separates the knowledge of different worlds. A clock is a good abstraction. On one side is the world of cog wheels. On the other side is someone trying to be on time in their busy daily schedule. Neither knows anything about the details of the other. SQL is another good abstraction. On one side is the world of fast indexing algorithms. On the other is finding all the orders for a particular customer. Let us consider a domain abstraction - the calculation of loan repayments. On one side is the world of mathematics with the derivation and implementation of a formula. On the other, the code is about a person wanting to know if they can afford to buy a house. If your abstractions don't separate knowledge of different worlds like this, then you are probably just factoring common code. Find the abstraction in that common code. Make it hide something complicated that's really easy to use and really useful, like a clock.

The creativity cycle starts with abstractions, such as cogs and hands, instantiates them, configures them for a particular use, then composes them into a new abstraction. In ALA we usually go around the creativity cycle three times, creating three layers on top of our base programming language.


==== Abstractions need ports

In traditional programs, inputs (or at least incoming function calls) are typically part of the module or class's interface but outputs (or at least outgoing function calls) are typically just buried in the code.

This is fine if calling functions or methods in a lower abstraction layer. However, it is absolutely not fine if calling functions or methods of a peer in the same abstraction layer. 

In ALA all inputs and outputs to or from peers in the same layer must be 'ports'. 
There should be one port for each peer that can be wired. This is the Interface Segregation Principle. A port is a logical wirable connection point. A port either implements or accepts an interface. Outgoing function calls buried in the code that at run-time will go to a peer must only go to the port, which has an indirection mechanism of some kind.

Programming languages encourage all outgoing function or method calls to refer directly to the destination, or the destination's interface, so you have to make an effort to avoid doing this.

A port is not an artefact of programming languages (yet) so they must be implemented logically somehow as normal code. To code a logical port, you need to do two things. 

. The interface type of the port must not be owned by another peer abstraction. The interface type must be from a lower abstraction layer.

. The name of the port is the name of the field that accepts the interface.

A port can have multiple interfaces. In this case I make the names of the multiple fields contain the port name.


If you are using an asynchronous event driven design, the equivalent of a conventional outgoing function call is typically written something like this:

 Send(Event, Receiver, Priority);

where the Event is something the receiver defines. 

Again, we are sending the event directly to a peer abstraction using the peer abstraction's interface (its event).

In ALA, sending an event should be self-oriented, so written something like this:

 Send(Sender, SenderPort)

The sender just sends the event out, not knowing where it goes, and the port identifies the event (or you could have both port and event). This just tells the event framework who the sender and sender's port was. The event framework gets information from the application in the top layer to know what to do with the event. The application has the specific knowledge to know what an event from a given sender on a given port means, and therefore where it should go, and what the priority should be.

In general, classes, modules, components, functions should all have ports for both input and output. They should not own the interface types for these ports, whether they are incoming or outgoing. 

An output port from an abstraction may say 'This has happened' or 'Here is my result', not 'do this next', or 'here is your input'.

There are multiple ways to implement the indirection inherent in ports for outgoing calls. They can be callbacks, signals & slots, dependency injection, or calls to a framework send function.

Note that inputs and outputs are not necessarily on different ports. We may want to wire both inputs and outputs between two instances or two abstractions with a single wiring operation. The general case is that a single wiring operation wires multiple interfaces that are logically one port. One contains methods going in one direction and the other contains methods going in the other.   



=== Complexity

==== Philosophy of complexity



==== Dijkstra on complexity

anchor:Dijkstra1[]

"It has been suggested that there is some kind of law of nature telling us that the amount of intellectual effort needed grows with the square of program length. But, thank goodness, no one has been able to prove this law. And this is because it need not be true. We all know that the only mental tool by means of which a very finite piece of reasoning can cover a myriad cases is called “abstraction”; as a result the effective exploitation of his powers of abstraction must be regarded as one of the most vital activities of a competent programmer. In this connection it might be worth-while to point out that the purpose of abstracting is not to be vague, but to create a new semantic level in which one can be absolutely precise. Of course I have tried to find a fundamental cause that would prevent our abstraction mechanisms from being sufficiently effective. But no matter how hard I tried, I did not find such a cause. As a result I tend to the assumption —up till now not disproved by experience— that by suitable application of our powers of abstraction, the intellectual effort needed to conceive or to understand a program need not grow more than proportional to program length."

The "conceive" part I agree with, if by that we mean the development. However, the "intellectual effort to understand" part needs further insight. We shouldn't have to read an entire program to understand a part of it. We ought to be able to understand any one part of it in isolation. The effort to read any one part should be approximately constant. In Chapter One of this article there was a quality graph of complexity <<ComplexityGraph1, here>>.

anchor:ComplexityGraph2[]

[chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC,legend=right"]
--
//Big ball of mud
1,	10
2,	20
5,	50
10,	100
20,	200
50,	500

//Loosely coupled
1,	10
2,	14
5,	22
10,	32
20,	45
50,	71
100,100
200,141
500,224
1000,316

//ALA
1,	10
2,	11
5,	12
10,	13
20,	13
50,	15
100,16
200,17
500,19
1000,20

//Code writer's brain limit
1,	100
2,	100
5,	100
10,	100
20,	100
50,	100
100,100
200,100
500,100
1000,100

//Code reader's brain limit
1,	50
2,	50
5,	50
10,	50
20,	50
50,	50
100,50
200,50
500,50
1000,50
--

These graphs are qualitative in nature, based on experience. But now that we have a better understanding of ALA structure, we can explain how it manages to keep complexity from increasing.

In ALA, the design-time view of the system is nothing more than a static view of instances of abstractions composed together. In a typical application, there will be of the order of fifty different domain abstractions - not a difficult number to familiarize yourself with in a new domain. 

Abstractions have no relationship with one another. Each is a standalone entity like a standalone program. If every abstraction contains say 500 lines of code, and the system itself contains 500 lines (instances of abstractions wired together) then the most complex the software gets is that of 500 lines of code.

Even if one abstraction is overly complex internally, say it conceals a piece of legacy code using a facade pattern, that doesn't affect the complexity of any other part of the system.

ALA is based on the realization that abstraction is fundamentally the only mechanism available to us to achieve this constant complexity. 

When doing this for the first time in a domain, it's not easy to invent the abstractions. but the alternative is always runaway complexity.

[TIP]
====
The goal of software architecture should be to keep complexity constant. 
====




=== No Loose Coupling

Here we meet the first meme from our list of software engineering topics that we must throw out. To many, this will seem a surprising one. Yes, I am saying 'loose coupling' is undesirable.

==== A common argument

An argument is sometimes stated along these lines: "There must be at least some coupling, otherwise the system wouldn't do anything." Hence we have the common meme about "loose coupling and high cohesion". In this section we show how this argument is false and resolve the apparent dilemma. We will eliminate all forms of design-time coupling except one. That one remaining one is anything but loose and very desirable.



==== Classifying coupling

Think of some instances of dependencies you know of in a system and try to classify them into these three types by asking when the system would fail without it. 

For example, let's say that data flows from an ADC (analog to digital converter) to a display as part of a digital thermometer. At run-time, both must exist. At compile-time both must have the same method signature:

[plantuml,file="diagram-01.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
ADC -> display [dir=forward, arrowhead=open, color=red]
}
@enddot
----

Or the display may tell the ADC when to do the conversion. At run-time there is temporal coupling. 

[plantuml,file="diagram-02.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
ADC -> display [dir=both, arrowhead=none, arrowtail=open, color=red]
}
@enddot
----

In this one there is an association from a Customer class to an Account class to facilitate communication between them. At run-time there is coupling. At compile-time there is coupling too - the type of the Account class must be exactly the same as expected by the Customer class:

////
[plantuml,file="diagram-03.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
Customer [shape=box]
Account [shape=box]
Customer -> Account [dir=forward, arrowhead=open, color=red]
}
@enddot
----
////

[plantuml,file="diagram-04.png"]
----
scale 2
class Customer
class Account
Customer->Account
----


In all the above diagrams, relationships shown in red indicate they are disallowed by the ALA constraints. Green is for desirable relationships, of which there is only one. When we disallow all these types of coupling, the modules, components, functions and classes can now be abstractions.


==== Run-time, Compile-time and Design-time

A few times already in the article, I have sneaked in a magic qualifier, 'design-time'. You know how we sometimes talk about run-time and compile-time with reference to binding. In ALA we recognise that understandability, complexity, etc, are all happening at design-time. By design-time I mean any time you are reading code, writing code, or changing code.

At run-time, the CPU processes data. At compile-time, the compiler processes code. At design-time the brain is processing abstractions. 

In conventional code, it is common for all forms of coupling, run-time, compile-time, and design-time, to appear as coupling between modules or classes.

You can work out what type of dependency you have by when it first breaks. A run-time dependency doesn't break until the program runs. The program can still be compiled and it can still be understood. 

A compile-time dependency first breaks at compile-time. At design-time the code can still be understandable. 

A design-time dependency prevents code from even being understood. The code loses its meaning. 


==== Layers

In everyday design, knowledge dependencies are not normally shown as lines. You simply use the abstraction by its name. But in this article, just so we can explain the meta-architecture, we will sometimes draw knowledge dependencies like this (always downward).

[plantuml,file="diagram-05.png"]
----
@startdot
digraph foo {
// size="3!"
C -> A [dir="both", arrowhead="open", arrowtail="diamond", color=green]
}
@enddot
----

This represents that the implementation of abstraction C knows about abstraction A. A is more abstract than C. C and A cannot therefore be peers, as was the case with the components above. Peer abstractions cannot have any coupling with one another.

==== Whole-Part pattern

If you are familiar with the Whole-Part pattern, ALA uses it extensively. But there is a constraint. The Whole-Part pattern is only used with knowledge dependencies (since that is the only relationship you are allowed). It may of course be used in other forms inside an abstraction, provided it is completely contained in a single abstraction.

A real world example of the Whole-Part Pattern with knowledge dependencies is Molecules and Atoms. A water molecule, for example, is the whole. 

[plantuml,file="diagram-06.png"]
----
@startdot
digraph foo {
// size="5!"
edge [color=green]
H2 [label=H]
Water -> O [dir="both", arrowhead="open", arrowtail="diamond"]
Water -> H [dir="both", arrowhead="open", arrowtail="diamond"]
Water -> H2 [dir="both", arrowhead="open", arrowtail="diamond"]
}
@enddot
----

Oxygen and hydrogen are the parts. Note that oxygen and hydrogen are abstractions, and they are more abstract than water because they are more ubiquitous, more reusable and more stable (as a concept) than any specific molecule. We could make a different molecule but still use exactly the same oxygen and hydrogen as parts to compose the new molecule.

NOTE: When we use the word 'ubiquitous', it refers to the number of times the abstraction is used in a Whole-Part pattern to make other abstractions. It doesn't refer to the number of abstractions that are instantiated. So just because there is a lot of water, that doesn't make the abstraction ubiquitous. In comparing the abstraction levels of Oxygen and Hydrogen with water, Oxygen and Hydrogen are more ubiquitous because they are used to make more abstractions than water is.  

The molecules and atoms analogy with ALA is very close, and we will return to it when we come to explain in more detail how run-time and compiler-time dependencies are moved inside a single abstraction.

For now we just need to remember that we are using the whole-part pattern with knowledge dependencies only. At design-time, the whole is explained and reasoned about in terms of the parts, just as the water molecule is in terms of the oxygen and hydrogen.

==== Run-time/design-time congruence

A software program can be temporally confusing. Everything that happens at design-time is in preparation for what will happen at run-time. Our low-level imperative languages tend to keep the two congruent. The statements in the program at design-time follow in the same order as they will execute at run-time. The only difference between the two is a time shift and the speeding up of the clock.

When we want the knowledge of run-time dependencies to be moved inside another abstraction, this congruence between design-time and run-time must be broken. Unfortunately, developers start out by learning a low-level imperative language, so it becomes unnatural to them to architect their programs without this congruence. Indeed, breaking this congruence needs a pattern to be learned, and then carefully protected from the temptations of our imperative languages. I call it the Ẃiring pattern'.

Before going into the pattern, we need to round out the most important aspects of ALA.


=== Wiring pattern - Part one

We now introduce the pattern that both solves the congruence problem just discussed in the previous section, and provides the alternative to all those disallowed coupling types discussed earlier. This pattern is usually an important part of ALA. 

Note: The wiring pattern is not necessarily a part of an ALA architecture. For example, if your whole problem is just an algorithm, and therefore suits a functional programming style, then you can still compose abstractions with function abstractions, provided all function calls are knowledge dependencies, and not say, just passing data or events. 

If you are using monads, especially I/O monads, or RX (reactive extensions), especially with hot observables, you are already using the wiring pattern. The pipes and filter pattern is also an example of the wiring pattern. Labview or Node-Red can use the wiring pattern. There are many other examples of the wiring pattern. Most support a data-flow programming paradigm. Here we generalise the pattern to support any programming paradigm. 

The wiring pattern may be the same as the "Component Pattern" in some literature if used with what is referred to as 'configurable modularity' or 'abstracted interactions'. 

The wiring pattern allows lines on your application diagram to mean any programming paradigm you want that express your requirements. It also allows you to implement multiple programming paradigms together in the same diagram.

If you are using dependency injection with explicit code for the wiring (not auto-wiring), then you are half way there. 

The wiring pattern separates design-time/run-time congruence. It works by having a 'wiring-time' that is separated from run-time. 'Wiring-time' can happen any time before run-time. It can happen immediately before it, as for instance in LINQ statements or RX with a cold observable. It becomes powerful when we make wiring-time congruent with design-time. Usually the wiring code will actually run at initialization time, when the program first starts running. That initialization code becomes the architectural design.   

Let's suppose you have designed your system with two modules, A and B. There will be one of each in your system.

[plantuml,file="diagram-07.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
A -> B [color=red]
}
@enddot
----

At run-time we know that A will talk to B. So we design A to have an association with B. The association may first appear on a UML model, or it may go straight into the code something like this:


 static component A
 {
    B_method();
 }

 static component B
 {
    public B_method() { }
 }

A and B may be implemented as non-static, with only one instance of each. The association is still there.

 component A
 {
    private var b = new B();
    b.method();
 }

 component B
 {
    public method() { }
 }

A may create B itself, which is a composition relationship, as above. Or A may have a local variable of type B passed in by some kind of dependency injection, which is still an association relationship.

 component A
 {
    B b;
    public setter(B _b) {b = _b}
    b.method();
 }

Note that although dependency injection was used, it only eliminated part of the dependency, that of which particular subtype of B it is going to talk to, but A still knows the general type B, which is not allowed in ALA. (Part of the problem here is that A and B were probably arrived at by decomposition, and so they have subtle knowledge of each other, for example of how they collaborate.)

If A and B are collaborating, they are not abstractions. Their knowledge of each other at design-time (to enable their relationship at run-time) binds them to each other so that neither can be reused in any other way. And if they can't be reused, they can't be abstract. 

Let's revisit the water molecule analogy we discussed earlier for the Whole-Part pattern, and develop it further to be clearer how these dependencies affect abstractions. Let's say we have decomposed water into two components, Oxygen and Hydrogen. Oxygen will talk to Hydrogen to get an electron, so we write:

 component Oxygen 
 {
    var h1 = new Hydrogen();
    var h2 = new Hydrogen();
    h1.getElectron();
    h2.getElectron();
 }

The diagram for that looks like this:

[plantuml,file="diagram-08.png"]
----
@startdot
digraph foo {
// size="4!"
edge [color=red]
H2 [label=Hydrogen]
Oxygen -> Hydrogen [dir="both", arrowhead="open", arrowtail="diamond"]
Oxygen -> H2 [dir="both", arrowhead="open", arrowtail="diamond"]
}
@enddot
----

In the real world, oxygen is a very useful abstraction for making other molecules. In writing code this way to make water, we have tied it to hydrogen. Oxygen can't be used anywhere else, at least not without bringing with it two hydrogens, rendering it useless. By implementing the Oxygen-Hydrogen relationship needed to make water in oxygen, we have destroyed the oxygen abstraction. We never even made the water abstraction. To understand water, we would have to read the code inside oxygen, where the parts about water have become entangled with the inner workings of oxygen, protons and neutrons and all that stuff. Oxygen is also used to make caffeine. We could never make coffee!

image::caffeine%20molecule.png[Caffeine molecule.png, 300,title="caffeine - oxygen atoms are red"]

Abstractions are fragile and get destroyed easily, so we have to take care to protect them. What we needed to do was to put the knowledge about the relationship between oxygen and hydrogen to make water in a new abstraction called Water.

[plantuml,file="diagram-09.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
Water -> Oxygen
Water -> Hydrogen
}
@enddot
----


In general, to break coupling between peer modules A and B, we move the knowledge of the coupling to a higher level abstraction (less abstract level) where it belongs. Let's call it C. C is a more specific abstraction. The knowledge is encapsulated there - it never appears as a dependency of any kind. And it is cohesive with other knowledge that may be contained inside abstraction C.

[plantuml,file="diagram-10.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
A -> B [color=red]
}
@enddot
----

becomes


[plantuml,file="diagram-11.png"]
----
@startdot
digraph foo {
// size="4!"
edge [color=green]
C -> A
C -> B
}
@enddot
----

The diagram above is only to show the ALA knowledge dependency relationships between the three abstractions. It doesn't yet show explicitly that an instance of Abstraction A will be wired to an instance of Abstraction B. In practice we never actually draw knowledge dependencies. We are just doing so here to show how ALA works. We would draw it in this way instead:

[plantuml,file="diagram-12.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=C
style=rounded
A -> B [color=green]
}
}
@enddot
----

[plantuml,file="diagram-13.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
A -> B [style=invis]
#a -> b [color=red]
}
@enddot
----

Now we have the explicit wiring. It looks a lot like the original diagram where we had no C. But where the knowledge is coded is very different. Because it is C and not A that has the knowledge of the relationship between A and B, Abstractions A and B do not change. They continue to know nothing of the connection. They remain abstractions. They remain re-usable.

It may seem at first that adding the extra entity C is a cost, but in fact C is an asset. It shows the structure of the system. It shows it explicitly. It shows it in one small understandable place. And it is executable - it is not a model.

The original abstractions were left below C to show that they still exist as free abstractions to be used elsewhere. They are not contained by C in any way as modules from a decomposition process would be. The A and B inside C are only instances. We wouldn't normally bother to draw the abstractions below. So we just draw this:

[plantuml,file="diagram-14.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=C
style=rounded
A -> B [color=green]
}
}
@enddot
----

C must achieve the connection between A and B either at compile-time or run-time. With current languages, the easiest time to do this is at initialization time, when the program first starts running. This is similar to dependency injection, except that we are not going to inject the instance of B into A.  

This is what the code inside C might look like:

 Abstraction C
 {
    var a = new A();
    var b = new B();
    a.wireTo(b);
 }

Typically we will write the code using the fluent pattern, with the wireTo method always returning the object on which it is called, or the wireIn method always returning the object wired to. The constructor already returns the created object by default. 

 Abstraction C
 {
    new A().wireTo(new B());
 }

If A and B are static modules, this produces something like:

 Abstraction C
 {
    A_setcallback(B_method);
 }


=== Wiring pattern - part two 

We are half-way through explaining the wiring pattern. Now we turn our attention to how A and B can communicate without knowing anything about each other. 

This part of the pattern is also called "Abstract Interactions"

Of course, one way is that C acts as the intermediary. This way is less preferred because it adds to C's responsibilities. But it is sometimes necessary if there are some abstractions brought in from outside. Such abstractions will 'own' their own interfaces or may come with a contract which C will have to know about. C will usually have to wire in an adapter, or handle the communications between the two abstractions itself.

A better way, because it leads to an architectural property of composability, is that A and B know about a 4th abstraction that is more abstract than either of them. This is legal because it is a design-time knowledge dependency.  Let's call it I. 

[plantuml,file="diagram-15.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2!"
C -> A
C -> B
A -> I
B -> I
}
@enddot
----

I is an interface of some kind. It may or may not be an actual artefact. What it must be is knowledge that is more abstract than A and B and therefore knows nothing of A and B. It is more ubiquitous and more reusable than A and B are. In other words we can't just design I to meet the particular communication needs of A and B. That would cause A and B to have some form of coupling or collaboration with each other, and again destroy them as abstractions. 

I is so abstract, ubiquitous and reusable, that it corresponds to the concept of a programming paradigm. We will cover programming paradigm abstractions in following sections because they are a critically important part of ALA. We will see that ALA is polyglot with respect to programming paradigms.

image::circuit%20diagram.gif[circuit diagram.gif, title="In an electronic schematic, the components are abstractions that are composed using two paradigm interfaces - live analog signals and live digital signals"]

Returning to a software example, let's choose a single simple programming paradigm: activity flow. This programming paradigm is the same as the UML Activity diagram. When we wire A to B and they use this paradigm, it means that B starts after A finishes. If A and B accept and provide this interface respectively, then wiring them together by drawing an arrow will have that meaning, and cause that to happen at run-time.

[plantuml,file="diagram-16.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
size="2!"
subgraph cluster_C {
label=C
style=rounded
A -> B [label="activity flow", color=green]
}
}
@enddot
----
It is easy to create an interface for the activity-flow programming paradigm. It has a single method, let's call it 'start'. Many abstractions at the level of A and B can either provide or accept this paradigm interface. Then instances of them can be wired up in any order and they will follow in sequence just like an Activity diagram. 

Note that the Activity Diagram is not necessarily imperative in that any Activity can take an amount of time to complete that is not congruent with the actual CPU execution of code. In other words activities can be asynchronous with the underlying code execution, and for example, delay themselves during their execution, or wait for something else to finish, etc.  

The code in Abstraction A could look something like this. Don't take too much notice of the exact method used to accomplish the wiring. There are many ways to do this using only knowledge dependencies. The important thing is that A continues to know nothing about its peers, continues to be an abstraction, and yet can be wired with its peers to take part in any specific activity flow sequence:

....
 Abstraction A : IActivity
 {
    private IActivity next = null;
    
    public IActivity wireTo(IActivity _next) 
    {
        next = _next;
        return _next;
    }
    
    IActivty.start()
    {
        // start work
    }
    
    // code that runs when work is finished.
    // may be called from the end of start, or any time later
    private finishedWork()
    {
        if (next!=null) next.start();    
    }
 }
....

Abstraction A both _provides_ and _accepts_ the interface. This allows it to be wired before or after any of its peer abstractions. In ALA we use the word 'accepts' rather than 'requires' because there is often an end to a chain of abstraction instances wired together. If no next interface is wired in, the activity flow ends. 

Abstraction B would be written in the same way, as it also knows about the Activity flow interface:
....
 Abstraction B : IActivity
 {
    private IActivity next = null;
    
    public IActivity wireTo(IActivity _next) 
    {
        next = _next;
        return _next;
    }
       
    IActivty.start()
    {
        // start work
    }
    
    // code that runs when work is finished.
    // may be called from the end of start, or asychronously later
    private finishedWork()
    {
        if (next!=null) next.start();    
    }
 }
....

NOTE: As an aside, in C# projects, we wrote wireTo as an extension method for all objects. It used reflection to look at the private interface variables in the source class and the interfaces provided by the destination class. It would then match up the interface types and do the wiring automatically. It could even use port names to explicitly wire ports of the same types.   

Now let's revisit the molecule analogy. By now we would know to put the knowledge that Oxygen is bonded to two Hydrogens inside the water abstraction where it belongs.

[plantuml,file="diagram-17.png"]
----
@startdot
graph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=Water
style=rounded
edge [color=green]
H2 [label=Hydrogen]
Oxygen--Hydrogen
Oxygen--H2
}
}
@enddot
----

In terms of knowledge dependencies it means this:

[plantuml,file="diagram-18.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
Water -> Oxygen
Water -> Hydrogen
Oxygen -> PolarBond
Hydrogen -> PolarBond
}
@enddot
----

The programming paradigm here is a polar bond. It is more abstract (more ubiquitous and reusable) than any particular atom.  We could have a second programming paradigm, a covalent bond, as well. Again, the important thing here is not what the code does - that is arbitrary (and not actually correct chemistry) but how the atoms can be made to interact while retaining their abstract properties with only design-time knowledge dependencies:


 Abstraction PolarBond
 {
    GiveElectron();
 }

....
 Abstraction Oxygen
 {
    private PolarBond hole1 = null;
    private PolarBond hole2 = null;
    
    public Oxygen wireIn(PolarBond _pb) 
    {
        if (hole1==null) hole1 = _pb; else
        if (hole2==null) hole2 = _pb;
        return this;
    }
       
    public Initialize()
    {
        if (hole1!=null) { hole1.getElectron(); BecomeNegativelyCharged(); }
        if (hole2!=null) { hole2.getElectron(); BecomeNegativelyCharged(); }
    }
 }
....
....
 Abstraction Hydrogen : PolarBond
 {
    PolarBond.getElectron()
    {
        BecomePositivelyCharged();
    }
 }
....
....
 Abstraction Water
 {
    new Oxygen()
        .wireTo(new Hydrogen())
        .wireTo(new Hydrogen())
        .Initialize();
 }
....

Let's do one more example, this time with a Data-flow programming paradigm. I have found that data-flow is the most useful programming paradigm in practice. It is useful in a a large range of problems. 

Let's construct a thermometer. Assume we already have in our domain several useful abstractions: an ADC (Analog Digital Converter) that knows how to read data from the outside world, a Thermistor abstraction that knows how to linearise a thermistor, a Scale abstraction that knows how to offset and scale data, a filter abstraction that knows how to smooth data, and a display abstraction that knows how to display data.

All these domain abstractions will use the Data-flow programming paradigm. Note that none of them know anything about a Thermometer, nor the meaning of the data they process.

So we can go ahead and create a Thermometer application just by doing this:

[plantuml,file="diagram-19.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label=Thermometer
style=rounded
#node [style=rounded]
node [shape=Mrecord]
ADC [label="<f0> ADC|<f1> Port=2|<f2> Pin=3|<f3> Frequency=1kHz"]
Thermister [label="<f0> Thermister|<f1> Type='K'|<f2> InputRange=20-1023"]
Scale [label="<f0> Scale|<f1> Offset=32|<f2> Slope=0.013"]
Display [label="<f0> FloatDisplayField|<f1> Digits=4|<f3> Decimals=1"]
ADC -> Thermister -> Scale -> Display
}
}
@enddot
----

Note that we configure all the abstraction instances for use in the Thermometer by adding configuration information into rows on the instances.

When we manually compile the diagram (assuming we don't have automated code generation), it might look something like this (again using fluent coding style):

 Abstraction Thermometer
 {
    new ADC(Port2, Pin3)
        .setFrequency(1000)
        .wireTo(new Thermister().setType('K').setInputRange(20,1023)
            .wireTo(new Scale(32,0.013)
                .wireTo(newDisplay().setDigits(4).setDecimals(1))
            )
        );
 }

NOTE: The configuration setters and the WireTo extension method return the object on which the call is made to support the fluent coding style.

The diagram is the requirements, the solution and the architecture of the application, and is executable. The diagram has all the cohesive knowledge that is a thermometer, and no other knowledge.

The diagram can be read stand-alone, because all the dependencies in it are knowledge dependencies on abstractions we would already know in the domain.

Let's say when the Thermometer runs, there is a performance issue in that the ADC is producing data at 1kHz, and we don't need the display to be showing Temperatures at that rate. Also the temperature readings are noisy (jumping around). Let's make a modification to the Thermometer by adding a filter to reduce the rate and the noise: 

[plantuml,file="diagram-20.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label=Thermometer
style=rounded
#node [style=rounded]
node [shape=Mrecord]
ADC [label="<f0> ADC|<f1> Port=2|<f2> Pin=3"]
Filter [label="<f0> LowPassFilter|<f1> Cutoff=1000"]
Thermister [label="<f0> Thermister|<f1> Type='K'|<f2> InputRange=20-1023"]
Scale [label="<f0> Scale|<f1> Offset=32|<f2> Slope=0.013"]
Display [label="<f0> FloatDisplayField|<f1> Digits=4|<f3> Decimals=1"]
ADC -> Filter -> Thermister -> Scale -> Display
}
}
@enddot
----

If the domain abstractions are not already implemented, we have got the architecture to the point where we can ask any developer to implement them, provided we first give them knowledge of ALA and of the programming paradigm(s) being used.

But let's look how the data-flow paradigm might work.

NOTE: If you are familiar with RX (Reactive extensions) with a hot observable source (which is an example of the wiring pattern), this is similar in concept although RX tries to have duality with for-loops iterating through the data. The data-flow paradigm we set up here will just be a stream of data. The IDataFlow interface corresponds to IObserver, and the wireTo method corresponds to the Subscribe method.

NOTE: The ideal would be a language where we don't have to decide if the data-flow will be push or pull, synchronous or asynchronous, buffered or unbuffered or other characteristics of communications. The abstractions would not need to know these things - they would just have logical I/O ports, and the type of communications could be binded in at compile-time as part of the performance configuration of the system.

NOTE: Later we will introduce an asynchronous (event driven) execution model. It is preferable to do the data-flow paradigm interface using that because it allows better performance of other parts of the system without resorting to threads.    

For simplicity, we will just implement a synchronous push system. Again, don't worry about the filter itself. The code is just there to see how the LowPassFilter fits in with the Data-flow programming paradigm, and how simple doing that can be. 

 Interface IDataFlow<T>
 {
    push(T data);
 }

....
 /// LowPassFilter is a Data-Flow paradigm decorator to be used in an ALA archtecture.
 /// 1. Decimates the incoming data rate down by the setCutoff configuration
 /// 2. Smooths the data with a single pole filter with cutoff frequency equall to the input frequency divided by the cutoff. T must be a numeric type.
 /// Normal checks and exceptions removed to simplify
 Class LowPassFilter<T> : IDataFlow<T>
 {
    private Dataflow next;
    
    // This is normally done by a general extension method
    public IDataflow wireTo(IDataflow _next) 
    {
        next = _next;
        return _next;
    }
    
    integer cutoff;
    
    setCutoff(integer _cutoff)
    {
        cutoff = _cutoff;
    }
    
    int count = 0;
    T filterState = NAN;
       
    IDataFlow.push(T newData)
    {
        if (filterState==NAN) filterState = newData * cutoff;
        filterState = filterState - filterState/cutoff + newData;
        count++;
        if (count==cutoff)
        {
            count = 0;
            if (next!=null) next.push(filterState/cutoff);
        }
    }
 }
....

You will notice that both the Domain abstraction, Filter, and the Programming Paradigm abstract interface, IDataFlow, use a parameterised type. This makes sense because only the application, the Thermometer, knows the actual types it needs to use.  

////
Suppose we wanted to do something more with the programming paradigm, let's say to support fan-out of the data so that multiple domain abstractions can be wired to the same data stream output. 
////
////
TBD: change the following code to use an intermediary (framework) abstraction to support fan-out using publish/subscribe, and asynchronous calls (event driven programming paradigm), and allow the framework to work without using parameterised types by using a capsule pattern, just to show that can be done. 


 Abstraction LowPassFilter<T> : IDataFlow<T>
 {
    private Dataflow next = new DataFlow();
    
    public IDataflow wireTo(IDataflow _next) 
    {
        if (next==null) next = new DataFlow();
        next = _next;
        return _next;
    }
    
    integer cutoff;
    
    setCutoff(integer _cutoff)
    {
        cutoff = _cutoff;
    }
    
    int count = 0;
    T filterState = NAN;
       
    IDataFlow.push(T newData)
    {
        if (filterState==NAN) filterState = newData * cutoff;
        filterState = filterState - filterState/cutoff + newData;
        count++;
        if (count==cutoff)
        {
            count = 0;
            if (next!=null) next.push(filterState/cutoff);
        }
    }
 }
////


=== Expression of requirements

One of the fundamental aspects of ALA is that the abstraction level of the application is fixed and defined by:

[TIP]
====
The succinct [green]#*description*# of [green]#*requirements*#
====

This is a similar concept to a DSL (but not quite the same). If the abstraction level were more specific, we wouldn't have the versatility to describe changing requirements or new applications in the domain (too expressive). If it were were more general, we would have to write more code to describe the requirements (not expressive enough).

I noticed during 40 years of code bases written at our company, two did not deteriorate under maintenance. They always remained as easy to maintain as they were in the beginning, if not easier. All others deteriorated badly. Some deteriorated so badly that they could no longer be maintained at all. At the time we din't know why and could not predict which way it would go. It seemed as if you just got lucky or unlucky. 

Perhaps it was the type of changes that came along? But the two code bases that were easy to maintain seemed to be easy for any kinds of change. And the ones that were hard were hard for any change. This continued to hold for years on end. Of course, most changes were changes to requirements, but often enough, changes would be for performance or other reasons. These also seemed easy in these two code bases, but hard everywhere else.

I began to look at the structure and style of the easy and hard code. The easy code was not complicated while the hard code had degenerated well into the complex. The two easy code bases were doing very different things in very different ways, so there was apparently not a common structure or style. But they did have one thing in common. The code that represented the knowledge of the requirements was separated out. That code _only_ described requirements, and it was expressed in terms of other things that were relatively independent, reusable and easy to understand (what we call abstractions). 
 
This is what first gave rise to one of the core tenets in ALA. The first separation is not along the lines of functional or physical parts of the system, such as UI, Business logic, and Data model. The first separation is code that just describes requirements.

Of course this has a strong parallel with how DSLs work. Is ALA just DSLs? There are several differences. Firstly in ALA we don't try to create a sandbox language for a domain expert to maintain applications. We don't go as far as an external DSL. It's for the developer and we don't want to cut him off from the power he already has when it is needed. We just give him a way to organise the code and a process to get him there - describe the requirements knowledge in terms of abstractions and then trust that those abstractions, when written, will make it work.


=== No two modules know the meaning of data or a message. 

The two modules will have collaborative knowledge. We reason that the sender must know the meaning to formulate the message, and the receiver must know the meaning to interpret the message. So how can it be avoided? The answer is to make the sender and receiver in same abstraction. They both know the same knowledge, so they are cohesive, so they should be together. In the logical view of the system, they are two instances of the one abstraction. We let the physical view fact that the sender and receiver will be deployed in different places drive them to be different modules. 





=== Expressiveness

Requirements are usually understated initially in terms of abnormal conditions. However, they are usually communicated quite quickly relative to the time to write the code. In ALA, they are separately represented. The precise expression of the requirements using the right programming paradigms should take about the same amount of information as the English explanation of them.

In general, ALA probably requires about the same amount of total code. But once the requirements are represented, the domain abstractions are known and they are independent small programs with dependencies only on the programming paradigm interfaces used. This independence should make them much easier to write. As the system matures, the effort to modify gets less as more domain abstractions come on line as tested, mature and useful building blocks. The final cost of maintenance should be much less than an equivalent ball of mud architecture.





=== No models

[IMPORTANT]
====
Leave out details only inside abstractions
====

It is generally accepted that a software architecture must, by necessity, leave out some details. Somehow we need to find a satisfactory architecture without considering all the details. Often models are used to represent the architecture. Like its metaphor in the real world, a model leaves out details. The problem is they can leave out arbitrary details. We can't be sure that some omitted detail won't turn out to be important to the architectural design.

ALA therefore does not use the model metaphor. Instead, it uses diagrams (if not plain old text). Of course, this distinction comes down to semantics. I define a diagram as different from a model in that it does not leave out details arbitrarily. The only way to leave out details in an ALA diagram is inside the boxes, in other words inside abstractions. Because abstractions already have the required meaning when used in the diagram, the details omitted can't be important to the diagram, and can't affect the architectural design.

==== Executable architecture
[IMPORTANT]
====
Your architecture should be executable
====

The distinction between diagrams and models explained in the previous section gives rise to an interesting property of the ALA architecture. Diagrams are executable. Therefore the architecture itself will be executable. When the implementation of the abstractions is complete, there will be no work left to do to make the architecture execute (apart from practical considerations of bugs, misinterpretations of the requirements, performance issues, improvements to the initially conceived set of domain abstractions, and the like).

There should be two aspects of an architecture, the meta-architecture and the specific architecture. If using ALA, ALA itself is the meta-architecture and the top level application diagram is the specific architecture.  

If your specific architecture is executable, it is also code. There is no separate documentation or model trying to act as a second source of truth.

==== Granularity

The final architecture of your software will consist only of abstractions. These abstractions will need to be independently readable and understandable. To meet this need, all of the abstractions will be small, even the 'system level' ones.   

Conversely, none should be too small. We want them small enough to allow the human brain to understand them, but there is no need for them to be smaller, or we will just end up with an inordinate number of them. This inordinate number will tax the brain in a different way, by causing it to have to learn more abstractions than necessary in a given domain.

The ideal abstraction size is probably in the range of 50 to 500 lines of code.


==== Modules, Components, Layers 

The common terms, modules, components, or layers often result from a decomposition process and therefore are parts of a specific system. The system may have only one of each type. The parts have a lower abstraction level than the system because they are just specific parts of it. In ALA we want to reverse this so that parts are more abstract than the system. 

But say you do end up with some single use abstractions and implement it in a static way, it is important to still see these entities as two aspects in one: an abstraction and an instance.

////
A and B have two aspects, the design-time aspect and the run-time aspect. This is exactly analogous to classes and objects. Even if you intend to have only one of a module or component, we still need to think about it in these two different aspects. In ALA we wont call these aspects classes and objects. We will instead call them Abstractions and Instances (first letter capitalized). The reason ís that classes and object carry with them a lot of baggage, such as associations and inheritance, which we are not allowed in ALA. We need a clean start. We want to remember that we have zero coupling by calling them Abstractions. So now we have Abstraction A and Abstraction B and Instance a and Instance b. When we have only one instance, A and a are two aspects of the same entity, as is B and b.

At runtime, Instances a and b will be communicating:

This knowledge that Instances a and b will be communicating at run-time must of course be represented somewhere at design-time. But we must not put that knowledge into either Abstraction A or Abstraction B, or we will destroy them as abstractions, like what happened to oxygen. The knowledge must go inside a 3rd Abstraction, C.
////
////
The A and B inside C are the Instance aspect of A and B. Even if A and B are never actually explicitly instantiated (because they are written as static modules), C still deals with their Instance aspect. If A and B are written in such a way that they need to be explicitly instantiated, C will do that.  
////

=== Abstraction Layers

==== Layers pattern

With only design-time knowledge dependencies to deal with, layers are used for organising these dependencies so that there are no circular dependencies, and that they all go toward more abstract, more stable abstractions. As the name "Abstraction Layered Architecture" suggests, layers are crucially important to ALA.

In the section on the wiring pattern we ended with three layers:

[plantuml,file="diagram-21.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2.5!"
fontsize=6
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Features layer"
C
}
subgraph cluster_2
{
label="Domain Abstractions layer"
A
B
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
}
C -> A
C -> B
A -> I
B -> I
}
@enddot
----


There is a Layers pattern that also controls dependencies, but since most systems have numerous run-time dependencies between elements represented as design-time dependencies, these layers are used for the run-time dependencies. It is usually explained that each layer is built on services provided by the layer below it. 

One example is the UI/Business Logic/Data model. Another example is the OSI communications model, where the layers are Application, Presentation, Session, Transport, Network, Data link, and Physical. In ALA, each of these ends up being turned 90 degrees. Metaphorically they become chains. In ALA each component wouldn't know about the components next to it. That applies symmetrically, to the left and to the right. Data goes in both directions. At run-time, everything must exist for the system to work. It doesn't really make sense to use a asymmetrical layers metaphor.

The design pattern for layers does have one or two examples of layering used by knowledge dependencies. The term ‘layer’ is therefore an overloaded term in software engineering. When used for knowledge dependencies, the English term 'layer' is a better metaphor. If a lower layer of a wall were to be removed, the layers above would literally collapse, and that's exactly what would happen in knowledge dependency layering. The layers above literally need the knowledge of abstractions in lower layers to make any sense.

ALA's ripple effects are already under control because the only dependencies are on abstractions, which are inherently stable, and furthermore, those abstraction must be more abstract. However, to make these dependencies even less likely to cause an issue during maintenance, we try to make the abstraction layers discrete, and separated by approximately an order of magnitude. In other words each layer is approximately an order of magnitude more abstract than the one above it. More abstract means more ubiquitous, so the layers contain abstractions which have greater scope, and greater potential reuse as you go down the layers. 

We won't need many layers. If you think about abstraction layers in the real world, we can get from atoms to the human brain in four layers. Remember the creativity cycle early in this article. We only need to go around the cycle four times to make a brain: Atoms, Molecules such as proteins, Cells such as neurons, neural nets, and finally the brain itself.   

==== The four layers

We start with four layers. They have increasing scope as you go down. This type of layering was described by Meiler Page-Jones. Meiler Page-Jones’ names for the four layers are: "Application domain", "Business domain", "Architecture domain", and "Foundation domain". 

image::Layers.png[Layers.png, title="Four ALA layers", width=75%]

////
[ditaa,file="diagram-03.png"]
--
Specialized
  
  |       Application layer        |
--+--------------------------------+--
  |   Domain Abstractions layer    |
--+--------------------------------+--
  |  Programming Paradigms layer   |
--+--------------------------------+--
  |         Language layer         |
  V                                v
  
Increasing abstraction            Dependencies
Increasing ubiquity
Increasing reuse
Increasing stability
--
////




ALA uses slightly different names: Application layer, Domain Abstractions layer, Programming Paradigms layer, and Language layer.

===== Application layer

The top layer has knowledge specific to the application, and nothing but knowledge specific to the application, i.e. representing your requirements.

A simple Application might wire a grid directly to a table. When Business logic is needed, any number of decorators (that do validation, constraints, calculations, filtering, sorting, etc.) can be inserted in between the grid and the table by changing the wiring of the application. 

===== Domain abstractions layer

Knowledge specific to the domain goes in this layer. A domain might correspond to a company or a department. As such, teams can collaborate on the set of abstractions to be provided there.

Applications have knowledge dependencies reaching into this layer. 

===== Programming Paradigms layer

All knowledge specific to the types of computing problems you are solving, such as execution models, programming paradigm interfaces and any frameworks to support these, is in this layer.

The Programming Paradigms layer will abstract away how the processor is managed to execute different pieces of code at the right time. Execution models are covered in detail in chapter four.

This layer is also where we arrange for our domain abstractions to have common simple connections instead of having a specific language for each pair of modules that communicate. The Programming Paradigms layer abstracts away ubiquitous communications languages (which we have been referring to as programming paradigms in this article.) 

Let's use the clock as a real world example. (This is the same clock example we used in section 2.9 when introducing the role abstractions play in the creative process.) One of the the domain abstractions for clocks is a cog wheel. Cog wheels communicate with one another. But they don't do it with communications languages specific to each pair, even though each pair must have the correct diameters and tooth sizes to mesh correctly. The cog abstraction just knows about the common paradigm of meshing teeth, a more abstract language in this lower layer. This language is analogous to a programming paradigm. With it, the clock abstraction (which is in the highest layer) can then instantiate two cogs and configure them to mesh. The concept of cog thus remains an abstraction and instances of it are composable. The clock, which already knows that two instances of cogs are needed, also knows where they will be fitted and what their diameters must be. The knowledge in the clock abstraction is cohesive. 

===== Language layer

The language layer is included to show what is below the other three layers. It is not hardware as you would find in many other layering schemes, nor is it a database, because it is not run-time dependencies we are layering. The lowest layer has the remaining knowledge you need to understand your code, that of the languages, libraries and any very generic APIs you may use.

The hardware and database do have a place, but we will cover it later. Being a run-time dependency, it will be well off to one side and slightly higher up.

===== Domain Abstractions API

The boundary between the application layer and the domain abstractions layer is an API that supports the solution space of your requirements (within the constraints of your domain).

The scope of the Domain Abstractions layer defines the expressiveness available to the application. The greater the scope (or bigger the domain), the more applications are able to do. The cost is expressiveness. The applications will have to be longer to specify what is to be done. Conversely, a smaller domain allows less versatility in the applications, but there is greater expressiveness, which means you write less code. 

===== Possible extra layers

The domain is an approximation of all the potential applications and all the modifications you are likely to make. If the domain is large because it is enterprise wide, you could have an additional layer for small domains. The enterprise domain would include enterprise wide abstractions such as a person identity, and the smaller domains would add additional, more specific abstractions, such as a customer (by composition).

If the applications are large and themselves need to be composed of features, an additional layer that supports plug-in style abstractions may work well. Plug-in abstractions may actually be instances of domain abstractions, such as a settings Menu, or a customer Table. A feature can then add settings to the menu, or columns to the table that remain unknown to any other features.

===== Programming Paradigms API

The boundary between all higher layers and the Programming Paradigms layer is another API. It separates the domain knowledge from the programming paradigm implementation knowledge. It almost always takes care of the ‘execution flow’, the way the computer CPU itself will be controlled to execute all the various parts of the code and when, often using a framework. On the other hand, the Programming Paradigms layer doesn’t necessarily have any code at all. Remember that the layers are ‘knowledge dependencies’, not run-time dependencies, so the paradigm could be a ‘computational model’ that just provides the knowledge of patterns of how to constracut the code in higher layers. The decisions about use of the patterns and about the way the code is executed have already been made and exist in the Programming Paradigms layer.

===== Rate of change of knowledge

The knowledge in each of the four layers has different change rates. 

* The Language layer contains knowledge that will likely change only a few times in your career. 

* The Programming Paradigms layer knowledge changes when you move to different computing problems types, or discover different approaches to solving a broad range of problems. For example, if you have not yet used an event driven execution model or state machines in your career, and you move into the embedded systems space, you will very likely need to have those skills.

* The Domain Abstractions layer has knowledge that changes when you change the company you work for. It will change at the rate that the company's domain is changing, or is becoming better understood. If your company uses lean principles, one of the things you want to do is capture knowledge for reuse. This is the whole point of the Domain Abstractions layer, it is a set of artefacts that capture the company's reusable knowledge. 

* The Application layer has the fastest changing knowledge, the knowledge that changes at the rate that an application gets maintained.

=== ALA is a logical view

If the system is deployed on multiple machines (this is the subject of the physical view), the ALA abstractions, layers and diagrams all remain identical. A simple application diagram connecting a temperature sensor to a display field does not change if the sensor happens to be on a Mars Rover and the display field is at JPL. 

Ideally, the performance view also does not affect the ALA logical view. This is a many faceted problem that we will return to later.

ALA usually works very well with aspects of the development view as discussed elsewhere. For example, the fact that domain abstractions have zero coupling greatly helps the allocation of teams. The teams need only cooperate on a common understanding of the programming paradigms used.   

=== No separation of UI

In ALA we don't separate the UI unless there is a reason to do so. The amount of knowledge in the UI that comes from a particular application's requirements is usually quite small and that knowledge is usually quite cohesive and coupled with the business logic of the feature it belongs with. For example, the layout of the UI is a small amount of information, and the bindings of the UI elements to data are a small amount of information. So all that cohesive knowledge is kept together, encapsulated inside a feature. Instead, the UI is composed from Domain UI abstractions. Being domain specific, these abstractions have a little more knowledge to them than generic widgets. For example, their domain knowledge may include style, functionality and suitability to their domain context. For example, a softkey or menu item will have an appearance, functionality and suitability to the way UIs are designed in the domain. Using one in a specific application only requires a label and a binding to an action. They will also provide consistency in the domain.

If there is an actual requirement to have different UIs, say a command based UI and a GUI based UI, then you just abstract the UI abstractions further until they can be used either way. The UI abstractions still remain an integral part of the application.

In the example project for this chapter, we will for the first time use multiple programming paradigms, a usual thing in real ALA projects.


=== Features

You may have noticed throughout this article the word 'features' being used quite often instead of 'Application'. When the application is large, we can think of it as a composition of feature abstractions. This is exactly what happens in natural language in the domain when describing requirements. 'Features' is just the word we give the natural abstractions in the requirements, without even realizing it. Just go with this in the software itself.    

=== Horizontal domain partitions

Say you are implementing a particularly large domain abstraction such as a 'Table', or are implementing a complicated programming paradigm. We would like to break these up into smaller components. Do we introduce a fractal type of structure to deal with this? Should we have hierarchical layers within layers contained completely inside the Table abstraction?

The astute reader will have noticed the non-ALA thinking in the statement "break these up into smaller components". In ALA we don't decompose a large abstraction into components, we compose it from abstractions, which if necessary we invent as we go. These new abstractions will have a scope or level of ubiquity, stability and reuse that corresponds to one of the existing layers. So there should be no hierarchical or fractal structures in ALA.

However, the domain that these new abstractions are in won't be the same domain as the one that provides for the writing of Application requirements. For example, the implementation of the Table abstraction will need to be connected to another abstraction in the domain of databases. One of the abstractions in that domain will know about a particular database, say SQL Lite. A polymorphic interface should exist between the two. That interface, being more abstract than either the Table or the SQL Lite abstractions, will be in the next layer down, where both the Table and the MySQL abstractions can have a knowledge dependency on it. Of course the SQL abstraction will actually be further composed of an adapter and a real database. 

Some application domain abstractions are complicated. Examples of these are abstractions requiring a connection to an actual database, actual hardware, the Internet, etc. Implementing these will typically wire out horizontally into other technical domains. You can visualise them going in multiple directions, which is exactly the idea of Alistair Cockburn's hexagonal architecture.

[plantuml,file="diagram-22.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2!"
fontsize=8
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Features layer"
Feature
}
subgraph cluster_2
{
label="Domain Abstractions layer"
Input
Table
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
IDataModel
HAL
}
subgraph cluster_4
{
label="Database configuration"
Config
}
subgraph cluster_5
{
label="Database domain"
SQLLite
}
subgraph cluster_7
{
label="Hardware domain"
ADCdriver
}
Feature -> Input
Feature -> Table
Input -> I
Table -> I
Input -> HAL
Table -> IDataModel
Config -> SQLLite
ADCdriver -> HAL
SQLLite -> IDataModel
}
@enddot
----



A communications domain using a OSI model may end up with a whole chain of communications domain abstractions going sideways:

[plantuml,file="diagram-23.png"]
----
@startdot
digraph foo {
edge [color=green]
fontsize=10
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Application layer"
Application
}
subgraph cluster_2
{
label="Domain Abstractions layer"
A
B
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
XML
REST
TCP
IP
ICMP
Ethernet
}
subgraph cluster_4
{
label="Network configuration"
ConfigComms
}
subgraph cluster_5
{
label="Network domain"
Presentation
Session
Transport
Network
Datalink
Physical
}
Application -> A
Application -> B
A -> I
B -> I
ConfigComms -> Presentation
ConfigComms -> Session
ConfigComms -> Transport
ConfigComms -> Network
ConfigComms -> Datalink
B -> XML
Presentation -> XML
Presentation -> REST
Session -> REST
Session -> TCP
Transport -> TCP
Transport -> IP
Network -> IP
Network -> ICMP
Datalink -> ICMP
Datalink -> Ethernet
Physical -> Ethernet

}
@enddot
----

The technicalities may be incorrect but the diagram gives the idea of how the OSI 'layers', which are just run-time dependencies, would fit into the ALA layers. 


=== No hierarchical design

ALA does not use any form of hierarchical structure. Instead it uses abstraction layers, together with "Horizontal domain partitions" discussed earlier.


=== Product owner perspective

TBD



=== Reuse

TBD


=== Documentation

TBD


=== Symbolic indirection

TIP: Avoid use of symbolic indirection without abstraction

When we start assembling requirements from abstractions, a topic that we will cover in coming sections, we will be using symbolic indirection, such as function calls or the new keyword with a class name. Unless a symbolic indirection is to an abstraction, they are for the compiler to follow at compile-time, not for the code reader to follow at design-time. Understanding the code relies on allowing the reader to read a small cohesive block of code. The reader should never have to follow the indirection somewhere else. If you don't achieve this, and abstraction is the only way you can, then any decoupled architecture will be _more_ difficult to read. 

Abstraction allows indirection while allowing the reader to continue reading on to the next line. The importance of this property cannot be overstated. As soon as we start thinking in mere programming language terms of modules, components, interfaces, classes, or functions, the abstraction will start to be lost. These other artefacts may have benefits at compile-time (the compiler can understand them), but that is not useful at design-time unless they are also good abstractions.  

It would be nice if your compiler could tell you that you have a missing abstraction, just as it does for a missing semicolon, but alas, they are not capable of understanding abstractions yet. So it is still entirely up to you.

Abstraction is almost a black and white type of property. It's either there or it isn't. If the reader of your code does not have to follow the indirection, you have it. 

Footnote: When the reader of your code meets your abstraction for the first time (usually a domain abstraction in a domain they have recently come into), ideally their IDE will give them the meaning in a little pop-up paragraph as their mouse hovers over any of its uses. Depending on the quality of the abstraction, after a single exposure, their brain will have the insight, like a light coming on, illuminating a meaning. The brain will form a new neuron to represent the concept. Since the reader will hopefully remain in the domain for some time, this overhead to readability shouldn't be large.

=== Everything through interfaces

A class, in contrast to an abstraction, has an interface comprising all the public members. In ALA we only want this interface to be used by the application when it instantiates and configures an instance of an abstraction. All other inputs and outputs that are used at run-time are done through interfaces (abstract interfaces). 


=== What do you know about?

Whenever I have only two minutes to give advice on software architecture, I use this quick tip. The tip is ALA reduced to its most basic driving principle.

Ask your modules, classes and functions:
[TIP]
====
[green]#*What do you _know_ about?*#
====

The answer should always be "I just know about...".

The anthropomorphization helps the brain to see them as abstractions. The word 'knows' is carefully chosen to imply a 'design-time' perspective. 

. It's a restatement of the SRP (Single Responsibility Principle). Every element should know about one thing, one coherent thing. Furthermore, no other elements should know about this one thing.

. An element may know about a single hardware device.

. An element may know about a user story.

. An element may know about a protocol.

. An element may know an algorithm.

. An element may know how to do an operation on some data, or the meaning of some data, but not both.

. An element may know a composition of other elements.

. An element may know where data flows between other elements.

. No element should know the source or destination of its inputs and outputs.




=== Example project - a real device

Unlike our previous example projects, this project is a real device and had previously been implemented without any knowledge of ALA. So this example serves to make comparisons between ALA and conventional software development. The original software was around 200 KLOC and took 3 people 4 years to write. 

The actual device is used by farmers all over the world. It can weigh livestock and keeps a database about them for use in the field. It connects to many other devices and has a large number of features: 

image::Tru%20Test%20XR5000%20Weigh%20Scale%20Indicator.jpg[Tru Test XR5000 Weigh Scale Indicator.jpg, title="Livestock weighing indicator", width=75%]

The architecture in the original software, was somewhat typically organised into modules and patterns by its developers. Also somewhat typically, it had ended up with a high cost of modifiability - a big ball of mud. After the first release, the first incremental requirement was a 'Treatments' feature, which involved several new tables, new columns in existing tables, new data pages, new settings pages and some new business logic. This feature took a further 3 months to complete (actually 6 calendar months), which seemed out of proportion for the size of the feature. Somehow the Product Owner and managers seemed to have a sort of intuition that if similar things had been done before, such as menus or database tables, those things were already done, and the only new work was in the specific details of the new requirements. Those requirements could be communicated in a relatively short time, say of the order of one hour or one day if you include follow up discussions of abnormal scenarios.  So 6 months did not go down well. ALA, of course, works in exactly this intuitive way that managers hope for. All the things already done are sitting there in the domain abstractions, waiting to be reused, configured and composed into new requirements.

==== Iteration zero

During the development, there had a been a high number of changes required to the UI. It occurred to me at the time that the underlying elements of the UI were not changing. It was mainly the details of layout and navigation around the device's many pages that were changing. The same could be said about the data and business logic. Only details were changing. 

I took to representing the new designs using box and line drawings representing both the UI layouts and the navigation flows. I realized these diagrams were potentially executable, and wondered how far I could go representing the data and business logic in the same way. I decided to try to represent all of the functionality of the indicator in just one  diagram.

It took two weeks to complete the diagram. I used Xmind because it laid itself out. I found that any drawing package that needed you to stop and do housekeeping such as rearranging the layout got in the way so much that you would lose your flow. Xmind allowed me to just enter in the nodes and it would automatically wire them in as either peers or chains and lay them out. The one disadvantage was that Xmind only does trees, so any cross tree relations had to be done manually, but this was also very quick in Xmind once you were used to it. I just let the cross wiring form arcs across parts of the tree.

Progress was extremely rapid once you had the abstractions and paradigms you needed. And many of them were obvious: softkeys, pages, grids, menus, actions, navigate-action, tables. etc. The programming paradigms would pop into play as needed. After the obvious UI-layout and navigation-flow ones came data-flow and data-flow of table types, events, and schema. The user of this device could set up custom fields, so the schema itself partially came from another  table. At times I would get stuck not knowing how to proceed. The longest of these blocks was half a day. But every time the required abstractions or programming paradigms would firm up, and in the end anything seemed possible.

The diagram itself took shape on the right hand side of the Xmind tree. On the left side I had the invented domain abstractions and paradigm interfaces, with notes to explain them. The right side was mostly just a set of relatively independent features, but there was the odd coupling between them such as UI-navigation lines that were also present in the requirements.

The diagram contained around 2000 nodes (instances of the abstractions), which is about 1% of the size of the total original code. There were about 50 abstractions, and several paradigm interfaces.

Part of the diagram is shown below (laid out more nicely in Visio)

image::All%20Animals%20Screen%20V3.png[All Animals Screen V3.png, title="Application diagram for the All Animals View feature", link=images/All%20Animals%20Screen%20V3.png]

As I did the diagram, I deliberately left out anything to do with the aforementioned Treatments feature, so that I could see how easy it might have been to implement once the domain abstractions for the rest of the requirements had matured. So after the diagram was completed, I added the Treatments feature. This involved adding tables, columns to existing tables, a settings screen, a data screen, and some behaviours.  No further abstractions needed to be invented. The incremental time for the diagram additions was of the order of one hour. Obviously testing would be needed on top of that, and the 'Table' abstraction would need additional work so it could migrate itself, a function it had not needed up until this point. Although somewhat theoretical, the evidence was that we could get at least an order of magnitude improvement in incremental maintenance effort.

At first the diagram seemed too good to be true. It had an elegance all of its own. It apparently captured all of the requirements, without any implementation at all, and yet seemed potentially executable. And if it worked, application modifications of all the kinds we had been doing were going to be almost trivial.

The burning question on my mind was, is it simply a matter now of writing a class for each of these abstractions and the whole job is done?

==== Translating the diagram to code

We hired a C++ student and proceeded with a 3-month experiment to answer this question.

It was a simple matter to translate the diagram into C++ code that instantiated the abstractions (classes), wired them together using dependency injection setters, configured the instances using some more setters, and used the fluent interface pattern to make all this straightforward and elegant. Part of the code for the diagram sample above is shown below to give you a feel for what it looked like.

....
m_animalListScreen
	->wiredTo((new Softkeys())
		->wiredTo((new Softkey())
			->setTitle("History")
			->wiredTo(new Navigate(m_animalHistoryScreen))
		)
		->wiredTo((skeyOptions = new Softkey())
			->setTitle("Options")
			->wiredTo(new Menu()
				->wiredTo(new Navigate("Session...", m_sessionSummaryScreen))
				->wiredTo(new Navigate("Settings...", m_settingScreen1))
			)
		)
	)
	->wiredTo((searchField = new TextDisplayField())
		->setLabel("Search")
		->setField(VIDField = new Field(COLUMN_VID))
	)
	->wiredTo(new Grid()
		->wiredTo(columnOrder = new ColumnOrder())
		->setRowMenus((new EventHandler())
			->setEvent(EVT_KEY_ENTER)
			->wiredTo(new Menu()
				->wiredTo(new Navigate("View information for this animal", m_animalSummaryScreen))
				->wiredTo((new Action("Delete Record", AnimalsTable::DeleteRow))->wiredTo(AnimalsTable))
			)
		)
	);
....

==== Writing the classes

We knew we wouldn't have time to write all 50 classes, so we chose to implement the single feature shown below as a screen shot. 

image::XR5000ScreenShot.jpg[XR5000ScreenShot.jpg, title="All Animals view in the weighing indicator", width=75%]

The student's job was to write 12 abstractions out of the 50. These 12 were the ones used by that feature. The initial brief was to make the new code work alongside the old code (as would be needed for an incremental legacy rewrite), but the old code was consuming too much time to integrate with, so this part was abandoned. 

The learning curve for the student was done as daily code inspections, explaining to him where it violated the ALA constraints, and asking him to rework that code for the next day. It was his job to invent the methods he needed in the paradigm interfaces to make the system work, but at the same time keep them abstract by not writing methods or protocols for particular class pairs to communicate. It took about one month for him to fully 'get' ALA and no longer need the inspections.  

// image:All%20Animals%20Screen%20V3.svg[]

The student completed the 12 classes and got the feature working in the device. The feature included showing data from one database table in a grid, sorting, searching, softkeys, and a menu.

Interestingly, as the student completed certain abstractions that allowed parts of other features to be done, he would quickly go and write the wiring code and have the other features working as well. For example, after the softkeys, actions, navigate, and page abstractions were done, he went through and added all the softkey navigations in the entire product as this only took minutes to do. 

We wanted more funding to retain the student until we had enough to do the treatments feature, and indeed all 50 abstractions with the hope of making this implementation the production code and improving our ongoing maintenance effort. But that was not to be, despite the promising result.

We have about a quarter of a data point. Some of the abstractions done were among the most difficult, for example the Table abstraction, which had to use SQL and a real database to actually work. So it is not unreasonable to use extrapolation to estimate that the total time to do all 50 abstractions would be about one person-year. That compares with the original 12 person-years. 

It seems that classes that are abstractions are faster to write. This seems intuitive because you don't have any coupling to worry about. More importantly, the two phase design-then-code methodology of ALA allows the developer not to have to deal with large scale structure at the same time as writing code. This frees the developer to go ahead and write the code for the local problem.

I believe it is beneficial for each developer to be trained to be both an architect and a developer, but just don't ask them to do both at the same time.

This practical result combined with the theory outlined earlier in this article suggests there ought to be a large improvement in incremental maintenance effort over a big-ball-of-mud architecture.
