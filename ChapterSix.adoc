:imagesdir: images

== Chapter six - ALA compared with:

In this chapter, our perspective is to compare ALA with existing programming paradigms, principles, styles, and patterns.

The idea is to understand ALA in terms of similarities and differences with something you may already understand.

A programming paradigm, principle, style, or pattern generally takes a long time for the average developer to get used to and master. It then generally only makes an incremental improvement to software quality, if any. ALA is a reference architecture that combines the best elements of these existing programming paradigms, principles, styles, and patterns into one coherent idea. 

Some programming paradigms, principles, styles, or patterns are just bad. The most prominent examples are the UML class diagram, the idea of 'decomposition' of a system (which includes all patterns like MVC), the idea that indirection is necessarily hard to trace, the idea of loose coupling, the idea of dependency management without distinguishing between good and bad dependencies, and the idea of layering patterns (sometimes called stacks) where the layers are driven by communication dependencies.

In this chapter we look at each of these good and bad patterns or styles in detail.


=== Monads

In chapter 3, we did a brief comparison of ALA and monads in which we assumed prior familiarity with monads. In this section we assume no familiarity with monads. So we start by explaining what monads are. I promise this will be the easiest explanation of monads you will find on the internet. I'll be using the approach that monads are a refactoring pattern. We'll first do some imperative code, and then do the equivalent refactored code. We will do the refactoring in several stages. We will point out the multiple advantages of the refactored code along the way. At the last stage the refactored code qualifies under as a monad.

____
Often abstract concepts in programming can be explained in terms of how they are syntactical sugar for a longer, imperative form of the code. For example, lambda expressions can be explained as syntactical sugar for passing in a named function. This is hard to do for monads, especially 'deferred' monads, because there is code generated under the hood. So most explanations of monads do not attempt to explain them in terms of equivalent imperative code. They go for an abstract or mathematical explanation instead. This makes these explanations very difficult to understand, especially for developers who are not so much mathematicians, but do understand imperative object oriented code just fine. I am going to show that code generated behind the scenes as well.
____

Monads are motivated by three problems in functional programming:

. Top layer code that calls functions must handle data for the functions. For example, data returned by one function is often passed to the next. This often involves creating local variables to hold data temporarily. But really we want to think of the top layer as just 'composing' functions. That's a more declarative approach - just composing things together. When we compose functions we want the output of one to be piped to the input of the next without us having to do it explicitly. Looked at in a different way, the functions' interfaces for input/output (the parameter and the return value) are exposed to the top layer when they don't need to be. We would rather think of this input and output as separate interfaces or ports. When the top layer composes two functions, these ports are wired up so that at runtime data is passed directly from one function to the next.

. Most programs use state because is often the best way to express a computation. This is especially true when the events coming into the system are asynchronous, for example coming from the outside world.
+
In pure functional programming, this state ends up essentially in the top layer. It is passed into the pure functions. Returned values are stored back in the state variable. The state structure itself may be immutable, so that if another thread has a reference to it, it does not see changing data. But the stateful reference to the structure must be stored in place while the system waits for the next external event. 
+
Passing state into functions that essentially own the state is a responsibility that the top layer should not have. Functions that would otherwise be good abstractions if they were self-contained with their state get broken by exposing their private parts. 
+
Instead good abstractions should stay. The problem of their mutable state should then be handled by treating each instance (or a local group of instances) as a unit running on a single thread. These groups can then _only_ communicate with one another asynchronously.tt

. Many times in functional programming when composing functions, the return value cannot be fed _directly_ into the next function. Some common code is needed between functional calls. For example, if the function could have an error, if or try statements would be needed after every function call to check for the error.
+
This type of common code should also not be the responsibility of the top layer. The top layer should just be about composing functions. This common code, which can take many forms, should be refactored out.

Monads allow the top layer to just compose the functions. The monad takes care of passing data from function to function, allowing the composed function to have state without the top layer code handling or knowing about the state, and doing any common code that needs doing after function calls. The top layer code remains pure functional code. 

To accomplish all this, monads (usually) use objects under the covers. These objects can be delegates (object/function references), closures (objects of compiler generated classes that capture local scope variables), or specific under the hood classes. These objects are wired together to build a structure that can be executed in much the same way as ALA wires together domain abstraction objects to build a program that can be executed.

The motivating problems described above will still seem quite vague to the reader without code examples. So that is what we will do in the following few sections. 

Most of the code snippets in this section are demonstrated by small executable projects on Github here:

https://github.com/johnspray74[https://github.com/johnspray74]

The project names are IEnumerableMonad, ContinuationMonad, and MaybeMonad.


==== Composing functions

Let's start by composing three functions in familiar imperative style.

In these examples, we will feed the number 42 into the first function, just to make it easy for you to see the source of the composed function chain:

[source,C#]
....
int result = function3(function2(function1(42)));
....

Composing functions in this way is not scalable because of the increasing levels of nested brackets every time we want to add a new link to the chain. Also we cannot add statements such as if statements to control the flow if there is an error.

To get a scalable version, we can write it like this instead:

[source,C#]
....
int r1 = function1(42);
int r2 = function2(r1);
int result = function3(r2);
....

This is representative of the basic style that most imperative code follows. There may be some logic statements thrown in amongst the function calls, but essentially most imperative code follows that style.  

This form has the disadvantage of creating temporary local variables, which makes the entire scope more complicated because anywhere in the scope can potentially use any variable. The variable can be immutable, but that doesn't help much.

Let's try to get to a style where we don't need to handle that data ourselves and we are just declaring what functions we want to compose. Lets try using a new function called 'Compose' to compose the functions:

[source,C#]
....
int Compose(int x, Func<int,int> f)
{
    return (f(x));
}    
....

So now we can compose the functions like this:

[source,C#]
....
int result = Compose(Compose(Compose(42, function1), function2), function3);
....

Well there doesn't seem like there is any advantage to that. We got our nested brackets back, plus it looks even more complicated than our original imperative code. But let's persevere just a little longer with this idea before we give up on it, because we are about to uncover a number of very cool advantages.

First let's make the Compose function an extension method by adding a _this_ keyword:

[source,C#]
....
static class ExtensionMethods
{
    public static int Compose(this int x, Func<int,int> f)
    {
        return f(x);
    }
}
....


Now we can compose the three functions using this syntax:

[source,C#]
....
int result = 42
    .Compose(function1)
    .Compose(function2)
    .Compose(function3);
....

We just solved the nested brackets problem. And we no longer need local variables. That looks useful. We are actually just composing the functions. This syntax is called fluent syntax. The chain of functions is now scalable - we can easily add more functions to the chain. Fluent syntax is our first advantage of using a Compose function. 

The three functions are chained in a way that it looks like a declarative dataflow programming paradigm instead of an imperative programming paradigm. We are just specifying what functions we want to compose in what order instead of imperatively calling them. The code now describes a flow of data more than a flow of execution. That's a good thing. This dataflow programming paradigm is our second advantage of using a Compose function. This advantage will turn out to be huge. In our user story code we just declare what functions we want to compose to make a dataflow. The compose function itself then takes care of how everything actually executes. 

The Compose function takes a function pointer or delegate as its parameter. If the function is only ever used once, we can make it anonymous and put the function code directly into the Compose call:

[source,C#]
....
int result = 42
    .Compose(delegate(int x){return x+1;)
    .Compose(delegate(int x){return x*10+1;})
    .Compose(delegate(int x){return 1/x;});
....

Doing it with delegates like that is somewhat verbose, so the next step is to change the syntax to lambda expressions.

[source,C#]
....
int result = 42
    .Compose(x => x+1)
    .Compose(x => x*10+1)
    .Compose(x => 1/x);
....

So that's our third advantage of using a Compose function. We can use lambda expressions right in the parameter of the Compose function instead of creating separate named functions.

Named functions are good if the function is a good abstraction in a lower layer. But if a function is specific to a user story (only used once, ever), it is not an abstraction. So the name becomes just a symbolic wiring between two points in the code. Symbolic wiring is bad. It's indirection without an abstraction. We would have to use an editor to search for the other point to find the wiring. Lambda expressions solve this problem because they are anonymous functions.

You can see that although this last form is just a refactoring of the original imperative code, it now looks even more like a dataflow programming paradigm. By dataflow, we mean that we are thinking of it in terms of piping data from lambda expression to lambda expression rather than imperatively execution of statements.

In the example so far, we know that under the covers of the Compose function, the execution flow follows the dataflow. Since we are just describing a dataflow with our top level code, it is possible for the execution flow in the compose function to work in a completely independent way. We can for example, implement deferred execution, where the Compose function builds an executable structure which can be run later. Later we will do even more powerful examples of an independent execution model such as asynchronous execution. This separation of how it executes from the declarative composition of the functions as a dataflow is our forth advantage of using a Compose function.


==== Deferred execution

The Compose function we had in the previous section evaluated the functions immediately and returned a result directly. If we write a deferred version, the Compose function will return a new function that represents the entire computation, but can be called later. Here is a deferred version of the Compose function:


[source,C#]
....
static class ExtensionMethods
{
    static Func<int> Compose(this Func<int> source, Func<int,int> function)
    {
        return () => function(source());
    }
}
....

The _() =>_ syntax is a lambda expression for a function that takes no parameters. Compose returns a function that calls the source function and then calls the _function_. 

What the Compose function returns is actually an object structure made up of delegates and closure objects created by the compiler:

image::ComposeClosure.drawio.png[title="Object diagram of the structure returned by the deferred version of the Compose function"]

Note that in the imperative world we would say we are really passing in two pointers to functions, and returning a pointer to a function, but in the functional world this is said to be just composing functions. 

The closure object has two fields, which are delegates to the two functions. A delegate is a pointer to an object together with a method in that object. A closure is an object made from a compiler generated class with a single method and one or more fields which are references to variables in the local scope.

Now that we have a deferred version of our Compose function, we can use it like this:

[source,C#]
....
Func<int> composedFunction = 42.ToFunc<int>
    .Compose(x => x+1)
    .Compose(x => x*10+1)
    .Compose(x => 1000/x);
....

This doesn't call any of the lambda expressions immediately. That can be done at any time later with:

[source,C#]
....
int result = composedFunction();
....

Note that we used another extension method called ToFunc to get a function that returns 42, our starting value. We needed this function because Compose takes a function as its first parameter, so we needed a function that returns 42 to start the chain.

Deferred function composition generally returns a surprisingly large object structure containing delegate objects and closure objects. Here is what the object structure for the composedFunction above looks like:

image::ThreeComposedFunctionsClosureDiagram.drawio.png[title=Object diagram of expression composing three functions using deferred Compose function]

We will generally go for a deferred version of a Compose function because then you have the option of using it immediately, or using it to build a larger program to be executed later. Deferred execution is our fifth advantage of using a compose function. Even if you run it immediately, the way a deferred composed function runs can be more efficient with use of memory. 

We are not finished yet. There is an even bigger advantage of using a compose function, which we will do next.


==== Composing functions that need logic between them

Sometimes we need to put some common logic between function calls such as to check for any errors that have occurred. We can refactor this common logic into the Compose function. This refactoring can't even be contemplated in the imperative version.

First we'll give four examples of imperative code. In each case, the functions we are composing are not returning a simple value that can be fed directly to the next function. They are returning a variety of different things, but in every case we need a little bit of extra code to handle what the function returns and then feed it to the next function.


===== Example 1

Composition of functions that can fail.

In this first example, we may need to allow for the fact that functions can throw an exception, or return null, or a Maybe object or even -1. For example the function may contain a divide by zero. In imperative code, we would commonly have to add if statements or try statements so that we don't call the rest of the functions in the chain in case something goes wrong. 

In C code, returning -1 is often used for this purpose, so let's use that for our first example because it's so simple. Here is the imperative code:

[source,C#]
....
// procedural composition of functions that can return -1 or null

int result1 = function1(42);
if (result1 != -1)
{
    int result2 = function2(result1)
    if (result2 != -1)
    {
        int result3 = function3(result2);
        if (result3 != -1)
        {
            DoSomething(result3);
        }
    }
}
// fall through means something returned -1
....

Note that, even though we are using intermediate variables, every composed function involves nested brackets for the if statements, which is really not scalable.


===== Example 2

Composition of functions that return many values.

We may have functions that return many values, such as an array, a list, an IEnumerable or an IObservable. We then want to feed all the individual values into the next function, and then recombine the results. In imperative code, we do this with nested for statements. For example, the function may be given customers one at a time and returns a list of their orders, which we want to join back into a single list of orders.


[source,C#]
....
// procedural composition of functions that return a list

var results1 = function1(42);
List<int> combinedList1 = new List<int>;
foreach(result1 in results1)
{
    var results2 = function2(result1)
    List<int> combinedList2 = new List<int>;
    foreach (result2 in results2)
    {
        var results3 = function3(result2)
        combinedList2.Append(results3);
    }
    combinedList1.Append(combinedList2);
}
List<int> result = combinedList1;
....

Again note the extra levels of brackets and indenting for every foreach. 


===== Example 3

Composition of functions that return a Future, Promise or Task object.

The functions that we want to compose may contain delays, or they may wait for input or output. So each function, instead of returning the result, may return a Task, future or promise object. The glue code between function calls needs to wait for the future object to have the result before calling the next function: 

[source,C#]
....
static void ComposedFunction()
{
    function1(1)
    .ContinueWith(task1 =>
    {
        function2(task1.Result)
        .ContinueWith(task2 =>
        {
            Console.WriteLine($"Final result is {task2.Result}.");
        });
    });
}
....

ContinueWith itself returns a Task, but these are discarded as we are only interested in continuing from the Task that is returned by function1 and function2. 

Again notice the nasty indenting for every function we want to chain. In this case we can eliminate the indenting by using Unwrap() like this:

[source,C#]
....
static void ComposedFunction()
{
    function1(1)
    .ContinueWith(task => function2(task.Result))
    .Unwrap()
    .ContinueWith(task =>
    {
        Console.WriteLine($"Final result is {task.Result}.");
    });
}
....

Note that both versions require lambda expressions (for example, the lambda expression starting with 'task1 =>" ). In the first implementation above, the lambda expression is an Action. In the second implementation the lambda expression is a function. So they are two different overloads of ContinueWith. In the second implementation, the lambda function returns the type returned by the function, which is a Task<T>. So ContinueWith returns Task<Task<T>>. The Unwrap discards the outer Task. 

Of course, async/await also simplifies this particular example, but I want to show how monads can also do it. 


===== Example 4

Composition of functions that return angles. 

There can be many other motivating examples. In fact we can do almost anything we like between the function calls as long as we are always doing the same thing. Let's do one more example just to show that we can do something fairly arbitrary. Let's say we always want to do modulo 360 arithmetic. And let's throw in a rotation counter as well:

[source,C#]
....
// procedural composition of functions that can return angles

int rotations = 0;
int result1 = function1(42)
rotations += result1 / 360;
result1 = result1 mod 360;
int result2 = function2(result1)
rotations += result2 / 360;
result2 = result2 mod 360;
int result3 = function3(result2)
rotations += result3 / 360;
result3 = result3 mod 360;
....

In all these above examples, we would like to be able to just compose the three functions in a declarative way like we were before, and have the common execution code inbetween refactored into the Compose function. 


==== The monad refactorings

This is our sixth advantage of using a Compose function. This one is huge. The refactoring is called the monad pattern. The Compose function is usually called _Bind_. It also goes by other names such as =\=>, flatmap, and SelectMany. From now on we will use the name _Bind_ instead of _Compose_ that we always used before.

Let's now do the Bind function for each of our imperative examples above. 

We will do _immediate_ versions of Bind first because they are simpler.


===== MinusOne monad

Composition of functions that can fail by returning -1.

Here is top layer code that composes functions that may return -1.


Application layer code
[source,C#]
....
int result = 42
    .Bind(x => x+1)
    .Bind(x = x*10+1)
    .Bind(x => x==0 ? -1 : 1/x);
....

Compare this with the imperative version we had previously that had to use nested if statements.

It's almost the same as when we used Compose except that now the lambda expressions are allowed to return -1. If any one of them does, the result will be -1. The last lambda expression is an example of one which can return -1.

Here is the Bind function:

Monad layer code
[source,C#]
....
static class ExtensionMethods
{

    public static int Bind(this int source, Func<int, int> function)
    {
        return source == -1 ? -1 : function(source);
    }
}
....

You can see that if any function in the chain returns -1, the rest of the functions are skipped and the final result is -1.

That is all there is to our first monad Bind function.


===== IMaybe monad

Composition of functions that can fail by returning IMaybe<T> or Nullable<T>.

Using minus one to represent a no value is not used outside the C world, and has limited use with only positive integers. The more general solution is the IMaybe<T> monad:

The IMaybe version is similar to the -1 version. However Bind in this case requires an IMaybe and returns an IMaybe, and the functions that we compose together also return an IMaybe. Here is example top layer code composing functions that return IMaybe. 

Application layer code
[source,C#]
....
IMaybe<double> combinedFunctions = 42.ToMaybe()
    .Bind(x => new Something<int>(x+1))
    .Bind(x => new Something<int>(x*10+1))
    .Bind(x => x==0 ? new Nothing<double>() : new Something<double>((double)1/x) );
....

Notice that we need to convert the starting value, 42, to an IMaybe so that Bind can be used on it. That's the reason for the ToMaybe extension method. To be a monad, we need to supply this function. In monad land, this function is sometimes called _unit_ or _return_. 

The IMaybe interface itself consists of two getters, one called HasValue() that returns a bool to find out if a value is there, and the other called Value to get the actual value out if there is one. 

[source,C#]
....
public interface IMaybe<T>
{
    bool HasValue { get; }
    T Value { get; }
}
....

You would normally use HasValue first and only if it returns true would you use Value. HasValue is analogous to the MoveNext method in the IEnumerator interface, which you also have to call first before retrieving a value. We will need two classes that implement IMaybe, one to represent a nothing, and one to represent something:


Monad layer code
[source,C#]
....
public class Nothing<T> : IMaybe<T>
{
    bool IMaybe<T>.HasValue { get => false; }
    T IMaybe<T>.Value { get { throw new Exception("No value"); } }
}


public class Something<T> : IMaybe<T>
{
    private T value;

    public Something(T value) { this.value = value; }

    bool IMaybe<T>.HasValue { get => true; }
    T IMaybe<T>.Value { get => value; }
}
....


The Bind function takes an IMaybe as a parameter and returns an IMaybe. It uses its input IMaybe<T> to see if there is a value present or not. If there is nothing it doesn't even call the function. It just returns a new IMaybe<U> implemented by a nothing object. If there is a value, it gets the value and passes it to the function, then Bind returns the IMaybe returned by the function.


Monad layer code
[source,C#]
....
static class ExtensionMethods
{
    public static IMaybe<T> ToMaybe<T>(this T value)
    {
        return new Something<T>(value);
    }


    public static IMaybe<U> Bind<T, U>(this IMaybe<T> source, Func<T, IMaybe<U>> function)
    {
        return source.HasValue ? function(source.Value) : new Nothing<U>();
    }
}
....

Monads in general consist of three things: an interface, a Bind function and a way to create an object that implements the interface. In this case they are IMaybe, Bind, and ToMaybe.


===== List monad

Composition of functions that return many values, in this case a list.


Here is example top layer code that composes functions that return a list:


Application layer code
[source,C#]
....
var result = List<int> result = new List<int>(){ 0 }
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....



The functions each return a list. So as we Bind each new functoin, the number of items in the list multiplies up. Here is an application using function that are lambda expressions that each return a list of three items:

[source,C#]
....
var result = new List<int> { 0 }  
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new List<int> { x * 10 + 1, x * 10 + 2, x * 10 + 3 });
....

In this case Bind will receive a list as its input. It will feed all the values one by one to the function. Each call of the function will return a new list. Bind will then join all the lists together and return the combined list. Because we compose three functions, and each returns a list of three items, the result list at the end will contain 27 items. The output is:

image::ConsoleOutputListMonad.png[ConsoleOutputListMonad.png, title="Output of three Bind functions in a row"]


Here is the Bind function for the List monad:

[source,C#]
....
static class ExtensionMethods
{
    public static List<U> Bind<T, U>(this List<T> source, Func<T, List<U>> function)
    {
        List<U> output = new List<U>();
        foreach (T t in source)
        {
            var List<U> functionOutput = function(t);
            output.AddRange(functionOutput);
        }
        return output;
    }
}}
....

Let's say the List<T> input were a list of students. Bind uses a for loop to get all the students one at a time. It passes each student to the function. Each call of the function returns a List<U>. Let's say this is a list of courses for the student. The bind function then joins all the separate course lists together to make a single list of courses of type List<U>, which it returns.

Note that the monad itself is designed to compose functions that return lists. It then has effectively a list of lists. It then flattens the lists. Often we will want to just do a one-to-one mapping of the values in a list, or we will even want to aggregate the values in the list down to a single value such as Sum. Methods to do these are usually supplied along with the monad, but the monad itself is the Bind function is the one that composes functions that return a list, and then flattens all the lists.


===== Mod360 monad

Composition of functions that return angles. 

This is not strictly speaking a monad because the function doesn't return the same interface as the Bind function uses for its input and output. That's because in this case the function didn't need to know anything about the rotations. However it still shows how the monad pattern can refactor arbitrary common code between composed functions.

Here is top layer code to compose function that return degrees. The second value in the Tuple is the number of rotations, which we initialize to 0.


Application layer code
[source,C#]
....

Tuple<int,int> result = new Tuple(42,0)
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....


Here is the Bind function:


[source,C#]
....
public static Tuple<int,int> Bind<T, U>(this Tuple<int,int> source, Func<int, int> function)
{
    int result = function(source.Item1);  // call the function
    return new Tuple<int,int> (
        result mod 360,   // normalize the angle
        source.item2 + result/360);   // count rotations
}
....


This time Bind takes a Tuple and returns a Tuple. The Tuple contains the angle between 0 and 359 and the rotations. Bind will do the mod 360 on the result returned by the function, and add any rotations. It returns a new Tuple with those two values.

Note that it was easy to get the starting 42 value into the Tuple needed by the Bind function by simply using 'new Tuple(42,0)'. So in this case we didn't need something like a ToTuple extension method.

Those were the immediate versions of the monads. Let's now have a look at the deferred versions of these monads. We want to understand the deferred version because they are much closer to how ALA works.


==== Deferred monads

If the monad is an immediate (eager) type, the value returned by the monad chain is the actual result. But if the monad is a deferred type, the value returned by the monad chain is an object structure that you can use to get the value. You might do things like the following to force the actual value out. 


[source,C#]
....
if (result!=-1) { use result }               // -1 monad
if (result.hasValue) { result.value }        // maybe monad
result.ToList()                              // IEnumerable
foreach (var value in result) {...}          // IEnumerable
result.Subscribe((x)=>{....})                // IObservable
result.ContinueWith(result => result.Result) // task
await result                                 // task
result.Item0, result.Item1                   // tuple
....


===== MinusOne monad (deferred version) (pull version)

Composition of functions that can fail by returning -1.

For the deferred version of the MinusOne monad, we use Func<int> instead of an integer as the interface. The Bind function takes a Func<int> and returns a Func<int>:


Here is top layer code that composes functions that can return -1:

[source,C#]
....
Func<int> CombinedFunction = 
    42.Bind(x => x+1).Bind(x = x*10+1).Bind(x => x==0 ? -1 : 1/x);
}
....


The Bind implementation doesn't call the function, it returns another function that can do that later: 

Pull version
[source,C#]
....
namespace Monad.MinusOne
{
    public static class ExtensionMethod
    {
        public static Func<int> ToMinusOne(this int source)
        {
            return () => source;
        }

        public static Func<int> Bind(this Func<int> source, Func<int, int> function)
        {
            return () =>
            {
                int value = source();
                return value == -1 ? -1 : function(value);
            };
        }
    }
}
....

The lambda functions are turned into closure objects by the compiler. The returned object structure looks like the diagram below.

image::MinusOneDeferredPullMonadDiagram.drawio.png[title=Object diagram of expression using deferred/pull version of MinusOne monad"]

This structure is exactly the same as the one we showed above for the Compose function. The only difference is that for the three closures that are created by the Bind function, the closure method contains the common code, that is it checks for  -1 from the source before calling the next function.

We got a little lucky with the implementation of the deferred/pull MinusOne monad. That is that we were able to use Func<int> as the interface that Bind takes and returns instead of using an actual interface with a function in it. That allowed us to use closures to implement the Bind and ToMinusOne functions, just as we did for the Compose function. From now on we won't be able to do that because the monads will be using an actual interface. 


===== MinusOne monad (deferred version) (push version)

Composition of functions that can fail by returning -1.

With deferred monads, we can do either pull versions or push versions.

For the pull version, we keep a reference to the last object in the structure. We call a function in that object when we want the result. That call pulls the data through the chain of objects.

For a push version, we still keep a reference to the last object in the structure, but when we call a function in that object, it just calls functions through to the  first object in the chain, which then pushes data through the chain. 

We will do both types so that we can properly understand the nuances of each. The push versions will be more comparable with default ALA programming paradigms. Here is the application code for the push version. 

[source,C#]
....
// deferred monad composition of functions that might return -1

IMinusOneObservable<int> result = 42.ToMinusOne()
    .Bind(x => x+1)
    .Bind(x = x*10+1)
    .Bind(x => x==0 ? -1 : 1/x);
}
....

The interface that Bind takes and returns is IMinusOneObserver. Here it is:

[source,C#]
....
public interface IMinusOneObservable
{
    void Subscribe(IMinusOneObserver observer);
}
....

All this interface does is give Bind a way to wire up another interface. And yes these two interfaces are exactly analogous to the IObservable and IObserver interfaces in reactive extensions.


[source,C#]
....
public interface IMinusOneObserver
{
    void Push(int value);
}
....

The IMinusOneObserve interface is wired in the same direction as the pushing  (although we could have chosen to use C# events instead). Since this interface is wired in the same directon as the dataflow, destinations implement the interface and sources will have a field of the type of this interface.

Bind can't be defined on the IMinusOneObsever interface because it's the wrong way around. Bind therefore uses the IMunusOneObservable interface that goes in the opposite direction of the dataflow.

For the push version we don't have the luck we had in the pull version that allowed us to implement it with closures because we had to use the IMinusOneObserver interface. The Bind function will instead use an explicit class, which we will call MinusOne. Here is that class, together with the ToMinusOne and Bind extension methods:


[source,C#]
....
namespace Monad.MinusOne
{
    static class ExtensionMethods
    {
        public static IMinusOneObservable ToMinusOneMonad(this int value) <5>
        {
            return new MinusOneStart(value);
        }

        public static IMinusOneObservable Bind(this IMinusOneObservable source, Func<int, int> function) <1>
        {
            MinusOne minusOne = new MinusOne(function);
            source.Subscribe(minusOne);
            return minusOne;
        }
    }




    class MinusOne : IMinusOneObservable, IMinusOneObserver <2>
    {
        private IMinusOneObserver observer; <3>

        private Func<int, int> function;

        public MinusOne(Func<int, int> function) <4>
        {
            this.function = function;
        }

        void IMinusOneObserver.Push(int value) <5>
        {
            if (value == -1)
            {
                observer.Push(-1);
            }
            else
            {
                observer.Push(function(value));
            }
        }

        void IMinusOneObservable.Subscribe(IMinusOneObserver observer)
        {
            this.observer = observer;
        }
    }




    class MinusOneStart : IMinusOneObservable <6>
    {
        private int value;
        private IMinusOneObserver observer;


        public MinusOneStart(int value) { this.value = value; }

        void IMinusOneObservable.Subscribe(IMinusOneObserver observer)
        {
            this.observer = observer;
        }

        public void Run()
        {
            observer.Push(value);
        }
    }
}
....

<1> The Bind method just instantiates a class to do the work. The Bind function also wires up the IMinusOneObserver interface using the Subscribe method.  

<2> IMinusOneObservable is implemented by data sources. IMinusOneObserver is implemented by data destinations. Our MinusOne class, as part of a chain of operations, is both a source and a destination, so it implements both. 

<3> Once wired, the only reference between the objects is the reference from source to destination in the field called observer in the MinusOne class. 

<4> The constructor just needs to store the function. we are composing.

<5> The Push method is the only part that runs when the monad object structure runs.

<6> The last thing to note is the usual method we need to get the 42 into the monad type so that we can start using Bind. In this case the monad type is IMinusOneObservable, so there needs to be a class that implements IMinusOneObservable. That class is MinusOneStart. The ToMinusOne extension method simply needs to instantiate this class.

Here is the object diagram of the resulting structure:

image::MinusOneDeferredPushMonadDiagram.drawio.png[title=Object diagram of expression using deferred/push version of MinusOne monad]

You can see that the three delegate-closure pairs we had in the pull version are replaced with an object of class MinusOne. The three objects are wired together in the direction of the data flow (left to right) using the IMinusOneObserver interface. The IMinusOneObservable was only used by the Bind function to effect the wiring of IMinusOneObserver. It is unused when the structure runs. The IMinusOneObservable interface at the end can be used to wire to an output object that implements IMinusOneObserver.

The 42 is stored in the object of the MinusOneStart class. This class has a run function which is used to start the structure executing. We start it from the source end because it is a push monad we are using. (This differs from the reactive extensions, which starts executing on Subscribe, so execution is actually initiated from the destination end.) In ALAs push programming paradigms, we usually initiate dataflow at the source end.

You can start to see the ALA pattern to this structure. It is instantiating objects and wiring them together to build a structure to run later. IMinusOneObserver is the equivalent of the ALA programming paradigm.

All the deferred monads we do from now on have this same structure. The push ones will be wired in the direction of dataflow, left to right, like this one is. The pull ones will be wired in the opposite direction of the dataflow, right to left. As I said, we were just lucky that the deferred pull version of the MinusOne monad that we did above was able to be implemented with closures because the monad type was Func<int> instead of a real interface. We will always need an explcit class from now on. 

Next well do a deferred pull monad that uses a real interface<T>, the IMaybe<T> monad.



===== IMaybe monad (deferred version) (pull version)

Composition of functions that can fail by returning IMaybe<T> or Nullable<T>.

Here is top layer code to use the deferred/pull implementation of the maybe monad.


[source,C#]
....
IMaybe<double> combinedFunctions = 42.ToMaybe()
    .Bind(x => new MaybeSomething<int>(x+1))
    .Bind(x => new MaybeSomething<int>(x*10+1))
    .Bind(x => x==0 ? new MaybeNothing<double>() : new MaybeSomething<double>((double)1/x) );
....

It looks the same as the immediate version. But it returns an IMaybe that's implements a large object structure instead of returning one of the two concrete IMaybe value objects. 

First we define the IMaybe interface, which is the same as for the immediate version above. The MaybeNothing and MaybeSomething classes are also the same as before.


[source,C#]
....
    public interface IMaybe<T>
    {
        bool HasValue { get; }
        T Value { get; }
    }

    public class MaybeSomething<T> : IMaybe<T>
    {
        T value;

        public MaybeSomething(T value) { this.value = value; }

        bool IMaybe<T>.HasValue { get => true; }
        T IMaybe<T>.Value { get => value; }
    }



    public class MaybeNothing<T> : IMaybe<T>
    {
        bool IMaybe<T>.HasValue { get => false; }
        T IMaybe<T>.Value { get { throw new Exception("No value"); } }
    }
....


The Bind function is different as it must build a structure that can be run later. It instantiates a class that implements IMaybe, which will do all the work at runtime.

[source,C#]
....
namespace Monad.MaybeDeferredPull
{
    static class ExtensionMethods
    {
        public static IMaybe<T> ToMaybe<T>(this T value)
        {
            return new MaybeSomething<T>(value);
        }

        public static IMaybe<U> Bind<T, U>(this IMaybe<T> source, Func<T, IMaybe<U>> function)
        {
            return new Maybe<T, U>(source, function);
        }
    }



    class Maybe<T, U> : IMaybe<U>
    {
        // implement the constructor, which receives the Action function
        private Func<T, IMaybe<U>> function;
        private IMaybe<T> source;
        private IMaybe<U> result;

        public Maybe(IMaybe<T> source, Func<T, IMaybe<U>> function) { this.source = source; this.function = function; }

        bool IMaybe<U>.HasValue 
        { get 
            {
                if (result == null)
                {
                    if (source.HasValue)
                    {
                        result = function(source.Value);
                    }
                    else
                    {
                        return false;
                    }
                }
                return result.HasValue;
            }
        }

        U IMaybe<U>.Value
        {
            get
            {
                if (result == null)
                {
                     result = function(source.Value);  // will throw exception if no value
                }
                return result.Value; // will throw exception if no value
            }
        }
    }
}
....

The code that runs later in the Maybe class is the HasValue and Value getters. They do all the work. 

Bind creates objects of the class Maybe and chains them together. This diagram shows the resulting structure from our little bit of application code:


image::MaybeDeferredPullMonadDiagram.drawio.png[title=Object diagram of expression using deferred/pull version of IMaybe monad]

Because this is a pull implementation of the monad, the references go in the opposite direction of the dataflow - from destination to source or from right to left. When you want to run the combined function, you pull the value from the right end. 



===== IMaybe monad (push version)

Composition of functions that can fail by returning IMaybe<T> or Nullable<T>.

Now the push version of the deferred IMaybe monad. Here is the top layer code, which in this case returns a IMaybeObservable.

[source,C#]
....
IMaybeObservable<int> result = 42.ToMaybe()
    .Bind(function1)
    .Bind(function2)
    .Bind(function3);
....

I've purposely left the lambda expressions out for now. Well get back to them in a minute.

As with the deferred push version of the MinusOne monad, we need two interfaces, IMaybeObservable<T> that Bind takes and returns, and IMaybeObserver for doing the actual pushing of data at runtime.

Here are the two interfaces:

[source,C#]
....
    public interface IMaybeObservable<T>
    {
        void Subscribe(IMaybeObserver<T> observer);
    }
....


[source,C#]
....
    public interface IMaybeObserver<T>
    {
        void NoValue();
        void Value(T value);
    }
....

The Bind function uses the IMaybeObservable to wire the IMaybeObserver interface in the opposite direction.

Now we consider the type that the functions that you compose should return. Normally with monads, this is the same interface that Bind takes and returns. So that would be IMaybeObservable. IMaybeObservable will certainly work, but the functions will be a little complicated. They will have the form: Func<T, IMaybeObservable<U>>. They would have to create an object implementing the IMaybeObservable interface to return. That interface then has a Subscribe method called on it, which gives the object an IMaybeObserver. Then the object can finally push out its result by pushing it via the IMaybeObserver.

It would be just so much simpler if the functions were passed the IMaybeObserver directly. If we did that, the functions would have the form Action<T, IMaybeObserver<U>>. Now when the functions run, they don't need to create an object to return. Instead they just directly push the result out via the IMaybeObserver<U>> interface. This kind of makes sense because it's a push monad. 

Here is the application layer code with lambda expressions:

[source,C#]
....
IMaybeObservable<double> combinedFunctions = 42.ToMaybe()
    .Bind((x,ob) => ob.Value(x+1))
    .Bind((x,ob) => ob.Value(x*10+1))
    .Bind((x,ob) => { if (x==0) ob.NoValue(); else ob.Value((double)1/x); } );
....

So remember when reading the monad implementation below, the 'functions' that you compose in the application layer are really Actions that take a T and a IMaybeObserver<U> and don't return a value.


[source,C#]
....
namespace Monad.MaybeDeferredPush
{
    static class ExtensionMethods
    {
        public static IMaybeObservable<T> ToMaybe<T>(this T value)
        {
            return new MaybeStart<T>(value);
        }

        public static IMaybeObservable<U> Bind<T, U>(this IMaybeObservable<T> source, Action<T, IMaybeObserver<U>> action) <1>
        {
            var maybe = new Maybe<T, U>(action);
            source.Subscribe(maybe);
            return maybe;           
        }
    }





    class Maybe<T, U> : IMaybeObserver<T>, IMaybeObservable<U> <2>
    {
        private Action<T, IMaybeObserver<U>> action;

        public Maybe(Action<T, IMaybeObserver<U>> action) { this.action = action; }


        private List<IMaybeObserver<U>> subscribers = new List<IMaybeObserver<U>>(); <3>

        void IMaybeObservable<U>.Subscribe(IMaybeObserver<U> observer)
        {
            subscribers.Add(observer);
        }


        void IMaybeObserver<T>.NoValue()
        {
            foreach (var subscriber in subscribers)
            {
                subscriber.NoValue();
            }
        }

        void IMaybeObserver<T>.Value(T value)
        {
            action(value, new ActionObserver<T, U>(this));
        }


        private class ActionObserver<T, U> : IMaybeObserver<U> <4>
        {
            private Maybe<T, U> outer;
            public ActionObserver(Maybe<T, U> outer) { this.outer = outer; }

            void IMaybeObserver<U>.NoValue()
            {
                foreach (var subscriber in outer.subscribers)
                {
                    subscriber.NoValue();
                }
            }

            void IMaybeObserver<U>.Value(U value)
            {
                foreach (var subscriber in outer.subscribers)
                {
                    subscriber.Value(value);
                }
            }
        }
    }




    class MaybeStart<T> : IMaybeObservable<T>
    {
        private T value;
        public ToMaybe(T value) { this.value = value; }

        private List<IMaybeObserver<T>> subscribers = new List<IMaybeObserver<T>>();
        void IMaybeObservabe<T>.Subscribe(IMaybeObserver<T> subscriber)
        {
            subscribers.Add(subscriber);
        }

        public void Run()
        {
            foreach (var subscriber in subscribers)
            {
                subscriber.Value(value);
            }
        }
    }
....


<1> As you can see, the Bind function just creates an object of the Maybe class to do all the work at runtime. The Bind function is defined on the IMaybeObservable interface and returns that same interface. It composes Actions rather than functions. These actions take an IMaybeObserver.

<2> The Maybe class implements both IMaybeObservable and IMaybeObserver. IMaybeObservable is only iused by Bind to call Subscribe. IMaybeObserver is the one that is wired (in the same directions as the dataflow) to be used at runtime to push the data through.

<3> The wiring of Maybe supports fanout or multiple subscribers (just like the observer pattern). We didn't do this for the MinusOne deferred push monad just to keep it simpler. But we will do it for all deferred push style monads from now on. It is normal for push monads to support fan out, in other words many observers can be listening to the same data that is pushed. It is another advantage of push style monads over pull style monads.

<4> You will notice an inner class called ActionObserver inside the Maybe class. At runtime, the Maybe class will need to call the action, and it needs an object that implements IMaybeObserver to pass to that action. That's what ActionObsserver is for. 


Here is an object diagram of the complete expression.

image::MaybeDeferredPushMonadDiagram.drawio.png[title=Object diagram of expression using deferred/push version of IMaybe monad]

You can see that the references between the objects, which use IMaybeObserver, go in the same direction as the dataflow. IMaybeObservable is only used for wiring the structure up.

The structure starts executing when the Run method in the MaybeStart object on the left is called. The application needs to keep a reference to this object so it can start the program. 

So far we have done deferred pull and deferred push implementations of the MinusOne and Maybe monads. Let's do a couple more examples of deferred monads to get more used to the pattern:


===== IEnumerable monad

Composition of functions that return many values, in this case an IEnumerable.

The IEnumerable monad is the deferred version of the list monad we did earlier. The IEnumerable monad is the most commonly used monad, and is what LINQ is based on.

The Bind function for the IEnumerable monad is called SelectMany in C#. SelectMany is not used as often as Select. Select takes a simpler function that returns U instead of IEnumerable<U>, so it doesn't expand the number of items, it just does a one-to-one mapping. While Select is used more often, it is the SelectMany function that makes it a Monad. Here in our example application we will use three SelectManys in a row. Each will expand in number by 3, so we will end up with an IEnumerable with 27 items in the end.  

Here is example top layer code that composes functions that return IEnumerable

[source,C#]
....


IEnumerable<int> result = 42.ToEnumerable()
    .SelectMany(function1)
    .SelectMany(function2)
    .SelectMany(function3);
....

You may remember that we used lambda expressions in the immediate example above that returned literally lists something like this:

[source,C#]
....
var result = new[] { 0 }  
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 })
    .Bind(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 });
....

While this will run fine when using the IEnumerable version of Bind, it's not really in the style of a deferred monad to create memory hungry arrays. So let's write functions that will do the same job in a lazy way:

[source,C#]
....
private static IEnumerable<int> MutiplyBy10AndAdd1Then2Then3(int x)
{
    yield return x * 10 + 1;
    yield return x * 10 + 2;
    yield return x * 10 + 3;
}
....

The _yield return_ keyword causes the compiler to generate an IEnumerable object, which it returns. The IEnumerable object contains a state machine where each state executes code till it hits the next yield return statement. 

Let's just reuse that function three times in our composed function:


[source,C#]
....
static void Application()
{
    var program = new[] { 0 }  
    .Bind(MutiplyBy10AndAdd1Then2Then3)
    .Bind(MutiplyBy10AndAdd1Then2Then3)
    .Bind(MutiplyBy10AndAdd1Then2Then3);

    var result = program.ToList();  // now run the program
    Console.WriteLine($"Final result is {result.Select(x => x.ToString()).Join(" ")}");
}
....

The Bind function (SelectMany) for this type of monad takes an IEnumerable<T> and returns an IEnumerable<U>. The Bind function doesn't use a for loop immediately as that would defeat the laziness. Instead the bind function uses an object that keeps state. Let's call this object the _output IEnumerable_. The output IEnumerable knows how to use the _source IEnumerable<T>_ to get the first value, which it gives to the function. The function returns an IEnumerable<U> which we will call the _function IEnumerable_. The output IEnumerable then knows how to get the values from the function IEnumerable<U> and return them one at a time. When it has exhausted all of them, the output IEnumerable<U> then gets the next value from the source IEnumerable<T>, and gives that to the function. The function again returns an IEnumerable<U>. This process continues until the source and function IEnumerables are both exhausted. 

In C#, the Bind function is really easy to write because the compiler can build an IEnumerable for you using the _yield return_ syntax:

[source,C#]
....
namespace Monad.Enumerable
{
    static class ExtensionMethods
    {
        public static IEnumerable<U> Bind<T, U>(this IEnumerable<T> source, Func<T, IEnumerable<U>> function)
        {
            foreach (var t in source)
            {
                var enumerator = function(t);
                foreach (var u in enumerator)
                {
                    yield return u;
                }
            }
        }
    }
}
....

Note that the code in the function does not run when this Bind function runs. The compiler sees the _yield return_ and builds an object containing a state machine that implements IEnumerable<U>, and returns that.

Since our purpose is to show how the Bind function is a refactoring of imperative code, here is a version that doesn't cheat by using the yield return syntax:


[source,C#]
....
static class ExtensionMethods
{
    public static IEnumerable<U> Bind<T, U>(this IEnumerable<T> source, Func<T, IEnumerable<U>> function)
    {
        return new EnumerableMonad<T, U>(source, function);
    }
}
....
    
All Bind does is instantiate the class and return it. The class gets passed the source IEnumerable and the function. The class implements IEnumerable<U> for its output, which means it must be able to return an object implementing IEnumerator. The easiest way to do that is have the class implement IEnumerator<U> as well. Then the IEmumerable can just return 'this'.


[source,C#]
....
class EnumerableMonad<T, U> : IEnumerator<U>, IEnumerable<U>
{
    private readonly IEnumerable<T> source; 
    private readonly Func<T, IEnumerable<U>> function;
    
    public EnumerableMonad(IEnumerable<T> source, Func<T, IEnumerable<U>> function)
        { this.source = source; this.function = function; } <1>

    private IEnumerator<T> sourceEnumerator = null;

    IEnumerator<U> IEnumerable<U>.GetEnumerator()
    {
        sourceEnumerator = source.GetEnumerator();
        return (IEnumerator<U>)this;
    }

    IEnumerator IEnumerable.GetEnumerator()
    {
        sourceEnumerator = source.GetEnumerator();
        return this;
    }


    private IEnumerator<U> functionEnumerator = null;

    U IEnumerator<U>.Current => functionEnumerator.Current;

    object IEnumerator.Current => throw new NotImplementedException();

    void IDisposable.Dispose() { }

    bool IEnumerator.MoveNext() <2>
    {
        while (true)
        {
            if (functionEnumerator != null)
            {
                if (functionEnumerator.MoveNext())
                {
                    return true;
                }
            }
 
            if (sourceEnumerator.MoveNext())
            {
                functionEnumerator =
                    function(sourceEnumerator.Current).GetEnumerator();
            }
            else
            {
                return false;
            }
        }
    }

    void IEnumerator.Reset()
    {
        functionEnumerator = null;
        sourceEnumerator.Reset();  
    }
}
....

<1> The constructor is passed both the sourceIEnumerable and the function. It saves both of them in local variables.
 
<2> The IEnumerator MoveNext method does all the work of the class at runtime. It is called by the next object in the chain. It gets the first element from the source, and feeds it to the function. Then it stores the Enumerator it gets from the function so it can use it in subsequent calls. Then it gets the first element from the function's Enumerator and returns it. A while loop is necessary because when the Enumerator that is returned by the function runs out, it needs to go back and get the next element from the source and pass that to the function.

The class is completely lazy, so it doesn't even get the source IEnumerator from the source IEnumerable until the first call of MoveNext.

The two fields, sourceEnumerator, and functionEnumerator are the state. The first can have a state of null, which is the state before we got the first value. 

The object diagram for the program again shows three objects wired in a chain from right to left:

image::IEnumerableDeferredPullMonadDiagram.drawio.png[title=IEnumerable Deferred Pull Monad Object Diagram]


Bind just wires the IEnumerable interface. The IEnumerable GetEnumerator method then effectively wires the IEnumerator interface (in the same direction). So you might wonder if the IEnumerable interface could be considered redundant. We not just make Bind wire up the IEnumerator interfaces and dispensed with IEnumerable altogether? That would work, but I guess the reason IEnumerable exists is because IEnumerator is already implemented by many underlying library collections. When writing a new class that will support foreach, we need only provide a GetEnumerator method that simply returns the underlying collection instead of implementing the whole IEnumerator interface. However in our class above, this didn't help because we had to implement the whole IEnumerator interface because we were recombining multiple collections.


===== IObservable monad

Composition of functions that return many values, in this case an IObservable.

The IObservable monad is the 'push' version of the IEnumerable monad, sort of. Once the flow of data begins, it is indeed pushed (source to destination). The data is pushed using the IObserver interface. But often it is the destination that initiates the transfer. The destination uses the Subscribe method in the IObservable monad to register to observe the data. But often this Subscribing is also what initiates the transfer in the source. Once a transfer is completed, another transfer can usually be started by unsibscribing and resubscribing. When used in this way, IObservable is sort of a pull programming paradigm for data transfer initiations.

Some writers equate IObservable with "asynchronous". However, a pushing interface like IObserver can be either synchronous or asynchronous. Data flows from the source object by calling a method in the IObserver interface called OnNext. That method can execute synchronously all the way to the destination end of the chain, or it can return at any point along the chain, and the data flow can resume from that point at a later time, which is what we refer to as asynchronous. 

Pull communications can't be asynchronous or broken up in time, at least not in a straight forward way. It either requires blocking the thread (we don't want to go there) or using a Callback, or using a Task or future object (which we cover later). The IEnumerator interface, being a pull interface, can only work synchronously. With IEnumerator, the destination end pulls data by calling a method. The function must execute synchronously all the way to the source otherwise it would return without a result. 

The ability of a push style programming to be either synchronous or asynchronous is a good reason to default to using it. It is the reason ALA defaults to using push. Sometimes there are good reasons to use pull, but where it doesn't matter, we prefer push. So it is worth covering the IObservable monad, even though IEnumerable monads tend to be more common. IObservable is the closest for comparison with the common ALA programming paradigms.


////
I think the reason the IEnumerable monad is more common may be because it seems more suited for database queries. After all, for this context it is the destination, not the source, that knows when it wants data. Or at least it's usually something nearer the destination end such as a button.

However, this doesn't mean that database queries should use pull. The system could well benefit from using push based communications even from a database. For example, this would allow for asynchronous data transfers of the results of a query over a network.

To use push for database queries, and initiate the transfer from the destination end, you need only invent a programming paradigm that has two push channels, one in each direction. A query push channel goes toward the database, and a response push channel comes back. In ALA, because you can easily implement programming paradigms, this is really easy to do, and should be the way database queries are done. A database adapter at the end implements this "push/push" programming paradigm and does the work of actually talking to the database with SQL.

The IObservable interface is apparently a push request/push response paradigm. In addition to wiring the IObserver interface, the IObservable.Subscribe method can also initiate the data transfer. But the Subscribe method can only communicate when we want the data, but can't take other details of an actual query. So IObservable is not that suited to databases without yet another push channel to handle the the query. So IQueryable, which is based on IEnumerable tends to be used with databases.
////

Unlike the IEnumerable/IEnumerator pair of interfaces which go in the same direction, the IObservable/IObserver interfaces go in opposite directions. The IObservable interface goes from destination to source whereas the IObserver interface goes from source to destination. 

In the context of monads, the IObservable interface, being in the direction of destination to source, is the one that is used by BInd. IObserable is then used to wire and initiate the IObserver interface in the opposite direction. 

////
It is possible for the source to not initiate the transfer on subscribe, and wait until it receives a separate event. As discussed above, this destination initiated data transfer paradigm appears to what we want for databases. However, with database queries, we need to pass request data in the push channel toward the database, and the Subscribe method can't do that. The only information it can take is timing information, that is 'when' to it wants the data. So it turns out that IObservable is not suitable for databases after all.

TBD look at IQueryable.
////

In the context of ALA, it is a disadvantage to combine the 'wiring' and the 'start transfer' in the same Subscribe method call. In ALA we keep these two things separate because we want the code for these two things to be in two separate places. The wiring code represents a user story and so goes in a user story abstraction. We wire up entire program first and then set them running. The starting of a data transfer is an run-time event. It originates, for example, from a button domain abstraction. The two pieces of code should be in two separate abstractions. However, because this is an IObservable monad implementation example and not ALA, the Subscribe method will do both the wiring and initiating the data transfer. 

Another thing we will do, like we did for the deferred/push version of the Maybe monad, is compose Actions instead of Funcs. When an Action is called at runtime, it will be passed an object for its output that implements IObserver. The action will use the IObserver to output directly instead of returning a function that has to create an IObservable in order to do its output. This greatly simplifies the code in the Actions, which is what we want because these Actions are application code. If we composed Funcs that return IObservables, we would need to make every Func more complicated. Instead the Bind function will take on extra work. It needs to create an IObservable object to pass to the action. 

If you look at the SelectMany in the reactive extensions library for C#, you will see that it takes a Func. But there are two overloads. In one, the Func returns an IObservable object as expected. For the other, it returns an IEnumerable. It's a shame that the second overload doesn't take an Action that takes an IObserver. That would have truly simplified things the actions. Anyway that's what we will do in our example here.

Here is an action to use in our example applicaton:

[source,C#]
....
static void MutiplyBy10AndAdd1Then2Then3(int x, IObserver<int> observer)
{
    observer.OnNext(x * 10 + 1);
    observer.OnNext(x * 10 + 2);
    observer.OnNext(x * 10 + 3);
    observer.OnCompleted();
}
....

It takes a single integer as input and outputs a steam of three integers. The output goes to the IObserver that is also passed to teh Action.


Here is our test application.

[source,C#]
....
static void Application()
{
Observable.Create<int>(
    observer => {
        observer.OnNext(0); 
        observer.OnCompleted();
        return Disposable.Empty; 
    })
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Bind<int,int>(MutiplyBy10AndAdd1Then2Then3)
    .Subscribe((x) => Console.Write($"{x} "),
                (ex) => Console.Write($"Exception {ex}"),
                () => Console.Write("Complete")
                );
}
....

We start with a single integer with value zero, and then compose the action three times. Finally we send the output to the Console.

Now lets write the Monad's bind function. As usual, C# (in this case the reactive extension library) provides us with a shortcut way to implement Bind by using Observable.Create and Observer.Create. This shortcut method obscures the way the Bind function is a refactoring of the imperative code, which is our purpose. However, for reference, here is the shortcut version first:


[source,C#]
....
static class ExtensionMethods
{

    public static IObservable<U> Bind<T, U>(this IObservable<T> source, Action<T, IObserver<U>> action)
    {
        return Observable.Create<U>(outputObserver => <1>
        {
            source.Subscribe( <2>
                x => { action(x, Observer.Create( <3>
                        value => outputObserver.OnNext(value), <4>
                        ex => outputObserver.OnError(ex), <4>
                        () => { } <4>
                    ));
                }, <5>
                ex => outputObserver.OnError(ex), <3>
                () => outputObserver.OnCompleted() <3>
            );
            return Disposable.Empty;
        });
    }
....

If you find this version hard to read, just skip forward to the next version.

<1> Bind returns an IObservable, so the first thing we do is create a new IObservable to be returned.
+
The Observable.Create method in the reactive extension library will create an object that implements IObservable. You pass it a Subscribe function. It does nothing more than create an object that implements IObservable, and uses the Subscribe method you gave it as the implementation of the IObservable. In this case we pass in a lambda (anonymous function) as the Subscribe method. 
+
Remember a Subscribe method is passed an IObserver, so that's the 'outputObserver' part of the lambda expression. The lambda expression takes up the entire rest of the code starting from 'outputObserver =>'. 

<2> When the Subscribe lambda expression gets called at runtime, it must subscribe to the source.

<3> In subscribing to the source, we supply three functions for the source to call, OnNext, OnError and OnCompleted. The OnError and OnCompleted are routed directly to the outputObserver. The OnNext is routed to the action.

<4> The action must in turn be given an observer for it to output to. Observer.Create creates an object that implements IObserver. You provide the three functions, OnNext, OnError, and OnCompleted that the IObserver interface needs. 
+
If the action outputs data it is passed directly to the outputObserver. If the action outputs an error, it too is passed directly to the outputObserver. But if the action outputs OnCompleted, it is discarded. This is ecause the monad must combine the streams from multiple calls of the action into a single stream. 

You may think we do not need the extra observer. Why not just pass outputObserver to the action like this:?


[source,C#]
....
x => action(x, outputObserver);
....

That would indeed correctly pass the multiple outputs of the action to the outputObserver. However, the action may call OnCompleted at the end of each of its sequences. If it does we need to intercept it and remove it because otherwise it will terminate the outputObservable sequence prematurely. This removal of the OnCompleted from the function's output is effectively what 'flattens' the output.

Removing the OnCompleted call is the reason we use Observer.Create(). 

Now we do a verion that does not use either Observable.Create or Observer.Create. Although the code is longer, this will be easier to understand since our purpose is to show how we can refactor the original imperative code. This shows more clearly that the Bind function works by instantiating an object that will do all the work at runtime, and then simply wiring that object to the previous one. 

[source,C#]
....
public static IObservable<U> Bind<T, U>(this IObservable<T> source, Action<T, IObserver<U>> action)
{
    return new Observable<T, U>(source, action);
}
....

The bind function simply instantiates an object from an explicit class called Observer. This class is listed below.


[source,C#]
....
private class Observable<T, U> : IObserver<T>, IObservable<U> <1>
{
    private readonly IObservable<T> source;
    private readonly Action<T, IObserver<U>> action;
    
    public Observable(IObservable<T> source, Action<T, IObserver<U>> action) { this.source = source; this.action = action; } <2>


    private IObserver<U> output;
    private InnerObserver<U> innerObserver;

    IDisposable IObservable<U>.Subscribe(IObserver<U> observer) <3>
    {
        output = observer;
        innerObserver = new InnerObserver<U>(output);
        source.Subscribe(this);
        return Disposable.Empty;
    }

    void IObserver<T>.OnCompleted() <4>
    {
        output.OnCompleted();
    }

    void IObserver<T>.OnError(Exception ex) <4>
    {
        output.OnError(ex);
    }

    void IObserver<T>.OnNext(T value) <5>
    {
        action(value, innerObserver);
    }
    
    // Observer that simply interceps OnCompleted
    private class InnerObserver<U> : IObserver<U> <6>
    {
        public Observable(IObserver<U> output) { this.output = output; }

        IObserver<U> output;

        void IObserver<U>.OnCompleted() { } // discard

        void IObserver<U>.OnError(Exception ex) { output.OnError(ex); }

        void IObserver<U>.OnNext(U value) { output.OnNext(value); }    
    }
}
....


<1> The objects of this class implement both IObserver and IObservable. IObserver allows the object to be used to subscribe to the source. IObservable allows the next object in the chain to subscribe to it.

<2> The class's constructor stores the source and the action.

<3> The class's Subscribe method saves the output observer. It also Subscribes this object to the source, which usually starts the transfer of data.

<4> The OnCompleted and OnError methods, (which are called by the source) simply pass through to the output observer.

<5> The OnNext method, (which is called by the source) calls the action, and passes it the InnerObserver object to output to. The InnerObserver passes OnNext and OnError through to the output, but discards any OnCompleted produced by the action. This discarding of OnCompleted from the action is what joins all the sequences produced by the calls to the action together.

<6> The InnerObserver's only function is to remove OnCompleted calls from the action getting to the output so that the sequences get joined. (Note: We could have used Observer.Create instead of having the InnerObserver class. However, we would have had to use Observer.Create in the OnNext method to get a new instance to pass to the action every time. This is because the observer object created by Observer.Create will stop working when it gets a OnCompleted.) The explicit InnerObserver class makes it a little clearer what is going on.


===== Task monad

Composition of functions that return a Future, Promise or Task object.

With this monad, we will be able to compose functions that return a Task object, which is an object that represents a value it will get in the future.

We did not do an immediate version of this monad earlier because the functions don't return a value immediately so we can't. So this is the first time we will do this monad.

We did the imperative code that called the functions one after the other earlier in this section. You may remember that we attached a continuation action to Task objects returned by each function. In the first imperative version, each continuation had another level of nesting, and in the second version, an Unwrap was required. Also, if you look at the version on Github, the ContinueWith requires an additional parameter to cause everything to run on one thread.

For the Task monad, we simply factor out all this logic into a Bind function, which is really easy to do.

The application code then uses the Bind function to compose functions declaratively in the same way as any other monad:


[source,C#]
....
// monad composition of functions that return a future

Task<int> CombinedFunction = 
    42.ToTask().Bind(function1).Bind(function2).Bind(function3);
....

The difference from other application code we have done is that the interface that Bind takes and returns is Task<T>. The starting value has to be converted to a Task<T> first, which is the purpose of the ToTask extension method.

Once again there is a way of using the compiler to cheat to implement the Bind function:


[source,C#]
....
public static async Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    return await function(await source);
}
....

The async/await feature is indeed powerful, but our purpose is to see how Bind is a refactoring of the original imperative code. So here is the version that uses ContinueWith instead of async/await.


[source,C#]
....
public static Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    var tcs = new TaskCompletionSource<U>();
    source.ContinueWith(
        (t) => function(t.Result).ContinueWith(
            (t) => tcs.SetResult(t.Result)
        )
    );
    return tcs.Task;
}
....

The Bind function is passed a Task<T> and immediately creates a new Task<U> via TaskCompletionSource, which is returned. A closure object is created for the first lambda expression and a delegate object is created to call that. The ContinueWith attaches the delegate to the source Task<T> as a (callback) Action. The Task<> that is returned by ContinueWith is discarded.

When the source Task<T> produces a result, the first lambda expression will run. When it does, it receives the Task<T> and passes the result from it to the function. The function immediately returns a Task<U> (a different Task<U> from the one created earlier). That Task<U> is attached to a second continuation lambda expression. When the Task<U> produces a result, the second lambda is called. It puts the result into the tcs.

The Bind function can also be written using Unwrap, which eliminates the need for the TaskContinuation source:

[source,C#]
....
public static Task<U> Bind<T, U>(this Task<T> source, Func<T, Task<U>> function)
{
    source.ContinueWith((t) => function(t.Result)).Unwrap();
}
....

When the lambda expression runs, it returns the Task<U> that is returned by the function, so the ContinueWith itself returns a Task<Task<U>>. The Unwrap discards the outer Task<>.

The async/await version generally runs everything on the same thread by default, which is great, but this is not the case for the ContinueWith version unfortunately. The example code on Github 
https://github.com/johnspray74/ContinuationMonad[https://github.com/johnspray74/ContinuationMonad]
shows a console application that passes a TaskScheduler.FromCurrentSynchronizationContext() parameter to the ContinueWiths so that everything runs on the Console UI thread. That thread is never blocked.

The functions that can be composed using this Bind function must return synchronously with a Task object, but can take as long as they want to put a value into the Task. In the sample application on Github, we use one function with a delay, and one that does I/O. Another case is a function that will do CPU bound work on another processor.

Here are the two examle functions we can compose:

[source,C#]
....
    private static Task<int> function1(int x)
    {
        return Task.Delay(3000).ContinueWith(_ => x + 2);
    }
....



[source,C#]
....
private static Task<int> function2(int x)
{
    Console.WriteLine($"Value is {x}. Please enter a number to be added.");
    string line = null;
    return Task.Factory.StartNew(() => line = Console.ReadLine())
    .ContinueWith(_ => x + int.Parse(line));
}
....


The Task monad consists of the Task<T> type, the Bind function and the ToTask function. It is used to compose asynchronous functions. It is inherently a deferred/push monad. 


===== Mod360 monad

Finally, let's do a deferred version of the mod360 monad that we used as an example of refactoring arbitrary code. You'll remember that we had imperative code that was doing mod 360 after every function call. We already did a simple immediate version of the monad. Let's skip the deferred/pull version and go straight to the deferred/push version. 

Here is a suitable interface for the monad:

[source,C#]
....
interface IMod360Observer
{
    void Push(Tuple<int,int> value);
}
....

Item0 in the Tuple is the angle, and Item1 in the tuple is the rotations.

And we will need a second interface for the Bind function to use:

[source,C#]
....
interface IMod360Observable
{
    void Subscribe(IMod360Observer observer);
}
....


Here is the application example code using the monad:

Application layer code
[source,C#]
....
var program = 42.ToMod360();
program.Bind(function1).Bind(function2).Bind(function3);

program.Run()
....


Here is the Bind function and ToMod360 function. Both use explicit classes to do the actual work. 

Monad layer code
[source,C#]
....
static class ExtensionMethods
{
    public static IMod360Observable ToMod360(this int value)
    {
        return new Mod360Start(value);
    }

    public static IMod360Observable Bind(this IMod360Observable source, Func<int,int> function)
    {
        var mod360 = new Mod360(function);
        source.Subscribe(mod360);
        return mod360;           
    }
}
....


The Bind function just instantiates a Mod360 class, configures it with the function being composed, and wires it to the previous object using the Subscribe method of its observable interface. The Subscribe method effects wiring in the opposite direction using the observer interface, which is needed because it is a push monad.

The class that does the work for the Bind function is below. It implements IMod360Observer for use by the previous object, and IMod360Observable for use by the next object.


[source,C#]
....
class Mod360 : IMod360Observer, IMod360Observable
{
    private Func<int,int> function;

    public Mod360(Func<int,int> function) { this.function = function; }


    private List<IMod360Observer> subscribers = new List<IMod360Observer>();

    void IMod360Observable.Subscribe(IMod360Observer observer)
    {
        subscribers.Add(observer);
    }


    void IMod360Observer.Push(Tuple<int,int> value)
    {
        int functonResult = function(value.Item1);
        Tuple<int,int> result = new Tuple<int,int> (
                functionResult mod 360,   // normalize the angle
                value.Item2 + functonResult/360) // count rotations
            );
        foreach (var subscriber in outer.subscribers)
        {
            subscriber.Push(result);
        }
                
    }
}
....

The Observer.Push function does all the work at runtime. It first calls the composed function, and then creates a result Tuple from the source Tuple and the Tuple that is returned by the function.


This is the class used by ToMod360, which is straightforward.


[source,C#]
....
class Mod360Start : IMod360Observable
{
    private int value;
    public Mod360Start(int value) { this.value = value; }

    private List<IMod360Observer> subscribers = new List<IMod360Observer>();
    void IMod360Observabe<T>.Subscribe(IMod360Observer<T> subscriber)
    {
        subscribers.Add(subscriber);
    }

    public void Run()
    {
        foreach (var subscriber in subscribers)
        {
            subscriber.Push(new Tuple<int,int> {value,0});
        }
    }
}
....

Note that previously with the IObservable monad, we used two interfaces IObservable and IObserver. The Subscribe method in the IObservable interface is what starts the data being pushed from the source.

In this Mod360 monad, we have deliberately gone to a purely push paradigm. Calling the Subscribe method from the destination end does not intiate the dataflow. Instead we keep a reference to the source, and have a Run method in the source. This makes an object structure that is more purely a push system, because the initaition of the dataflow is not done by a pull call from the destination end. This is much closer to how ALA works for its default programming paradigms.

That completes our four examples of refactoring imperative code using the monad refactoring pattern. We are now in a position to understand the general monad refactoring pattern for composition of functions.


==== The monad pattern

In the examples of Bind above, the type that Bind takes and returns for chaining is generally a class or interface. A class is like an interface with only one implementation, so we are generally going to think of it as an interface. We did have one example where it was an integer, and one where it was a Func, but these too can be thought of an interface in a broad sense.

The interface can be anything we want for the refactored code to communicate along the chain. It can be an actual interface, such as IEnumerable<T>, or IMaybe<T>, or it can be a class such as Task<T>. Or it can be a complex interface that we write to get any common information we want through the chain.

Bind always takes this interface and returns the same interface. You can therefore chain Bind calls together using fluent syntax. 

The interface is usually generic, so takes a type as a parameter, e.g. IEnumerable<T>. The Bind function takes an Interface<T> and returns an Interface<U>. So the generic type can change as it goes along the chain.

The pattern is about composing functions. These functions gnerally take a T and return an Interface<U>. 

Here is an application that composes three functions using a Bind function:

[source,C#]
....
var I4 = source.Bind(function1).Bind(function2).Bind(function3);
....

When composing functions like this, you can't explicitly see the type of the interface that's being used. I sometimes insert a decorator to write the type to the console:

[source,C#]
....
var I4 = source.Type().Bind(function1).Type().Bind(function2).Type().Bind(function3).Type();
....


[source,C#]
....
public static T Type<T>(this T source) { Console.Writeline(typeof(T)); }
....

Here is pseudo code showing the actual types:

[source,C#]
....
Interface<T> I1 = source;
Interface<U> I2 = I1.Bind(func<T, Interface<U>>);
Interface<V> I3 = I2.Bind(func<U, Interface<V>>);
Interface<W> I4 = I3.Bind(func<V, Interface<W>>);
....

As you can see, while Bind always takes an interface and returns the same interface, the generic type may change along the way. In our examples above we didn't change the type much, but remember that you can.

Here is a diagram of the general monad pattern.


image::MonadPattern.png[title=The monad pattern]


As you can see, monads are a 2-layer pattern. The two layers correspond roughly with ALA's application and programming paradigms layers. The code that uses Bind to compose functions, and the lambda functions themselves are in the application layer. The Bind function and the Interface<T> are in the programming paradigms layer. Often monads come with a set of more specialized functions such as Sort, Filter or Sum. These would go in the equivalent of the domain abstractions layer. These functions either use Bind, or do the equivalent logic as Bind themselves.

In the higher layer you have the functions that you are composing to build a specific application. In the lower layer, the Bind function contains the common refactored code. Everything is more abstract and more reusable in the lower layer.

The functions that are being composed take a T and return an Interface<U>. It is tempting to think that the Bind function simply returns the Interface<U> that is returned by the function, because they have the same type. But that is not usually the case. Bind usually creates a new object that implements Interface<U>, and then combines information from both the input Interface<T> and the output of the function to provide the output Interface<U>. That's what the diagram is trying to convey.

In many explanations of monads, they call the interface the _monad type_, or a _wrapped type_, or a _container type_, or a _type in a box_, or an _amplified type_, or just the notation _M T_. I don't think any of these forms are helpful in understaning monads. The _wrapped_, _container_ and _box_ terms don't work well for deferred monads, which don't actually contain a value. They contain a means of getting a value. For example, the deferred version of a list is IEnumerable. If our function returns an IEnumerable, that's not really a container or box.

The term _amplified_ just introduces another seemingly abstract concept which is unnecessary. And the term Monad type or the notation M T seems a bit circular - let's not explain monads in terms of monads. So I prefer to think of the thing that the Bind function takes and returns as simly an interface. It sometimes has one implementation, such as Task or List, but often it has more than one implementation such as IMaybe or IEnumerable. Usually the Maybe monad uses IMaybe with two implementations, one for when there is a value and one for when there is no value. 

So generally I just think of it as _Interface<T>_.

The monad pattern requires three things: 
* an Interface<T>
* a constructor or method for making ordinary values of type T into an object that  implements Interface<T>
* a Bind function that takes an Interface<T>, returns an Interface<U>, and is passed a function of the form Func<T, Interface<U>>.

The constructor or method for getting ordinary values into Interface<T> form is required to get started at the beginning of a chain. At the end of the chain, we can always get values back out because the Interface<T> always provides that.

Bind can pipe any extra information or capability we want through the interface. We could, for the sake of a silly example, pipe through an audio stream if we really wanted to. The bind function would take care it.

===== SelectMany vs Select

The LINQ opertors such as Select and SelectMany use IEnumerable as their _composition interface_ - they take an IEnumerable and return an IEnumerable. This allows them to be composed in chains using dot operators.  

Select is like Map. It takes a function that maps inputs to outputs in one to one correspondence. Aggregating operators such as Sum produce a single output from many inputs. SelectMany is the opposite - it produces many outputs from a single input.  

Select is probably the most common operator used in LINQ statements. So why is SelectMany the fundamental Bind operator and not Select?

It's because SelectMany is the one that strictly fits the monad pattern as shown in the previous section. For a monad, the function being composed also returns the _composition interface_. SelectMany is the one that does that. Select only takes a function that returns a single value. 

So while we sometimes think of LINQ as being monads, strictly speaking only SelectMany is part of the IEnumerable monad.  



===== Summary of monad benefits.

Monads allow us to simply compose functions declaratively in the top layer to implement a user story. How everything executes is handled by the Bind function in a more abstract lower layer.

The declarative code in the top layer is a different programming paradigm from imperative. It's called dataflow, because we are directly composing a flow of data, irrespective of how the underlying execution will work.

Monads make it possible for the application code to concentrate on expressing user stories, and not be concerned with execution details.  

Monads take care of passing data from function to function within Bind, without the application layer code needing to handle it.

The execution code in the Bind function can handle many different cases of logic that would otherwise have been messy imperative code between function calls.

We can compose as many functions as we like in chains of arbitrary length without any nesting of brackets or indenting.

Monads make it possible for application code itself to be pure functional code, even though the structure of connected objects that is built is not. 

The application code examples that use the deferred versions of Bind look much the same as the immediate versions. That's because at the application level, we are just declaratively composing functions. 

We prefer to implement deferred versions of Bind because then we have the option of executing them straight away as if it was immediate, or use them as part of a larger program for later execution. 

Deferred monads make it possible to completely separate all code that expresses user stories from code that implements computing details.


=== ALA compared to monads

Now that we have an understanding of monads, and deferred/push monads in particular, we are in a position to compare them with ALA.

In chapter three, we compared ALA and monads. 

The points were:

* In the application layer, monads compose functions whereas ALA composes objects with ports.

* Composing with monads is a dataflow programming paradigm, whereas composing objects with ports is a multi programming paradigm.

* Composing monads creates mostly a chain structure whereas composing objects with ports creates an arbitrary network structure. Monads can be networked as when two streams are merged, but in practice most functions have a single input and single output port.

* Both deferred monads and ALA build a structure of objects which is subsequently executed in a second phase. This separates declarative application code from computing code.

* Both monads and ALA use pure functional code for the application code in the top layer. In this respect ALA and monads achieve the same job by putting the dirty computational work inside a pre-written Bind function or class. This dirty work can include private state and I/O side effects.

* ALA's domain abstraction objects are more versatile than functions because they can more naturally have many ports, and these ports can use different programming paradigms. This allows for abstractions suitable for composing all aspects of user stories, such as UI, schema, business rules, etc.
+
For example, you can have a single domain abstraction with a UI port (to be attached somewhere in the UI) multiple event driven ports (for mouse clicks) and a dataflow port (for binding to a data source).

* Dataflow ports can each use either push or pull as appropriate in each particular case, whereas monads tend encourage you to use only one type or the other as a programming style, e.g. 'reactive programming'. 

* 'Push' dataflow interfaces can be used for either synchronous or asynchronous dataflows. So in ALA we default to using push style dataflows unless 'pull' has a particular advantage in a particular case. This allows instances of abstractions to be wired either synchronoulsy or asynchronously. In other words the choice of syncronous or asynchronous is deferred until the application user stories are written. Asynchronous can be chosen for example when two instance of abstractions will communicate over a network, or on on differnt threads, and synchronous can be chosen when the two will communicate on the same thread.
+
'Push' style dataflows (reactive extensions) appear to be less popular. I don't understand why. Perhaps it's because the IObservable interface isn't a true push style since the destination usually starts the flow of data by Subscribing (cold observables)? This mix of pull and push behaviour in the IObservable/IObserver pair is confusing and not easily amenable to network or miltithreaded systems that would otherwise suit push programming paradigms. Hot observables do not need the pull to initiate the data flow, but they have to avoid using both OnCompleted and OnError, otherwise the whole chain must be resubscribed. So they don't use the full benefits of the IObserver interface.

* ALA programming paradigms, which are usually interfaces, are analogous to monad interfaces. ALA programming paradigm interfaces can do anything that monad interfaces can do, such as IMaybe, IEnumerable, or Task or futures. 

* A monad's Bind function is partially analogous to ALA's WireTo function, because it implements the wiring. However the Bind function is different for every different monad type because it includes the deferred, run-time, common, execution code of the monad. ALA's WireTo function only does the wiring. It does not normally include any common run-time code, although it can sometimes be overridden to do special wiring. Instead, in ALA, that common code goes into programming paradigm interface, which may use intermediary objects. WireTo is generally the same WireTo for all programming paradigms and therefore all wiring up of an entire application.

* Monads usually use deferred execution and ALA always uses deferred execution, so in this respect they are similar. Both build an object structure which you then run after the wiring up is completed. They both have two phases, the wiring up phase and the run-time execution phase. However, in ALA, we always separate out all the wiring code for the entire application and then set the whole application running. Deferred monads are often wired up and then executed in the same code statement.
+
By building the entire application first, ALA completely separates code into a top layer at the abstraction level of specific user stories, and a second layer that consists of domain abstractions that contain all the code that executes at run-time. In this way the top layer has _all_ the declarative code that expresses the application and the second layer has _all_ the imperative code that knows how to do general computation work at runtime.

* ALA's application layer corresponds loosely with functional code that composes functions. ALA's programming paradigms correspond loosely with Bind functions. And ALA domain abstractions correspond loosely with the set of methods that generally come with a monad library such as Select or Where. With respect to these three layers, monads are a pattern that is consistent with ALA's fundamental constraints.



==== Composing with plain objects instead of functions.

By using plain objects the barrier to understanding seems lower than for monads, at least for developers already familiar with objects. Functional programming, and monads in particular, seem to have quite a high barrier to entry unless you are a mathematician. The world needs the programmers who are able to understand objects but do not necessarily understand mathematical notation. I'm not sure what would happen if all universities only taught functional programming so that everyone is introduced to pure functions first. Perhaps then it would be objects which have a barrier to entry. 

ALA's domain abstraction objects are easier to understand than monads because they are plain objects. The mental model of composition in ALA is wiring instances of  domain abstractions by their ports, which is conceptually known as the component model. Monads compose functions so the mental model is primarily oriented to composing a chain of functions as a dataflow. To make an analogy with electronics, ALA is like composing ICs (integrated circuits with many pins) and monads is more like composing two-port components such as resistors, capacitors, inductors and transistors.

There seems to exist computing problems that are best described using state. Objects are the language feature that provides for this. Monads end up using objects with state anyway - they are just hidden beneath the covers. 

The only slightly unusual thing about ALA's domain abstraction objects and plain object oriented objects is the use of _ports_. Posrt are used for all run-time input and outputs. Any programmer with familiarity with dependency injection can understand that a port is just an implementiion of dependency injection. A _port_ is implemented simply as a field of the type of an interface, or is an implemented interface. As with normal dependency injection, the field is assigned a reference to another object that implements the port interface. 

Unlike conventional dependency injection, the field is not assigned by the constructor or any setters. Instead the field is always assigned through use of WireTo or WireIn. 

The bigger difference between ALA and conventional dependency injection is that the interface used must be more abstract than either of the classes. It is not even an abstract base class. It is even more polymorphic than that. This type of interface is called a programming paradigm, and can be implemented by many disparate classes. Therefore, the dependency injection cannot be container based. Instead the application code must explicitly instantiate the objects and then wire them together.

Because ALA uses plain objects, and plain interfaces as their ports, ALA developers can add new domain abstractions and programming paradigms themselves to build a DSL for expressing their user stories. In the functional world, developers can certainly write new monad types, but it doesn't seem that easy, and seems generally left to library developers. The abstraction level of these libraries is therefore generally not as close to the domain, and does not make a DSL.


==== ALA vs monad syntax

Although ALA supports multiple programming paradigms, the dataflow programming paradigm is quite a common one. So we will inevitably need domain abstractions like those that come with monad libraries like Select, Where and Sum. So it is worth comparing the syntax of dataflows.

Here we are comparing the code in the top layer, the code that describes a user story. Both monads and ALA use fluent style with dot operators. For monads, the composed abstractions are functions that return the same interface, so they can be chained directly: 

[source,C#]
....
source.Filter(x=>x>=0).Select(x=>sqrt(x))
....

In the Monad version above, the Filter and Select functions effectively do both the wiring and specify the operation to be wired.

In ALA, WireIn is just a generalized object composition operator, so we need to separately instantiate an object that does the operation we want:

[source,C#]
....
source.WireIn(new Filter<int,bool>(x=>x>=0)).WireIn(new Select<int,int>(x=>sqrt(x))
....

Usually this code is generated from a diagram. However, there is nothing stopping us achieving exactly the same syntax as the monad version if we really want to. We just create some extension methods:


// in Select.c
[source,C#]
....
namespace DomainAbstractions
{
    static class ExtensionMethods
    {
        public static IBindable Select<T, U>(this IBindable source, Func<T,U> function)
        {
            var select = new Select<T, U>(function);
            source.WireIn(select);
            return select;
        }
    }
}
....


// in Filter.c
[source,C#]
....
namespace DomainAbstractions
{
    {
        public static IBindable Filter<T>(this IBindable source, Func<T,T> function)
        {
            var filter = new Filter<T>(function);
            source.WireIn(filter);
            return filter;
        }
    }
}
....

The code for these extension methods go in the same abstractions as the Select and Filter classes respectively.

Note that IDataFlow is the interface that is actually being wired. IDataFlow goes in the forward direction (the same direction as the data flow). So the Select and Filter extension methods can't be defined on IDataFlow or IObservePush. We need an interface on which to define Select and Filter. This interface must go in the reverse direction towards the source. So that's what IBindable is for. IDataFlow and IBindable are somewhat analogous to the IObserver and IObservable interfaces respectively. Note, though, that IBindable only exists to give us an interface on which to define the extension methods. It doesn't do anything else, so it contains no methods:

[source,C#]
....
interface IBindable {}
....

Note: normally IBindable would have a type parameter: IBindable<T>. That would allow type inference to be used for the type parameter of methods that are defined on it such as Bind<T,U> and Select<T,U>, etc. However, the compiler can't always successfully use type inference for that second type parameter. It can if the second parameter passed to Bind is a function that returns a certain type. But it can't if the second parameter is an action, which is the case for the ObServerPushAction domain abstraction. Therefore I have removed the type parameters from IBindable so that its less confusing, and Bind etc will always need to have its types passed explicitly.


////

===  Monads (old, needs review)

==== Monad syntax


Let's assume for the ALA case, that the instanceB being wired converts objects from one type to another, the same as a function binded to monad does. So in both cases, we have a source of TAs and we want to wire in an operation that will convert them to TBs. 

Both bind and WireIn have an object as their first argument. That object is the source for TAs. Both bind and WireIn can be written using the dot operator style:

.Monad wiring code
[source,C#]
....
objectA.bind(...)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(...) 
....


_bind_ and _WireIn_ are different in their second argument. _bind_ requires a function whereas WireIn requires an object. The function takes a TA and returns an MTB (a TB wrapped in a monad container). The object has an input port of type TA and an output port of type TB.

.Monad wiring code
[source,C#]
....
monadA.bind((a)=>(func<TA,Monad<TB>>)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(instanceB) 
....


In the monad case, the bind function returns a new monad object. 
In the ALA case, the WireIn function returns instanceB.
Therefore, in both cases you can now chain additional operators using fluent style:

.Monad wiring code
[source,C#]
....
monadA.bind(func<TA,Monad<TB>>).bind(...)
....


.ALA wiring code
[source,C#]
....
instanceA.WireIn(instanceB).WireIn(...)
....

In the monad version, we often want to specify the function to return a TB instead of a Monad containing a TB. That is what Select is for in C#. Select uses bind under the covers but does the wrapping of the TB into a monad for you:

.Monad wiring code
[source,C#]
....
monadA.Select(func<TA,TB>)
....

In the ALA case, we will usually use a prexisting domain abstraction to perform the operation. For example, we might use the domain abstraction OffsetAndScale. This allows code to generally be inside domain abstractions layer, and only configuration constants (that come directly from requirements) to be in the application layer. But to get closer to the same problem that monads solve, let's assume we have no domain abstraction that does what we need, and we really do want to specify the mapping function in the application layer right in amongst the wiring. In other words we want a domain abstraction that is configured with a lambda function. In this case we can invent a domain abstraction called Lambda which takes a lambda function when it is constructed: 

.ALA wiring code
[source,C#]
....
instanceA.WireIn(new Lambda<TA,TB>(funct<TA,TB>))
....


Just as _Select_ is a more specialized version of bind that changes the type, _Where_ is also a more specialized version that removes records from the stream. It requires a predicate function that returns a bool:

.Monad wiring code
[source,C#]
....
monadA.Where(funct<TA,bool>)
....

.ALA wiring code
[source,C#]
....
instanceA.WireIn(new Where<TA>(funct<TA,bool>))
....


You can see that the ALA syntax for solving this particular problems is now more verbose. It requires the additional use of WireIn and the _new_ keyword. The tradeoff for the extra words is versatility. We could consider using the less verbose Monad syntax for all ALA wiring. What would we lose if we did that:

For example:

.ALA wiring code
[source,C#]
....
    adc.WireIn(new LowPassFilter(10)).WireIn(new OffsetAndScale(0,0.5));
....


.consider monad style ALA wiring code
[source,C#]
....
    adc.LowPassFilter(10).OffsetAndScale(0,0.5);
....

To accomplish this syntax, we would have to provide methods with the same names as the domain abstractions. These methods would perform the new operation and then the wiring operation.

We would briefly consider defining these methods directly on the domain abstractions such as ADC, but that would pollute ADC with knowledge of LowPassFilter. Since there are many ways of wiring things, every abstraction would need methods for every other abstraction to which it could be wired. That would be ridiculous. 

Instead we might make every domain abstraction implement an _IWireable_ interface. I think this inerface would be empty. Then all the wiring methods would be extension methods on _IWireable_. They would all return an _IWireable_ ready for fluently calling the next wiring method. Now the code for ALA would look like:

[source,C#]
....
    (adc as IWireable).LowPassFilter(10).OffsetAndScale(0,0.5);
....

which is pretty much the same as the Monad code.


The methods would be fairly simple:

[source,C#]
....
static class LowPassFilterExtensonMethod
{
    static IWireable LowPassFilter(this IWireable instanceA, int strength)
    {
        return instanceA.WireIn(new LowPassFilter(strength));
    }
}    
....


Note that IWireable is kind of analogous to IEnumerable in the monad examples we have been looking at. We give it the more abstract name _IWireable_ because domain abstractions can have more than one output port, and we could be wiring any one of them, whereas monads generally only have one output such as IEnumerable.
////

In ALA we use the explicit WireIn and new operators for the following reasons:

* In ALA, Domain abstractions are generally at a slightly more specific level of abstraction than monad library functions (specific to the domain to support the construction of user stories). So, domain abstractions are written by the application developer much more frequently than new monads are written. They are extremely simple to write once the concept of ports is understood, because the ports make them zero coupled with one another and with the application layer above. The only difference from plain classes is that you have to know that input ports must use implemented interfaces from the programming paradigms layer, and output ports must be plain private fields of the types of these same interfaces. We don't want the extra burden of adding a corresponding extension method.

* In ALA we can choose between WireIn and WireTo depending on whether we want to chain instances of abstractions or do fanout wiring. Monad library functions alway return the next object in the chain, so only naturally wire up chains.

* The mental model of components with ports that you explicitly wire up is more versatile than the mental model of composing functions as a dataflow chain. Functions can be thought of as have multiple ports, for example the merge function can have two input streams, but the fluent syntax of combining monadic functions does not suit it.

* Composing monad functions is only a dataflow programming paradigm. In ALA many diverse programming paradigms can be used. The diverse programming paradigms represent different meanings of composition. For example, we can compose the UI. The code below puts a Button, TextBox and Grid inside a window.  
+
.ALA wiring code
[source,C#]
....
    window.WireTo(new Button().WireIn(...))
          .WireTo(new TextBox().WireIn(...))
          .WireTo(new Grid().WireIn(new DynamicDataSource().WireTo(...)));
....
+
The button can be further wired using an event driven programming paradigm. The Textbox can be further wired to its data using dataflow. The Grid can be wired using a dynamic dataflow programming paradigm to a dynamic data source, which could itself be wired using a schema programming paradigm.

* Deferred monads look like operations on data, but obscure the fact that they build a structure of objects for later execution. This is confusing until you get used to it. The _WireTo_ and _WireIn_ operators together with the _new_ operator make it explicit that you are building a structure of objects as a program that you can then set running.  

* Because domain abstractions can have multiple ports, _WireIn_ and _WireTo_ allows us to specify which port we want to wire when it could be ambiguous.

* Inherent in the requirements of a typical application is really a network of relationships. This network is often best represented by a diagram. Explicit WireIn and WireTo operators allow us to directly translate a diagram to code. Also, diagramming tool can automatically generate the wiring code containing using _WireTo_ and _new_.



=== Using monads in an ALA application
 
Although composing with objects is generally more versatile than composing with functions, if you already have a monad library containing functions such as SelectMany, Select, Where, Sort, Aggregate, etc, we would certainly want to make use of it in ALA applications. There would be no sense in reinventing that functionality as 2-port classes. You can use the monad library for some dataflow parts of the program.

In this section we discuss two methods to use monads within an ALA application: 

. The first method is to use IObservable as the interface for some of the ports of your domain abstractions. Then two instances of these domain abstractions can be wired with a reactive extension expression inbetween. Although n IEnumerabe version is possible, we will only show an example using the IObservable interface because that is more compatible with how ALA programming paradigms gnerally work (push by default). We will give examples for both static and dynamic type dataflows.

. The second method is to write a general purpose domain abstraction that can be configured with a monad expression. The domain abstraction has input and output ports using ALA's DataFlow interface.  We will do both an IEnumerable and an IObservable version of this domain abstraction.


==== Domain abstractions with IObservable ports

===== Statically typed 

The first way to use monads with ALA is to use the monad interface, such as IObservable, for the ports on some domain abstractions. For example, we could have a domain abstraction for a CSV file reader that has an output port of type IObservable<DataType>. Then we can have a domain abstraction called ObservableToSerial that has an input port of type IObservable. 

We can then wire there two end instances via some _.Where_ or _.Select_ functions inbetween using monad functions that already exist in the reactive extension library. Here is some example application code:

[source,C#]
....
class Program
{

    static void Main()
    {
        var outputer = <6>
        ((IObservable<DataType>)new CSVFileReaderWriter<DataType>() { FilePath = "DataFile1.txt" }) <1>
        .Select(x => new { Firstname = x.Name.SubWord(0), Number = x.Number+1 } ) <3>
        .Where(x => x.Number>48) <4>
        .WireInR<T>(new ObservableToSerial<T>(Console.Writeline)); <5>
    
        var program = new StartEvent().WireTo(outputer); <7>
        program.Run(); <8>
    }

    private class DataType <2>
    {
        public string Name { get; set; }
        public int Number { get; set; }
    }
}
....

<1> We start the chain by instantiating a CSVFileReaderWriter and providing it with a filepath. 

<2> We also give CSVFileReadWriter a type, DataType, which corresponds with the fields in the CSV file we are going to read. (This is not a dynamic CSV file, so we are going to do this program completely with compile-time type checking using type inference.)

The CSVFileReaderWriter domain abstraction can have multiple output ports of different types, but the one we are going to wire is an IObservable<DataType>. CSVFileReaderWriter implements this interface. To specify which port we are wiring we simply cast the CSVFileReaderWriter to IObservable<DataType>. It's a shame we had to have DataType appear twice in the program.

<3> We wire the CSVFileReaderWriter's IObservable port to a _Select_ function. Like a monad, _Select_ returns another IObservable, with a different type. The compiler can use type inference to generate this type. 

<4> We wire the output of Select to a _Where_ function. _Where_ returns yet another IObservable with a type using type inference.

<5> We wire the output of _Where_ to a new domain abstraction called ObservableToSerial. (The type inference doesn't work here, but we will fix that soon.)

<6> We store the ObservableToSerial in a local variable called outputer because we need to wire to it in another place. 

<7> outputer has an IEvent input port which is used to start the transfer. With IObervables, the data transfer is started from the destination end. We wire a StartEvent domain abstraction to the outputer. StartEvent has an IEvent output port and can be used to set a program running. We store the StartEvent in a variable called program.

<9) To start the program running we call program.Run(), which is a method in the StartEvent.

The line labelled 5 in the listing doesn't compile. It's what we would like to have written to get the type inferencing working starting from the CSVFileReaderWriter right through to the outputer. The reason it doesn't compile is that _new ObservableToSerial<T>_ needs a type to be specified for T. The WireInR<T> knows the type from its _this_ parameter. But you can't get the compiler to transfer that type to the second parameter of WireInR, the _new ObservableToSerial<T>_.

The solution is to use an extension method to do the WireInR and the _new ObservableToSerial<T>_. Here is a suitable extension method:

[source,C#]
....
public static ObservableToSerial<T> ToConsole<T>(this IObservable<T> observable) where T : class 
{ 
    var o = new ObservableToSerial<T>(Console.WriteLine); 
    observable.WireInR(o);
    return o; 
}
....

Using this extension method, here is the application again:


[source,C#]
....
    static void Application()
    {
        var outputer = 
        ((IObservable<DataType>)new CSVFileReaderWriter<DataType>() { FilePath = "DataFile1.txt" })
        .Select(x => new { Firstname = x.Name.SubWord(0), Number = x.Number + 1 })
        .Where(x => x.Number > 48)
        .ToConsole();

        var program = new StartEvent().WireTo(outputer);
        program.Run();
    }
}
....

Type inference now works all the way through the dataflow chain. We only had to specify the type of the data in the CSV file. 


===== Dynamically typed

This next example does the same functionaility as the previous example, that is demonstrating mixed use of domain abstractions with IObservable ports and reactive extension monads. However, this time it does not statically define the data type at compile-time. In other words, it makes no assumptions about the data schema in the CSV file. Instead, it determines everything at run-time. If any code tries to access specific data that doesn't exist or has the wrong type, run-time exceptions are thrown rather than compiler errors.

Since the CSV file is now considered dynamic, it has two header lines, one to name the columns and one that defines the types of the columns. Knowledge about these header lines is contained in the CSVFileReaderWriter abstraction. The first half of the code writes some data to the CSV file to ensure header lines are created.


[source,C#]
....
static void Application()
{
    var csvrw = new CSVFileReaderWriter() { FilePath = "DataFile2.txt" }; <1>
    
    // First write some data to the file
    
    IObserverPush<ExpandoObject> writer = csvrw; // writer port <2>
    writer.OnStart(); <3>

    dynamic eo = new ExpandoObject(); <4>
    eo.Number = 47; <5>
    eo.Name = "Jack Up";
    writer.OnNext(eo); <6>

    eo.Number = 48; <7>
    eo.Name = "Wynn Takeall";
    writer.OnNext(eo);

    eo.Number = 49;
    eo.Name = "Rich Busted";
    writer.OnNext(eo);

    writer.OnCompleted(); <8>

    // Now wire the output port of the CSVFileReaderWriter via a Select and a Where to an outputter.

    var outputer = new ObservableToSerial<ExpandoObject>(Console.WriteLine); <9><10>

    ((IObservable<dynamic>)csvrw)  <11>
        .Select(x => new { Firstname = ((string)x.Name).SubWord(0), Number = x.Number + 1 })
        .Where(x => x.Number > 48)
        .WireInR(outputer);

    var program = new StartEvent().WireTo(outputer); <12>
    program.Run(); <13>
}
....

<1> First we instantiate a CSVFileReaderWriter domain abstraction. Notice how this abstraction is not generic like we had before. Instead its ports use the ExpandoObject class.

<2> Get a reference to the input port of the CSVFileReaderWriter. This input port has type IObserverPush<ExpandoObject>. The IObserverPush programming paradigm is like IDataFlow, but can handle batches of data:
+
[source,C#]
....
interface IObserverPush<T> : IObserver<T>
{
    void OnStart();
}
....
+
As you can see it is a standalone version of IObserver. It doesn't need a corrsposnding IObservable interface. It operates by itself. It is explained in detail later.


<3> Calling OnStart on the input port causes CSVFileReaderWriter to create a new file.

<4> Create a temporary ExpandoObject. This is a usefull class when using dynamic typing which can have properties added at run-time.

<5> Add fields to the ExpandoObject.

<6> Give the ExpandoObject to the input port of the CSVFileReaderWriter, which will write the data to the CSV file.

<7> Write more records in the same way.

<8> Complete writing the CSV file.

<9> Instantiate an ObservableToSerial for the end of the chain. ObservableToSerial has an IEvent input port called trigger that is used each time we want the program to go (by subscribing to its data source). 

<10> Configure the ObservableToSerial to output to the console.

<11> Wire the chain up starting from the CSVFileReaderWriter through to the ObservableToSerial via two LINQ operators. IObservable ports are used the whole way. The IObservable output port of the CSVFileReaderWriter is selected by the cast.
+
One unusual thing you may notice about this ALA program is the use of WireInR instead of WireIn that we would normally use to wire things in a chain. A.WireInR(new B()) actually wires in the reverse direction from normal, that is from B to A. You use it like you would use WireIn, in the same direction as the dataflow, but it actually wires in the opposite direction. This is because IObservable, the programming paradigm interface being used, must be wired in the opposite direction as the dataflow, like a _pull_ interface. The A object implements IObservable and the B object has a field of type IObservable. So the wiring must go in the reverse direction of the data flow. WireInR is implemented simply as WireInR(this object A, object B) {WireIn(B, A);}  

<12> Wire an instance of a StartEvent to the ObservableToSerial _Trigger_ input port. 

<13> Make the program run by telling the StartEvent to output an event.




==== Domain abstraction configured with monads  

This is the second method of using monads in an ALA application.

It uses a domain abstraction that can be configured with a monad expression. This domain abstraction uses your normal ALA dataflow programming paradigm forits its input and output ports. We will do two versions, one configured with an IEnumerable chain and one configured with an IObservable chain.

===== Configuring with IEnumerable monads


Let's call the domain abstraction EnumerableQuery. You configure an instance of EnumerableQuery with a LINQ expression.  

Here is an example program using EnumerableQuery. EnumerableQuery uses IDataFlow as the programming paradigm for its ports. We chain up three of them and configure them all with a similar query:

[source,C#]
....
static void Application()
{
    var proxySource1 = new EnumerableProxySource<int>(); <1>
    var query1 = proxySource1.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 1); <2>
    var proxySource2 = new EnumerableProxySource<int>(); <1>
    var query2 = proxySource2.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 2); <2>
    var proxySource3 = new EnumerableProxySource<int>(); <1>
    var query3 = proxySource3.SelectMany(x => new[] { x * 10 + 1, x * 10 + 2, x * 10 + 3 }).Select(x => x + 3); <2>

    var userStory = new StartEvent(); <3>
    userStory
    .WireIn(new ValueToDataFlow<int>(0)) <4>
    .WireIn(new EnumerableQuery<int, int>(proxySource1, query1) { instanceName = "Query1" }) <5>
    .WireIn(new EnumerableQuery<int, int>(proxySource2, query2) { instanceName = "Query2" }) <6>
    .WireIn(new EnumerableQuery<int, int>(proxySource3, query3) { instanceName = "Query3" })
    .WireIn(new DataFlowToSerial<int>(Console.Write)); <7>

    userStory.Run(); <8>
}
....

<1> To build a LINQ expression, you need to start with a source that implements IEnumerable. Since we don't have an actual source, we will use a proxy for the source. That's what the EnumerableProxySource is.

<2> An example LINQ expression consisting of a SelectMany and a Select.

<3> Instantiate a StartEvent domain abstraction, which we will use to tell the user story to run.

<4> Instantaite a domain abstraction that represents a simple scalar value and will output that value to its output IDataFlow port when told to by its IEvent input port.

<5> Wire in the first of the three EnumerableQuery domain abstractions. EnumerbaleQuery has an input IDataFlow port and an output IDataFlow port. Configure it with the LINQ expression. To do that we give it both the proxySource object and the LINQ expression object. EnumerableQuery will receive data pushed to its input port, apply the LINQ expression to it, and push the result out its output port.

<6> We chain up three of the EnumberableQuerys to demonstrate normal ALA wiring up of this abstraction. 

<7> We wire the final output to the console using an instance of a DataFlowToSerial domain abstraction configured to give its serial stream to the Console.

<8> Tell the user story to run.

Here is the output of the program:

image::ConsoleOutputListMonad.png[ConsoleOutputListMonad.png, title="Output of demo code using EnumerableQuery domain abstraction", link=Console output result-01.png]

The initial value of zero expands to 27 numbers because of the SelectMany in each of the LINQ expressions.

Internally, what EnumerableQuery does is every time an input data arrives, it executes a foreach on the query. When the query asks for for data from the proxySource, the proxySource returns the data that came into the input port. 

Here is the EnumerableQuery domain abstraction: 

[source,C#]
....
class EnumerableQuery<T, U> : IDataFlow<T>  // input port <1>
{
    private readonly EnumerableProxySource<T> proxySource;
    private readonly IEnumerable<U> query;
    
    public EnumerableQuery(EnumerableProxySource<T> proxySource, IEnumerable<U> query) { this.proxySource = proxySource; this.query = query; proxySource.Enumerable = getIEnumerableForInputData(); } <3>

    private IDataFlow<U> output;  // output port <2>

    private T inputData; 

    private IEnumerable<T> getIEnumerableForInputData() <4>
    {
        yield return inputData;
    }


    void IDataFlow<T>.Push(T data) <5>
    {
        this.inputData = data;
        foreach (var x in query) output?.Push(x);
    }
}
....

<1> The input port is an IDataFlow<T>

<2> The output port is an IDataFlow<T>

<3> The constructor takes a LINQ expression (both its proxySource object and the query itself) and saves them to local variables. The constructor also sets up proxySource to get its data from an IEnumerable.

<4> The IEnumerable is returned by getIEnumerableForInputData. This IEnumerable simply returns the data that has come in on the input port. The IEnumerable is implemented with a method that contains a yield return.

<5> The implementation of the input port is what drives the domain abstraction. It first saves the incoming data so that the query can use it as its source, then enumerates the LINQ query. The results are given to the output port.

The code above can be found in a working example program on Github in the IEnumerableMonad repository here: https://github.com/johnspray74[https://github.com/johnspray74]




===== Configuring with IObservable monads

In the previous example, we created a domain abstraction that can be configured with a LINQ query. In this next example, we create a domain abstraction that can be configured using reactive extensions.

When all else is equal, I prefer reactive extensions over LINQ because it can do asynchronous and synchronous. 

We could have done this example using IDataFlow ports just as we did in the previous example. However, the IObserverPush programming paradigm that we briefly introduced earlier is more appropriate. IDataflow handles an open-ended stream of data, whereas IObserverPush can handle open-ended batches of data. 

Here is a user story example of using this domain abstraction. 


[source,C#]
....
    static void Application()
    {
        var subject1 = new Subject<int>(); <1>
        var query1 = subject1.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 1); <2>
        var subject2 = new Subject<int>();
        var query2 = subject2.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 2);
        var subject3 = new Subject<int>();
        var query3 = subject3.SelectMany(MutiplyBy10AndAdd1Then2Then3).Select(x => x + 3);

        var userStory = new StartEvent(); <3>
        userStory
        .WireIn(new ValueToObserverPush<int>(0)) <4>
        .WireIn(new ObservableQuery<int, int>(subject1, query1)) <5>
        .WireIn(new ObservableQuery<int, int>(subject2, query2))
        .WireIn(new ObservableQuery<int, int>(subject3, query3))
        .WireIn(new ObserverPushToSerial<int>(Console.Write)); <6>

        userStory.Run(); <7>
    }


    static IObservable<int> MutiplyBy10AndAdd1Then2Then3(int x) <8>
    {
        return Observable.Create<int>(observer =>
        {
            observer.OnNext(x * 10 + 1);
            observer.OnNext(x * 10 + 2);
            observer.OnNext(x * 10 + 3);
            observer.OnCompleted();
            return Disposable.Empty;
        });
    }
....

<1> First we need a proxy source object that implements IObservable on which to build our reactive extensions expression. The RX library provides a suitable class that we can use for this called Subject. 

<2> Create the RX expression consisting of a SelectMany and a Select.

<3> The user story will consist of three ObServableQuerys wired up in a chain. Data transfers are intitaited at the source. So we instantiate a StartEvent domain abstraction to give us a way of starting (or restarting) the dataflow.

<4> The StartEvent instance is wired to the start port of an instance of ValueToObserverPush using an IEvent programming paradigm. ValueToObserverPush is a simple domain abstraction that is configured with a single value. It has an IObserverPush output, and will output its value when it gets a signal on its start port.

<5> The ValueToObserverPush is wired to an ObservableQuery using the IObserverPush programming paradigm. ObservableQuery is configured with an RX expression. Both the subject and the expression itself must be passed in. 

<6> After the three ObservableQuerys are wired, the output is wired to an instance of ObServerPushToSerial, where it is converted to text to be displayed on the Console.

<7> Now that the user story is all wired up, we can run it. It can be run more than once.

<8> The function passed to the SelectMany is implemented using the Observable.Create method, which is a convenient way to do it for our purposes here.



Here is the code for ObServableQuery:

[source,C#]
....
class ObservableQuery<T, U> : IObserverPush<T>  // input port <1>
{
    private readonly Subject<T> queryFrontEnd;
    private readonly IObservable<U> query;
    public ObservableQuery(Subject<T> queryFrontEnd, IObservable<U> query) { this.queryFrontEnd = queryFrontEnd; this.query = query; } <3>

    private IObserverPush<U> output;  // output port <2>


    private IDisposable subscription = null;

    void IObserverPush<T>.OnStart() <4>
    {
        output.OnStart(); <5>
        subscription?.Dispose(); <7>
        subscription = query.Subscribe( <6>
            (data) => output.OnNext(data),     
            (ex) => { output.OnError(ex); terminated = true; }
            () => output.OnCompleted());
    }

    void IObserver<T>.OnNext(T data) <8>
    {
        queryFrontEnd.OnNext(data);
    }

    void IObserver<T>.OnError(Exception ex) <9>
    {
        queryFronEnd output.OnError(ex);
    }

    void IObserver<T>.OnCompleted() <10>
    {
        queryFronEnd.OnCompleted();
    }

}
....

<1> The input port is an IObserverPush

<2> The output port is an IObserverPush

<3> The constructor configures the domain abstraction with an IObservable expression. Both the front end Subject object and the RX expression object itself are passed in. These are saved as local variables.

<4> An OnStart call prepares for a new batch of data.

<5> The OnStart signal is propagated to the output port so it goes right through the chain to prepare the entire chain for the data sequence.

<6> The query that we were configured with is subscribed to.  This does not cause data to flow from the RX expression yet. Outputs from the RX expression are routed directly to the domain abstraction's output port. The subscribe must be done here rather than in the constructor because if OnStart is called again for a subsequent batch of data, Subscribing needs to be done again to 'reset' the RX expression if it had completed.

<7> If the query had previously been subscribed to, it probably had an OnCompleted or OnError which would prevent it working until it is subscribed to again. But we don't want to subscribe to it twice, so we first unsubscribe.

<8> When data arrives at the input port, it is given to the query via the Subject object.

<9> Any exception coming in from the input is passed through to the output via the query. If the query has already generated an exception it will likely discard it.

<10> The OnCompleted from the input is also passed through to the output via the query.

That completes our examples of how you can use monads within an ALA application.


This has been a long section contrasting monads and ALA. In summary ALA solves the same problem that monads solve, that of composing more abstract computational units to create more specific computational units. But where monads are about composing functions, ALA composes objects. While pure functions are _mathematically_ simpler than objects, many _computations_ are more naturally expressed using state. That's why ALA is object oriented. In other words, sometimes objects just make better abstractions than functions. 

But if you already have an existing monad library, it makes sense to use it within an ALA application.  


==== IObserverPush interface

We used the programming paradigm interface _IObserverPush_ a couple of times in the examples previously.

Here it is again:

[source,C#]
....
interface IObserverPush<T> : IObserver<T>
{
    void OnStart();
}
....

Nothice that it is the IObserver interface with one added method: _OnStart_.

Now we can explain the reasoning behind this programming paradigm, and compare it with the IObserver/IObservable pair.

IObserverPush<T> is similar to IDataFlow<T>, but with the ability to handle batched data and to propagate errors down the data flow.

This interface is the 'pure push' version of the IObservable/IObserver pair. Remember that while IObserver is a push style interface, IObservable is not. The Subscribe method of IObservable is more of a pull style that usually gets the flow of data started. So its hard to use IObservable asynchronously or over a network.

Data transfers using IObserver are usually triggered from the destination end. It does so via IObservable. For example, ObservableToSerial in the previous section must subscribe to 'pull' the data. So Subscribe does two things: 1) it wires the IObserver interface in the opposite direction, and 2) it (usually) starts the data transfer. The source will then push the data back using the IObserver interface.

Sometimes Subscribe only wires the IObserver, and thereafter the source initiates the data transfer whenever it likes. This is called a hot observable. OnCompleted and OnError cannot really be used with hot observables because they usually stop everything. If the source does use OnCompleted or OnError, then the source must really send the data in response to the Subscribe. If OnCompleted or OnError are called, the detsination must unsubscribe and resubscribe to get the next batch of data. The Subscribe method, therefore, is not just used for wiring - it is usually used to start the transfer.  

I find this behaviour of IObservable/IObserver doesn't suit permanently wired user stories like we do in ALA. Besides, IObservable and IObserver seems to be a weird mix of 'push' and 'pull' styles. What I want is a purely push programming paradigm, that can be permanently wired, can batch the data, and can propagate errors down the dataflow chain. 

The other problem with the IObservable interface is that the destination wires itself to the source. The destination of a communication should never wire itself to the source if its in the same layer. It's fine if the source is in a lower (more abstract) layer. But general wiring up within an abstraction layer should always be done by a higher layer.

So to fix all these problems with the IObservable/IObserver pair, I use IObserverPush as an ALA programming paradigm. 

The OnStart method effectively takes the place of the Subscribe method in that it will allow data to flow again after an OnCompleted or OnError. In other words, we can permanently wire IObseverPush, and it will work for ongoing batches of data even after OnCompleted or OnError occurs in each batch. The wiring aspect of the Subscribe method is not needed. In ALA the layer above will wire up the IObserverPush interface. The IObservable interface is therefore completely redundant.

In summary, IObserverPush

* is used instead of IObserver/IObservable
* is a pure push programming paradigm
* like IObserver, goes in the direction of the dataflow
* requires the layer aobve to wire it up
* is designed to be permanently wired, but can still handle batches of data using OnCompleted, or OnErrors.




=== Encapsulation, polymorphism and inheritance

ALA replaces encapsulation with abstraction.

ALA removes associations and inheritance and instead uses composition (provided the composition uses a more abstract abstraction).

ALA replaces polymorphism with zero coupling.

The first two we know as fundamental principles in ALA, and have already been discussed in chapter three.

The third statement requires some elaboration.

In the meme pool of software engineering we have at least five memes for the one concept. These are polymorphism, information hiding, protected variations, dependency inversion principle and open closed principle. 

I shall argue in their individual discussion later that none of them is a principle.
All five are just a simple pattern. The motivation is that if you have code that couples knowledge of different 'things', you extract the knowledge into their own modules. Now when the 'thing' changes, you can change it or swap it out without affecting the client module. Switch statements were a smell in traditional code that different things were mixed.

You may already have separated out one implementation of a thing. So now your client code talks to a concrete thing. The conical example is a particular database. But now you need to use a different thing. Instead of putting in a switch statement everywhere to talk to different databases, you use the polymorphism / information hiding / protected variations / dependency inversion / open closed pattern. 

The pattern itself consists of an interface. That's it. All those memes all trying to tell you to use an interface. Oh, and another one - if you have heard the phrase "program to interfaces".

On top of that, single responsibility also pretty much forces the use of an interface. Referring to a peer concrete object is always a second resposibility.

ALA does not use this pattern.

To understand why, lets call the client module B and the modules that implement the interface, C1, C2 etc. B doesn't know which of the C modules it is talking to at run-time. If we want it to be C2 for a particular application, we have higher level code that injects C2 into B.   

It's important that we realize that in this pattern the interface is owned by B. It describes what B _requires_. It is cohesive with B. It is part of abstraction B. This still the case even if the interface is split out into a module or even a different compilation unit of its own. 

Therefore C1, C2 etc have a dependency on B. They implement B's requirements. They collaborate with it. The dependency in the design is just inverted from what it might have been. C1 & C2 are coupled with B. 

So this is illegal in ALA (assuming B and C1, C2 etc are all at a similar level of abstraction, which they likely are. That's why for ALA I have stated that the equivalent is zero coupling. ALA replaces the dependency with nothing at all between A and C1, C2 etc.

We have talked about how ALA still works in Chapters three and four. It does still use an interface but it is not owned by B (or C1 or C2). It is at a much more abstract level, the level of a programming paradigm. For example if abstractions B, C1 and C2 know about the event-driven programming paradigm, then instances of them may be wired together.

ALA further requires that the higher level code that does the injecting is also an abstraction. It is just one that is specific to a user story. Let's call it A. A needs to cohesively do all the wirings of all the instances of domain abstractions to implement a whole user story in a cohesive way.

These five memes don't have anything to say about that. They are redundant with respect to ALA. By just using ALA the job is done in a better way.

The SRP, DIP amd OCP are discussed further in the sections below.


=== SOLID Principles

The SOLID principles collated by Robert Martin are confusing. Their one or two sentence descriptions don't describe them very well, so you have to go a read a lot to understand them. Unfortunately they are collected up into the catchy acrostic "SOLID" with a meaning that is undeserved. This has made the collection more well known than it deserves, as we shall explain.  


====  Single Responsibility Principle

The SRP strangly worded differently from it's name. It states that a module (function, class or package) should have only one reason to change. I find this s strange formulation of the name.


By using abstractions, the SRP is complied with in terms of reasons to change. However, some abstractions arguably have more than responsibility. I often use the question "What do you know about?" to an abstraction. It is always one thing it knows about, but it may have multiple responsibilites for that thing.

Examples:

* An ADC driver (analog to digital converter hardware) knows all about a particular ADC chip. It has the responsibilies of initializing it and getting the readings from it. It changes only if the HW chip changes.

* A protocol abstraction knows about a protocol. It has the responsibility to send data using the protocol and to receive it. It changes only if the protocol changes.

* A file format abstraction, such as CSVFileReaderWriter knows about a file format. It has the responsibility to both read it and write it. It changes if the file format changes.

My advice is that the SRP is made redundant by thinking in terms of abstractions, which accomplishes the intention of the SRP better. 


====  Open Closed Principle

Talk about confusing. Firstly Betrand Meyer coins the phrase, which is impossible to understand without further reading. On further reading you find that Robert Martin has a completely different principle by exactly the same name. Then he has two verions of that, one for modules in the same compilation unit and one for when the client is in a different compilation unit and is already published. By the way, being already published was also the context of Meyers OCP.

None of them are principles - they would need to be used in the right conext at best. They have associated patterns anyway (or anti-patterns relative to ALA).

===== Martins version

The sources of knowledge about the meanings of these memes are:

Craig Larman
Kevlin Henny





==== Liskov Substitution Principle

TBD

====  Interface segregation principle

TBD

==== Dependency Inversion Principle

The DIP is stated:

A.   High-level modules should not import anything from low-level modules. Both should depend on abstractions (e.g., interfaces).

B.   Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions.

This sounds the same as the ALA fundamental rule that all dependencies must be on abstractions that are more abstract. 

The Dependency Inversion Principle, and its associated pattern goes some way toward ALA in one respect and far too far in another respect.

Firstly ALA uses the word abstraction for the unit of code. The DIP really only uses the word abstraction as a synonym for interface – e.g. abstract class. The essence of the difference is that when ALA allows a dependency on an abstraction, it means more abstract than what DIP does. In both cases an interface is introduced. But in DIP, that interface is owned by the first module, and expresses what that module requires, so it’s highly coupled with the module, not really more abstract than it. ALA’s interfaces don’t belong to domain abstractions but go all by themselves in a lower layer. They are so much more abstract that we call them programming paradigms.

To be more precise, the DIP (as its name suggests) reverses a dependency used for communication between two classes, but ALA completely removes it. But the ALA wiring pattern also adds other dependencies. It adds a dependency on each module from a higher layer for dependency injection and it adds dependencies from each module to a programming paradigm interface in a lower layer for ports.

Let’s start with conventional code where B talks to C. It uses a dependency:

B ----> C

DIP does this:

B < --- C

ALA does this:

B ---- > I

C ---- > I

Those who know the DIP might immediately say “no the DIP has a version where the interface is put into its own separate package like that as well”. The DIP allows for the interface to be placed in a different compilation package than B. Lets call it IB. Theoretically this allows C (the implementer of IB) to be reused without B. However, this is a superficial change from the point of view of abstraction level. Simply moving IB doesn't make it more abstract. That interface is still owned by B - it represents what B requires. So as it still just a part of the B abstraction.

With DIP, you get to choose a specific implementation, C, to satisfy what B requires. In ALA you get a port with a programming paradigm that will take any domain abstraction instance with a compatible port of the same programming paradigm. 

Both DIP and ALA require dependency injection. So let’s draw the injection dependencies as well:

Conventional code version:

B ----> C

DIP version:

A ---> B

A ---> C

C <--- B

ALA version

A ----> B

A ----> C

B ---- > I

C ---- > I

DIP effectively moves the interface from C to B. B gains an interface that does a similar job to C. C then implements it and B uses it.  

Because the new interface is owned by B, it may be different from the one in C because now it’s about what B requires rather than what C provides.

Because of this, it might often be an adapter that implements the interface, and then the adapter uses the original interface of C.

TBD

Think of B as being some business logic and C being the database. B no longer depends directly on a specific database. But the databases do now depend on B. To avoid changing the databases, you would use adapters. The pattern is designed to increase the reuse potential of B, the business logic, because different databases can be plugged into it. But it likely decreases the reuse potential of the things around the business logic unless adapters are used. The DIPs application is primarily around making business logic reusable, and leads to hexagonal architecture, which has the business logic in the middle, and all the peripherals are plugged into its interfaces.

 

 

Returning to the sentence in the DIP that states: “High-level modules should not import anything from low-level modules.”.

 

The 2nd  ALA dependency rule is in a way less constraining than the DIP here. If a low-level module is much more abstract, ALA allows to keep the dependency. This is what allows the dependencies between the application user stories and the domain abstractions. It comes down to what is meant by high-level and low-level in Martin’s writings. I think by ‘low-level’ he refers to what would have been depended on in conventional code. Things like the database, middleware for communications, and frameworks.(e.g. for supporting asynchronous events.)

 

In ALA, yes you would wire the specific database adapter and the specific middleware adapter (and the specific UI), but you wouldn’t wire in the framework. It doesn’t matter that the abstraction depended on is low level. I want to commit to only one implementation of the framework. It would be silly to have to use ports on every single domain abstraction so I can wire in a framework of my choice, and have to wire it to every single domain abstraction, when I want to commit to using one. This becomes more obvious as you get to even lower levels such as math libraries. I don’t need to allow for swapping out the math library implementation. So ALA allows dependencies on more abstract abstraction even if they are low-level modules. In fairness, Martin probably doesn’t mean to include all low-level modules in the DIP, just certain ones that should be decoupled.


===  Dependency injection pattern

By now we know that ALA uses dependency injection. It uses it for wiring up all instances or all domain abstractions.

We have favoured using reflection to do the injection in our examples, but that is just a syntactic shortcut that allows domain abstractions to have many ports without also having many setters. It also allowed us to keep the ports private from direct access by the application layer. It allows ports to be implemented very simply, without the need for setters at all. It allows some other interesting things to be done. For example, after an instances port has been wired, there may events in the interface of the port that need internally wiring to event handler methods. The wireTo method can look for and call a method in the instance to do this immediately after wiring.

ALA always uses explicit wiring. This is one of the most important aspects of ALA. It's usually in the form of a diagram, because the wiring is usually an arbitrary graph. ALA never does dependency with automatic wiring. Having a dependency injection container means that the wiring itself is implicit in the interface types. If one module requires an interface, and the container has a module that implements it, that means these two modules get wired together. This type of implicit wiring is indirect and obfuscated and illegal in ALA. 

In ALA, abstraction pairs don't have their own interfaces for their instances to communicate. So we don't have the situation where class A has a dependency on class B, and so an object of class B (or one of its subclasses) is injected into class A. Similarly, we wouldn't have the situation where class A requires an interface that is implemented by class B.

In ALA the interfaces must be programming paradigm interfaces, which are a whole abstraction layer more abstract. So we need to be thinking that if class A accepts or implements a certain programming paradigm interface, there could be any number of other abstraction instances that could be wired to it. Furthermore, we could build arbitrarily large compositions. Some abstractions will have some ports that don't need to be wired to anything. So it doesn't really make sense to call what we are injecting 'dependencies'. We just think of it as wiring things up. You wouldn't describe what an electronics engineer does as dependency injecting components into each other.

In ALA, the explicit wiring should not be XML or JSON. I do not consider these readable programming languages. They are data languages. 

Usually user stories contain a graph structure of relationships. So the wiring should be a diagram to best show that structure. 

However, if the graph is mostly a tree structure (with relatively few cross connections), then it may still make sense to avoid the weight of a diagramming tool, and represent the wiring in text form. But in this case I still much prefer the readability of code written in a programming language than XML or JSON. An argument can be made for the declarative nature of say XAML and that UI designers could learn this declarative language more easily than a programming language. But I would maintain that a the subset of the programming language needed to the equivalent of XML is declarative style. That's what most of the wiring examples in this website are: declarative composition.

Besides, its not just about UI. For a given user story there will likely be UI, business logic, data transformations, and data storage. These should all be expressed togther cohesively. They should all be composed inside one abstraction. To handle the sometimes non-trivial configuration of the abstraction instances, normal code is sometimes needed, for example for lambda expressions or delegates. If we have a UI designer on the team, great, just teach him the subset of domain abstractions that are used for the UI, how to configure them, and how to compose them. Languages like XAML are not particularly easy just because they are declarative.





===  Physical boundaries

I was listening to a talk by Eric Evans where he said that Microservices works because it provides boundaries that are harder to cross. We have been trying to build logical boundaries for 60 years, he said, and failed. So now we use tools like Docker that force us to use say REST style interfaces in oder to have physical boundaries. I have also heard it suggested that using multiple MCUs in an embedded system is a good thing because it provides physical boundaries for our software components. And I think, really? Is that the only way we can be create a logical boundary? I can tell you that multiple MCUs for this reason is not a good idea if only because all those MCUs will need updating, and the mechanisms and infrastructure needed to do that make it not worth it. Unless there is a good reason, such as to make different parts of your code independently deployable, the extra infrastructure required for physical boundaries that are just logical boundaries is not necessary. Furthermore, physical boundaries, like modules do not necessarily make good abstractions. The only boundary that works at design-time is a good abstraction. So ALA achieves it's design-time boundaries by using abstractions.

===  Test Driven Development

It is said that TDD's main advantage is not so much the testing, but the improvement in the design. In other words, making modules independently testable makes better abstractions. This is probably true, but in my experience, TDD doesn't create good abstractions nearly as well as pursuing that goal directly. The architecture resulting from TDD is better but still not great.


===  Observer pattern

TBD




===  Layer patterns

==== MVC

TBD

==== Application, Services, Drivers, Hardware

TBD

===  Factory method pattern

The Factory Method pattern in both the GOF book and in online examples has multiple variations. The only thing they seem to have in common is that the client doesn't use "new ConcreteProduct()". It just wants an object that implements an interface, IProduct. For any reason it doesn't want to be the one who will decides at design-time what that concrete product will be. 

Here are some of the variations. 

* Several ConcreteCreators exists to encapsulate knowledge of how to use the ConcreteProduct constructor which has many parameters, in a consistent way to make a valid ConcreteProduct. The common example is different named pizzas or sandwiches. 

* The Client finds out at run-time what ConcreteProduct is needed (usually a string name). We want to move the switch statement out of the client and into a Creator class.)

* The client knows when the objects are needed, but needs to be more stable. Which product is needed changes more often (although still known at design-time). So it goes into a class that changes. 

In all cases we end up with two objects wired together through the IProduct interface. These two objects we will refer to as the Client and the ConcreteProduct (from the pattern terminology). To get them wired using the Factory Method pattern requires the use of a FactoryMethod. The FactoryMethod typically goes in an abstract class called ICreator, which may do the creating itself, or maybe overridden by one or more ConcreteCreators.

In the context of abstraction layers, ALA gives more insight into the FactoryMethods pattern. Remeber we expect lower layers to more stable. The IProduct and ICreator interfaces are in the ProgrammingParadigms layer (lowest layer). The Client and all the different ConcreteProducts are in the DomainAbstractions layer (middle layer). The ConcreteCreator is in the Application layer and wires one of the ConcreteProducts to the client. So now when we want to change the ConcreteProduct, only the ConcreteCreator in the application layer has to change.

But in ALA we typically accomplish that in a far simpler way. We commonly let the application code instantiate the right concrete class (that implements the interface, IProduct), and wire it to the Client object using the WireTo() method. This is nothing more than static wiring, but can only work when the required ConcreteProduct is known at design-time.


==== case 1

Now to the case in ALA where we have a client that needs a concrete product creating later than design-time, that is at run-time. Such a client is the Multiple Abstraction. It's job is to make many instances of a Domain Abstraction. But it is an abstraction so can be used to make instances of any object. They don't even have to implement a specific interface such as IProduct, because Multiple doesn't interact with these instances itself.

==== case 2

Let's say you have a Table domain abstraction that stores a table of data. In your application, you want to instantiate many Tables. Now lets suppose that we want these Table instances to persist their data. A database must be attached via an IPersistance interface. We don't want the Table class to know about concrete Databases. We want the application layer at the top to do that. But we don't want the application layer to have to wire the database to every instance that requires an IPersistance. We want the Application to be able to just use a Table as if it is a self-contained abstraction. We want the Table instances to take care of themselves for Persistence. So we make a Peristence abstraction in the Programming paradigms layer. The concept of Persistence is at the right abstraction level to go in this layer. The Table class can use this persistence abstraction through a FactoryMethod. A variable in the Persistence abstraction stores the IPeristence object. The application instantiates which database it wants to use and passes it to the Peristence abstraction.


=== Decorator pattern

TBD

===  Bridge pattern 

TBD


===  Architecture styles

I am not an expert at these so called 'Architectural styles'. Any feedback about the accuracy of the following comparisons would be appreciated.


==== Components and connectors

David Garlan and Mary Shaw in their paper titled "An Introduction to Software Architecture" 1994 use components and connectors as a framework for viewing architectural styles. Depending on the style, the connectors can be a procedure call, event broadcast, database query, or pipe (which we call dataflow).

*Similarities*

ALA follows this idea closely. 


*Differences*

In ALA we call the styles programming paradigms, and it is emphasised that multiple programming paradigms can be used in the one user story. The reason not to call them 'styles' in ALA is that the word style tends to imply using a single style throughout the program.

In ALA 'components' becomes 'abstractions' and 'connectors' becomes 'ports and wirings'. This change in terminology is to emphasis that the wiring is distinct from the abstractions themselves. The term components and connectors can (albeit not necessarily)) refer to an effectively monolithic system that is just separated into pieces and the pieces connected back together in a fixed rigid arrangement. This is especially true if the design methodology is decomposition of the system into elements and their relations. Such a system is loosely coupled at best. In ALA you can't do that. Systems must be composed of instances of abstractions wired together by a higher layer abstraction that directs the wiring. Abstractions are necessarily zero-coupled with one another. They use ports that have the types of a small number of programming paradigms so that instances of them can be composed in (generally) an infinite variety of ways. The style where components being filters and connectors being pipes works this way. 

I suspect that most components and connector systems use interfaces that are specific to the components. 

Examples using the UML component diagram, even though it uses the term ports, show interfaces that rigidly couple their components to one another, for example, interfaces with names such as CustomerLookup. This would mean that only components that are implementations of that specific interface could be substituted. Usually there appears to be only one, making the components effectively just modules. In UML, components appear to be just containers. They are the first level of decomposition of a system, and themselves just contain connected classes. This type of architecture is incompatible with ALA.   



==== Component Based Software Engineering

// TBD, some of this may be repeated

ALA uses many of the same methods found in component based engineering or the Components and Connector architectural style.


===== Similarities

* Components are Abstractions.

* Reusable software artefacts.

* Connection ports for I/O.

* Composability

* Both instantiate components, specialize them by configuration, and compose them together to make a specific system.

* ALA's 3rd layer has interfaces used to wire abstractions in the 2nd layer, so at a lower level (more abstract) level. They represent something more like programming paradigms. The equivalent pattern in components engineering is "Abstract Interactions".  

* The architecture itself is composed of a generic part and a specific part. The general part is the ALA reference architecture itself and the components or the connectors architectural style. The specific part is the wiring diagram of the full system.

===== Differences

* Component based engineering technologies such as CORBA primarily solve for platform and language interoperability in distributed system whereas ALA brings some of the resulting concepts and properties to everyday small-scale, non distributed development as well, where the only separation is logical.

* In ALA there is perhaps more particular emphasis on making components clearly more abstract than the systems they are used in, and making the interfaces clearly more abstract than the components. The components are pushed down a layer and the interfaces down to a layer below that. Then all dependencies must be strictly downwards in these layers. In component based engineering, this structure is not necessarily enforced. If the components are just a decomposition of the system, then the system, components and interfaces may all be at the same level of abstraction, making the system as a whole complex.

* ALA depends on the 'abstractness property' of components to get logical separation, and so calls them 'Abstractions' and not components to help them retain that property. Even if there will only be one use and one instance, it is still called an abstraction. This keeps them zero coupled and not collaborating with other abstractions they will be wired to.

* ALA layers are knowledge dependency layers.  Components may still be arranged in layers according to run-time dependencies, such as communication stacks. In ALA run-time dependencies are always implemented as explicit wiring inside another higher layer component.

* ALA's top layer must be a straight representation of the requirements, whereas components may tend to be decomposed pieces of the system.

* ALA's 2nd layer of components are designed for expressiveness of user stories or requirements, and provide DSL-like properties. ALA puts emphasis on the 2nd layer of components having the scope of a domain as the means of explicitly controlling the expressiveness of the pallet of components.

* ALA is not fractal. In ALA the components of components are abstractions that become more abstract and thus ubiquitous and reusable. ALA therefore uses abstraction layers rather than hierarchies.

* ALA forces decisions about which abstraction layers the software artefacts go into, and then controls knowledge (semantic) dependencies accordingly.

* ALA tries to make the abstraction layers discrete and separated by a good margin. 

* ALA puts greater emphasis on wiring being able to represent any programming paradigm that suits the expression of requirements, and the use of many different paradigms in the same wiring diagram.

* ALA emphasises the cohesion of functional parts of a system such as UI, logic and Data, by bringing them all together in one small diagram using domain level components

* Instead of 'required' interfaces, in ALA they are called 'accepts' interfaces. This is because the abstractions are more abstract and composable, so, as with Lego blocks, there isn't necessarily a connection to another instance.





==== Presentation, Business, Services, Persistence, Database

TBD

==== Presentation, Application, Domain, Infrastructure

The middle two layers appear to be the same as ALA's. The Presentation (UI) only has run-time dependencies on the Application, and the Domain layer only has run-time dependencies on the Infrastructure (Persistence etc), so these layers are not present in ALA. 

Instead Presentation is done in the same way as the rest of the application, by composing and configuring abstractions in the domain. The meaning of composition for UI elements (typically layout and navigation-flow) is different from the meaning of composition in the use-cases (typically workflow or dataflow).

In ALA, the foundation layer is also done in the same way as the rest of the application, at least a little. Domain abstractions that represent say a persistent table are in the Domain layer. The composition and configuration of them again goes in the Application layer. This time the meaning of composition is, for example, columns for the tables and schema relations.  

If the implementation of any domain abstraction is not small (as is the case with the persistent Table abstraction mentioned above, which will need to be connected to a real database), it will be using other abstract interfaces (in the Programming Paradigms layer) connected to its runtime support abstractions in a technical domain, the same as in Hexagonal Architecture.

==== Object Oriented Programming

From my reading, it seems that the most characteristic feature of OOP is that when data and operations are cohesive, they are brought together in an object. Others may see it as enabling reuse, inheritance, and still others may see it as polymorphism. New graduates seem to be introduced to polymorphism in inheritance and not be introduced to interfaces at all, which is a shame because the concept of interfaces is much more important. 

I have never been an expert at Object Oriented Design as I found the choice of classes difficult and the resulting designs only mediocre. But I think the most fundamental and important characterising feature of OOP is under-rated. That is the separation of the concepts of classes and objects. This separation is not so clearly marked when we use the terms modules or components. The separation is fundamentally important because it's what allows us to remove all dependencies except knowledge dependencies. In the way described earlier in this article, you can represent the knowledge of most dependencies as a relationship between instances completely inside another abstraction. What OOP should have done is represent relationships between objects completely inside another class. The problem is that OOP doesn't take advantage of this opportunity. Instead, it puts these relationships between objects inside those objects' classes, as associations or inheritance, thereby turning them into design-time dependencies, and destroying the abstract qualities of the classes. Abstractions, unlike classes, retain their zero coupling with one another.

ALA addresses the problem by calling classes abstractions and objects instances. Abstractions differ from classes by giving us a way to have logical zero coupling, as if they were on different physical platforms. Instances differ from objects by having ports because their classes give them no fixed relationships with other objects.

Of course, when you are writing ALA code, abstractions are implemented using classes, but you are not allowed associations or inheritance. Instances are implemented as objects but with ports for their connections. A port is a pair of interfaces that allow methods in both directions. The interfaces are defined in a lower layer.
 
In ALA, the UML class diagram completely loses relevance. Because classes have no relationships with each other, bar knowledge dependencies, a UML diagram in ALA would just be a lot of boxes in free space, like a pallet of things you can use. You could show them in their layers and you could even draw the downward composition relationships that represent the knowledge dependencies, but there would be no point to this except in explaining the concepts of ALA. When you are designing an actual system, the real diagram is the one inside of an abstraction, especially the uppermost one, the application. It shows boxes for instances of the abstractions it uses, with the name of the abstraction in the box, the configuration information for those instances, and of course the lines showing how they are wired together. The names inside the boxes would not even need to be underlined as in UML, because the boxes in such diagrams would always be instances. 

Such a diagram is close to a UML object diagram. However, a UML object diagram is meant to be a snapshot of a dynamic system at one point in time. In ALA, any dynamic behaviour is captured in a static way by inventing a new abstraction to describe that dynamic behaviour. Thus the design-time view is always static. So the object diagram is static. The application class specifies a number of objects that must be instantiated, configured, and wired together to execute at run-time. Since the structure is always static, ideally this would be done by the compiler for best efficiency, but there is no such language yet. So, in the meantime, it is done at initialization time. The object diagram can be fairly elegantly turned into code using the fluent coding style shown in the XR5000 example.

===  DSLs

We briefly discussed ALA as a DSL in the structure chapter <<DSL1, here>> 

ALA includes the main idea of DSLs in that the fundamental method "represent[s] requirements by composition of domain abstractions". It shares the DSL property that you can implement a lot more requirements or user stories in a lot less code. 

But ALA only tries to be a light-weight way of telling ordinary developers how to organise code written in your underlying language. Although the domain abstractions do form a language and the paradigm interfaces give it a grammar, ALA doesn't pursue the idea of a language to the point of textural syntactic elegance. Instead, you end up with explicit wiring methods to combine domain entities, or plain old functional composition, or some other form of composition in the wider sense of the word. Often, the text form is only a result of hand translation of an executable diagram. ALA certainly doesn't overlap with DSLs to the extent of an external DSL, nor does it try to sandbox you from the underlying language. It therefore does not require any parsing and doesn't need a language workbench, things that may scare away 'plain old C' developers.

Like DSLs, ALA can be highly declarative depending on the paradigm interfaces being used to connect domain abstractions. It is better to have the properties of composition and composability in the your domain language even if they may not be in a perfectly elegant syntactic form. ALA may end up composing abstractions with calls to wireTo methods instead of spaces or dots. But often a diagram using lines is even better than spaces and dots.  

In DSLs, it is important that different languages can be combined for different aspects of a problem. For example, a DSL that defines State machines (the state diagram) and a DSL for data organisation (Entity Relationship Diagram) may be needed in the same application. You don't want to be stuck in one paradigm. ALA recognises this importance by having paradigm interfaces that are more abstract than the domain abstractions. 

DSLs probably work by generating a lot of code from templates whereas ALA works by reusing code as instances of abstractions. Both of these methods are fine from the point of view of keeping application specific knowledge in its place, and domain knowledge in its place. Howver, the distinction between ALAs domain layer and programming paradigms layer is probably not so as clearly made in the implementation of the templates.   

It is an advantage of DSLs that they can sandbox when needed. An example from the wiring pattern earlier is that the ports of instances do not need to be wired. Therefore, all abstractions need to check if there is something wired to a port before making a call on it. Enforcing this is a problem I have not yet addressed.

A possible solution, albeit inferior to a real DSL that would tell you at design-time, might be that when there are tools that generate wiring code from diagrams, they automatically put stubs on all unwired ports. These stubs either throw an exception at run-time, or just behave inertly. 

ALA is different from external DSLs. ALA is just about helping programmers organise their code in a better way. It doesn't try to make a syntactically elegant language, as a DSL does. Certainly an external DSL will end up representing requirements in a more elegant syntax. But that is not the most important thing in ALA. The most important thing is the separation of code that has knowledge of the requirements, which will cause the invention of abstractions that have zero coupling (because the coupling was really in each requirement - that is why a requirement is cohesive). ALA also avoids taking the average imperative language programmer out of their comfort zone. It does not require a language workbench and does not sandbox you from the underlying language.

ALA probably does fit into the broadest definition of an internal DSL. However, again, it does not target syntactic convenience in the expression of requirements so much as just separating the code that knows about those requirements from the code that implements them. An internal DSL usually aims to have a mini-language that is a subset of the host language, or it tries to extend the host language through clever meta-programming to look as if it has new features. ALA is about abstraction layering. It is about this design-time view of knowledge dependencies: what abstractions in lower layers are needed to understand a given piece of code.







===  Multi-tier Architecture

TBD


===  Clean Architecture

Clean architecture is initially viewed as concentric circles which are in effect layers. Entities are innermost, with business logic next, and the external system consisting of things like database, UI and communications on the outer. These layers are allowed to have dependencies going inwards. 

In conventional code, dependencies tend to follow communications, and communications, when implemented in the form of direct function or method calls, flow from the initiator of the communications.  

This gives rise, for example, to dependencies from the UI to the business logic, and then from the business logic to the database. In clean architecture, these are referred to as primary and secondary I/O with respect to the business logic. The idea in clean architecture is to invert the secondary dependencies so that all communications dependencies are now toward the business logic.

In this way the business logic at the core is reusable, and perhaps more importantly understandable without knowing details of a concrete database, middleware, or UI. It also facilitates easier testing of the business logic.

The business logic uses interfaces to communicate with the outside world. The primary communications have interfaces that the business logic _implements_ (unchanged from conventional code). The secondary communications have interfaces which the business logic _requires_. The concrete implementations of database, etc are passed in or injected in. This wiring is specific to a unique application, so in ALA terms, it goes in the top layer.

From the point of view of the business logic only, this is compliant with ALA, except for the dependencies on entities, which is discussed below. The elements of the business logic, which in clean architecture are called use cases, can be considered abstractions that know about the business use cases and nothing else.


==== Adapters

In the clean architecture, dependencies, such as those between business logic and database, are reversed (following the dependency inversion principle) from what it would have been in conventional code. These reversed dependencies do not comply with ALA. I think most implementations recognise these as bad dependencies, and solve it by removing the dependencies altogether using adapters. This is now a lot closer to ALA compliance. 

Something must pass-in or inject the adapters into each of the business logic use cases. If this logic is thought of as being in a higher layer, then this is also ALA compliant.

In terms of ALA abstraction layers, the use cases, the database, the UI, and other IO are all about the same level of abstraction. They all know about different types of details. While the use cases know about the domain and it's requirements, the database knows about how to efficiently store data. They are all abstractions that are zero coupled with one another. The adapters go in a layer above, and are specific to a use case / external IO pairing. The main() (or a function it delegates) goes in a layer above that and wires everything up using (usually) constructor dependency injection on the use cases.

==== Entities

Clean architecture allows dependencies of use cases on entities. This is incompatible with ALA.  

Entities typically hold all sorts of domain details, for example various informations about customers. When the requirements change, these will change. We expect requirements to change - that's why we have agile.

Entities are an easy place to just add all fields to do with an identity. They will tend to hold some fields that, although they associate with an identify, really belong to separate use cases. These fields should be cohesive with their use cases. If entities hold information that is not significantly abstract with respect to use cases, such as the customer's address, which is primarily used by one or two use cases only, then it is not ALA compliant. The customer identity abstraction's responsibility should not be to know all data that can be associated with a customer, but to know about the idea of identity. It should not be used as the carrier of information between two use cases, which would expose all entity data to all use cases. Instead, use cases should all know about the abstraction, _customer identity_. A particular use case should only know about it's own data, and only store it against a customer identity.


In other words, a user story should be able to have private data that is associated with an identity and still ultimately stored with all other data for that identity in the database. The only idea that is abstract enough to go in a layer below the use cases is the customer identity, which is likely to be reused by most new use cases. Subclassing, so that every use case has its own subclass may solve the problem in one way, but I expect would cause other problems.

Even if some customer detail needs to be shared with another use case, communicating this via a shared entity is bad. For example, consider a use case in a system that knows about the address that customers enter into the system. It could have an output port called 'address' that can be used to wire it to other use cases. This port will probably have a DTO type that belongs to it. The DTO cannot be shared with other features in the same layer without violating ALA constraints. A feature such as frieghtcost may need an address to calculate freight. Remember it is written separately from the address feature so is not coupled with it.  It cannot know about the address feature. It can't know the DTO of the address. Nor does it need the entire address. So it may be written, for example, to have input ports for country and zip code. Yet another feature is shipping. It needs an address for a shipping label. It may have an input port that takes a string for of address, because it isn't interested in the content of the address, only in faithfully printing it. So these three ports are incompatible. The wiring layer, which knows that it needs to wire these three together also knows how to adapt them, which can be done quite simply by passing in a lambda expression into the WireTo method (analogous to a Select clause in LINQ).

More generally in ALA, such applications are best viewed primarily in terms of dataflows rather than abstracted entities. Dataflows to/or from the database, for example. It flows to particular use cases, and only the data that is needed by the use case. At any point in the flow, the flow has a type. It is still nice to have a compiler generated, anonymous, fully type checked class at each point in the flow. But nowhere do we want to create an explicit class for sharing a whole entity, or even a part of an entity.

The identity of a customer itself is probably an abstract concept that can be used by all features. We therefore want a shared abstraction for the identity (just knowing about a unique internal or external number or key). 

It should be possible to add a feature that needs a new private field (private to the feature). The data can still be associated with an identity and be stored in the database. Adding this field should cause a database migration, but not changes to other use cases. 

So the way entities should be handled is quite different in ALA.

TBD do a simple 'task list' application on Github in both ALA and clean architecture to show how entities are handled in ALA. Then add a feature such as e-mail notification on due date to show how a new feature can have it's own private data stored against the task identity (the e-mail sent status) and communicate via a port with an existing feature (the due date feature).



==== Primary separation

There is a second major difference between clean architecture and ALA. In clean architecture, the UI and other externals IO such as the database are considered to be separated first. That is how it is shown on an architecture diagram, almost as if they are separate packages. You hear of being able to switch between a GUI or CLI based UI. 

This view of primarily separating UI from business logic will likely lead to coupling. It is unlikely that the UI is so generic that it knows nothing about the business logic. It will need to specific to the data the business logic needs or produces. Similarly, the design of the UI will usually influence the way the business logic works. For example, the UI may be designed so that you enter all data first (like a form) and then submit, or it may be designed so that you select generally what you want to do, and then wizards guide the user through. The choice is likely to affect the way the business logic works.

In ALA, the primary separation is by features first. The UI and the business logic for a particular feature is considered to be cohesive with respect to that feature abstraction. The use case will wire up both the elements of the business logic and the elements of the UI (and those for the necessary database queries, etc). The UI elements used can still be swapped out for different ones, but that is an operation on the feature. 

In the case that the UI design is not changing, but its implementation is, that involves swapping out the implementations of the UI domain abstractions. The abstraction themselves do not change, so the use cases wont change. But the new UI abstractions can shift to a different technology, shift from desktop to cloud, or the like. 


==== DTOs

DTOs have two different uses.

- part of an interface to group together related data that is sent through the interface at one time. 
- to collect data together to be transported together to cut down on the overhead of messaging.

===== interface DTOs

In ALA, DTOs are not generally abstractions in themselves. Therefore, they may not be put in a lower layer and shared by two abstractions to communicate. That would couple the knowledge inside the two abstractions. If many abstractions want to know about the same DTO, this is likely to be the case as new abstractions are added, then maybe it is sufficiently abstract to be in a lower layer and shared. 

Otherwise in ALA, you need to use adapters. This can be as simple as a lambda expression passed to the WireTo operator, in the same way that you would pass a lambda expression to a .Select clause in LINQ.

Although this is ALA compliant, in ALA we generally prefer not to use adapters. Instead we use interfaces that are a significantly more abstract that are not owned by the business logic core. These are of course at the abstraction level of programming paradigms. These types of interfaces are heavily reused, allow composability in the wiring, and help tremendously to keep all abstractions from being implicitly coupled.

If a DTO can be avoided by, for example, having two dataflow ports that use primitive types, this will increase the abstraction level, reusability and composability of your abstractions. 

===== transport DTOs

In ALA you wouldn't use DTO for transport purposes. Instead, invent an abstraction say called multiplexer_demultiplexer for packing/unpacking (or serializing/deserializing) multiple input or output ports. Then instances of any two abstractions A and B, that would normally be compatible for wiring together, and which use asynchronous communications, can be physically deployed to opposite sides of the transport system. The wireTo operator, knowing they are in different physical locations, defers to a version that wire each of them to the respective multiplexer_demultiplexer instances.

==== Stability of wiring/adapter/feature layers

A system built from a wiring layer at the top, then an adapters layer below that, and then a layer below that for independent features, use cases, databases, UIs etc is ALA compliant. This is because the abstraction layers are more abstract as you go down. The top layer abstraction is a specific application. The second layer adapters are specific to pairs of things in the third. The third is the layer of fully reusable things. A database, even though we call it concrete, is a lot more reusable than a particular application, or a particular adapter.

An ALA application using these three types of layers is a little different from the layers we normally talk about, which uses domain abstractions that are wired directly together using compatible ports instead of via adapters in the layer above. To enable the ports to be compatible, there must be a layer below that provides abstract interfaces, which is what we call the programming paradigms. This latter arrangement has compositionality. For example, two domain abstractions currently wired together can have another domain abstraction, which is a decorator such as a filter, wired between them.

The two styles of layering can be used together.

==== Swapping out technology

In clean architecture, part of the reason for avoiding dependencies from business logic to things like a particular database or framework is to allow swapping out the technology. The database in the third layer can be exchanged for a completely different type - the coninical example is changing it from a relational database to a simple file. The business logic does not change. Only new adapters are needed, one for each use case. The top layer wiring of course also needs to change to use the different adapters.

An ALA application that uses the preferred layering scheme of application layer, domain abstractions layer, programming paradigms layer can also have its technologies swapped out. Let's again use the canonical example of swapping a relational database for a simple file. The domain abstraction that implements persistence using a database will have a port that implements a suitable programming paradigm. Usually this port has a type like ITableDataflow. You only need to substitute this domain abstraction with one that uses the same programming paradigm, but implements it as a simple file. Effectively these domain abstractions are wrappers, not adapters. 

The wiring again needs to change in all the places that were instantiating the database implementation. This is probably the only practical way to do it, as the database implementation probably needs different application specific configuration than what a simple file implementation would.

Now let's consider swapping out the UI. Let's say we are changing the UI from a desktop windowed application to a browser, or from a PC window to a CLI (Command Line Interface).

In the original PC application, the wiring instantiates UI GUI domain abstractions. These domain abstractions are wrappers for, say, WPF UI elements. The wrappers have ports which the wiring uses to connect them to the corresponding parts of the business logic. These ports are, or course, abstract interfaces from the programming paradigms layer.

To swap out the UI involves changing the wiring to instantiate from a different set of these UI domain abstractions. They will have the same ports that are still wired to their relevant place in the business logic as before.

In the case of the browser, these new domain abstraction work by changing elements of the HTML that will be returned by an initiating HTTP request. Just as the windowed domain abstractions were wired to their containing window, browser domain abstractions will be wired to their containing page. The containing page will request their content when it is time to send the response to the HTTP request.

The case of the CLI is more interesting. Whenever there is a case of either a GUI or a CLI user interface in conventional architecture, the business logic is tied to the CLI commands, and the GUI then uses the CLI. But in ALA we have the option to do this without coupling the design of the business logic to the design of the CLI commands.  

This is how it could work. Imagine we have previously built the application as a desktop windowed application, just as we did before. Now we change the wiring to use a set of CLI domain abstractions instead. Actually we need only two abstractions, one called command and one called response. Instances of the command abstraction are configured with the command that they handle. The command has an output event port which fires when the command is entered. If there are parameters, the abstraction can have other output ports for them, which are output before the event port fires. Alternatively you could chain up a series of parameter abstractions, each with a single output port. The response abstraction has an input port, and just prints any input data it receive. Optionally it could have a configuration name so it can identity itself when it prints.

Just as there are containing domain abstractions that describe layout for the GUI types of UI domain abstractions, CLI domain abstractions would also connect to a common domain abstraction that receives commands in a general form and passes them to the handler that is configured for that command. It would also collate the responses, add newlines to the output, etc.  

There is one other possibility. In the above cases of swapping out the UI, we changed the names of UI domain abstraction instantiated by the wiring. That was potentially all we needed to change.

It is possible that the configuration of the domain abstractions did not need to change. For example, CLI command abstractions need to be configured with the actual command string they will respond to, whereas their GUI equivalents, which are buttons, need to be configured with a button name. These could potentially be the same. If other configuration information of UI domain abstractions, such as style, is implemented in a generic way such as having a style port wired using WireMany, then it is possible that the wiring only needs to specify the UI domain abstraction names. 

In this case we could name all equivalent UI domain abstraction with the same name. Then by which set of classes we include in the project, it will be built for different technologies. I'm not really proposing it be done this way, just exploring the idea.




===  Onion Architecture

TBD



===  Hexagonal Architecture (Ports and Adapters)

ALA includes the basic idea of hexagonal architecture, but with modification using the Bridge Pattern to keep cohesive knowledge belonging to the application from being split. 

In a previous section we intimated that the sideways chains of interfaces going out in horizontal directions were the same as hexagonal architecture. While ALA shares this aspect of hexagonal architecture, there is still an important difference.

ALA retains domain abstractions of the UI, Database, communication and so on. For instance, in our XR5000 example, we had a domain abstraction for a persistent Table. We had domain abstractions for UI elements such as Page, Softkey etc. We don't just have a port to the persistence adapter, we have an abstraction of persistence. We don't just have a port for the UI to bind to, we have abstractions of the UI elements. The implementation of these abstractions will then use ports to connect to these external system components. Why is it important that we have domain abstractions of these external components?

. The Database and the UI will have a lot of application specific knowledge given them as configuration. Remember the creativity cycle. After instantiation of an abstraction comes configuration. The database will need a schema, and the knowledge for that schema is in the application. The Softkey UI elements will need labels, and that knowledge is in the application. By making domain abstractions for persistence and UI, the application can configure them like any other domain abstraction as it instantiates and wires up the application. To the application, these particular domain abstractions look like wrappers of the actual database and UI implementations, but they are more like proxies in that they just pass on the work. 
+
The Persistence abstraction then passes this configuration information, via the port interface to the actual database. The Softkey abstraction then passes its label, via the port interface, to the softkeys. Otherwise the Application would have to know about actual databases and actual softkeys.
+
If you need a design where the UI can change, you just make the UI domain abstractions more abstract. A softkey may be a command abstraction. It is still configured with a label. But it may be connected to a softkey, a menu item, a CLI command, a web page button, or a Web API command.

. From the point of view of a DSL, it makes sense to have concepts of UI and persistence and communications in the DSL language. The application is cohesive knowledge of requirements. The UI and the need for persistence are part of the requirements. In fact, for product owners communicating requirements, the UI tends to be their view of requirements. They talk about them in terms of the UI. Many of the product owners I have worked with actually design the UI as part of the requirements (with the backing of their managers, who are easily convinced that software engineers can't design UIs. PO can't either, but that is another story.). The point here is that the UI layout, navigation, and connection to business logic is all highly cohesive. We explicitly do not want to separate that knowledge. 
+
As a restatement of an earlier tenet of ALA, it is much better to compose the application with abstractions of Business logic, UI and persistence than to decompose the application into UI, persistence and business logic.

. We want the application to have the property of composability. We have previously discussed how that means using programming paradigm interfaces for wiring up domain abstractions. By using domain abstractions to represent external components, the abstractions can implement the paradigm interfaces and then be composable with other domain abstractions. For example, the Table domain abstraction which represents persistence may need to be connected directly to a grid, or to other domain abstractions that map or reduce it. Indeed, the Table abstraction itself can be instantiated multiple times for different tables and be composed to form a schema using a schema programming paradigm interface. I have even had a table instance's configuration interface wired to a another Table instance. (So its columns can be configured by the user of the application.)     

. The fourth reason why it is important for the application to not directly have ports for external components of the system is that we don't want the logical view of the architecture to become just one part of the physical view. If there is a communications port that goes to a different physical machine where there is more application logic, the application's logical view should not know about that. It may be presented as an annotation on the application (lines) connecting certain instances, but it shouldn't split the application up. At the application level, the collaboration between parts instantiated on different machines is still cohesive knowledge and belongs inside one place - the application.  

=== Domain Driven Design

Domain Driven Design's "Bounded Contexts" and ALA's Domain Abstractions layer have the same goal, that of encapsulation of the domain specific knowledge.

Domain driven design appears to concentrate on common languages to allow  pairs of elements to communicate, which ALA explicitly avoids. ALA tries to abstract the languages so that they are more abstract and fundamental than the domain, and more like programming paradigms.

// TBD Discuss with a DDD expert the comparison between ALA and DDD.




===  Microservices

TBD




===  Architecture evaluation methods

Methods such as ATAM tell us how to evaluate an architecture for quality attributes such as maintainability, for instance by giving it modification scenarios to test how difficult the modifications would be to implement. There are several scenarios based methods to do this such as ATAM. Using this we could, theoretically, iteratively search over the entire architecture design space to find a satisfactory solution. It's a bit analogous to numerically solving for the maxima of a complex algebraic formula. In contrast, ALA is analogous to an 'algebraic solution'. If the desired quality attributes, and all the software engineering topics listed above are the equations, ALA is the algebraic solution. It simplifies them down into a parameterised template architecture, ready for you to go ahead and express your requirements.


anchor:Monads[]


===  Reactive Extensions

TBD 




===  WPF & XAML

TBD

===  Functional programming

TBD

===  Functional programming with monads

TBD

===  Functional Reactive Programming

TBD

===  Example project - Game scoreboard

For the example project for this chapter, we return to the ten-pin bowling and tennis scoring engines that we used in Chapter two, and add a scoreboard feature (well a simple ASCII scoreboard in a console application rather than real hardware).

As the requirement, say we want a console application that displays ASCII scoreboards that look like these examples:

....
Ten-pin

 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
|   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |    10  |
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
| 1| 4| 4| 5| 6| /| 5| /|  | X| -| 1| 7| /| 6| /|  | X| 2| /| 6|
+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+--+
|   5 |  14 |  29 |  49 |  60 |  61 |  77 |  97 | 117 |   133  |
 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
....

....
Tennis

 -----++----+----+----+----+----++--------
|   1 ||  4 |  6 |  5 |    |    ||    30  |
|   2 ||  6 |  4 |  7 |    |    ||  love  |
 -----++----+----+----+----+----++--------
....



As usual in ALA, our methodology begins with expressing those requirements directly, and inventing abstractions to do so. So, we invent a 'Scorecard' abstraction. It will take a configuration which is an ASCII template. Here are the ascii templates that would be used for ten-pin and tennis:

....
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-----------
|   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |   9   |     10    |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|
+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+---+
|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-------------
....

....
 -----++----+----+----+----+----++--------
| M0  ||S00 |S10 |S20 |S30 |S40 || G0---  |
| M1  ||S01 |S11 |S21 |S31 |S41 || G1---  |
 -----++----+----+----+----+----++--------
....

The scorecard ASCII template has letter place-holders for the scores. (A single letter is used so it doesn't take up much space on the template design.) Different letters are used for different types of scores. Digits are used to specify where multiple scores of the same type are arranged on the scoreboard. They are like indexes. Either 1-dimensional or 2-dimensional indexes can be used in the scoreboard template. For example, the frame scores in ten-pin bowling have scores for each ball for each frame, F00, F01 etc, as shown in the example above.

The scorecard abstraction needs functions it can use to get the actual scores. The functions are configured into little 'binding' objects that we then wire to the scoreboard. The binding objects are configured with the letter that they return the score for. 

==== Ten-pin

Having invented the Scorecard and Binding abstractions, we can now do the ten-pin application diagram:
 

[plantuml,file="diagram-bowling-3.png"]
----
@startdot
digraph foo {
rankdir=LR

#note rankdir does not work inside subgraphs
subgraph cluster_C {
fontsize=20
label="Ten-Pin Bowling                                                            "
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter number of pins\""]

scoreboard [fontsize=14,label=<
<table border='0' cellborder='1' cellspacing='0'>
<tr><td colspan="21" sides="B"><font point-size="14">Scorecard</font></td></tr>
<tr><td colspan="2">1</td><td colspan="2">2</td><td colspan="2">3</td><td colspan="2">4</td><td colspan="2">5</td><td colspan="2">6</td><td colspan="2">7</td><td colspan="2">8</td><td colspan="2">9</td><td colspan="3">10</td></tr>
<tr><td sides="LTR">F00</td><td>F01</td><td sides="LTR">F10</td><td>F11</td><td sides="LTR">F20</td><td>F21</td><td sides="LTR">F30</td><td>F31</td><td sides="LTR">F40</td><td>F41</td><td sides="LTR">F50</td><td>F51</td><td sides="LTR">F60</td><td>F61</td><td sides="LTR">F70</td><td>F71</td><td sides="LTR">F80</td><td>F81</td><td sides="LTR">F90</td><td>F91</td><td>F92</td></tr>
<tr><td colspan="2" sides="LBR">T0</td><td colspan="2" sides="LBR">T1</td><td colspan="2" sides="LBR">T2</td><td colspan="2" sides="LBR">T3</td><td colspan="2" sides="LBR">T4</td><td colspan="2" sides="LBR">T5</td><td colspan="2" sides="LBR">T6</td><td colspan="2" sides="LBR">T7</td><td colspan="2" sides="LBR">T8</td><td colspan="3" sides="LBR">T9</td></tr>
</table>
>]

framebind [label="Binding|F"]
totalbind [label="Binding|T"]
game [label="Frame|\"game\"|nFrames==10"]

node [shape=record]
function1 [label="GetSubFrames()\n.Select(sf =\> sf.GetScore()[0])\n.Accumulate()"]
function2 [label="GetSubFrames()\n.Select(f =\> f.GetSubFrames()\n.Select(b =\> b.GetScore()[0])"]
translate [label="Translate\nX,/,- etc"]

console -> game  [label = "IConsistsOf"]
console -> scoreboard [constraint=false, label = "IPullDataFlow"]
scoreboard -> framebind -> translate -> function2 -> game
scoreboard -> totalbind -> function1 -> game

{rank=same console scoreboard}
{rank=same framebind totalbind}
{rank=same function1 function2}

}
}
@enddot
----

An abstraction we didn't mention yet is the ConsoleGameRunner. Its job is to prompt for a score from each play, display the ASCII scoreboard, and repeat until the game completes. 

The 'game' instance of the Frame abstraction on the right of the diagrams is the scoring engine we developed in Chapter Two. Together with this engine, we now have a complete application. 

The rounded boxes in the diagram are instances of domain abstractions as usual for ALA diagrams. The sharp corner boxes are instances of Application layer abstractions. They are the mentioned functions for the Bindings. That code is application specific so goes in the application layer. They just do a simple query on the scoring engine.

Now tranlate the diagram into code. Here is the entire application layer code for ten-pin:
....
consolerunner = new ConsoleGameRunner("Enter number pins:", (pins, engine) => engine.Ball(0, pins))
.WireTo(game)
.WireTo(new Scorecard(
"-------------------------------------------------------------------------------------\n" +
"|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|\n" +
"|    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+----\n" +
"|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |\n" +
"-------------------------------------------------------------------------------------\n")
.WireTo(new ScoreBinding<List<List<string>>>("F", 
    () => TranslateFrameScores(
        game.GetSubFrames().Select(f => f.GetSubFrames().Select(b => b.GetScore()[0]).ToList()).ToList())))
.WireTo(new ScoreBinding<List<int>>("T", 
    () => game.GetSubFrames().Select(sf => sf.GetScore()[0]).Accumulate().ToList()))
);
....

....
....
If you compare this code with the diagram, you will see a pretty direct correspondence. 
Remember 'game' is the reference to the scoring engine project in the previous chapter.

That's pretty much all the code in the application. Oh there is the 'translate' function, but it is pretty straight forward once you know the way a ten-pin scorecard works. For completeness here it is.

....

/// <summary>
/// Translate a ten-pin frame score such as 0,10 to X, / and - e.g. "-","X".
/// </summary>
/// <example>
/// 7,2 -> "7","2"
/// 7,0 -> "7","-"
/// -,3 -> "-","7"
/// 7,3 -> "7","/" 
/// 10,0 -> "",X
/// 0,10 -> "-","/"
/// additional ninth frame translations:
/// 10,0 -> "X","-"
/// 7,3,2 -> "7","/","2"
/// 10,7,3 -> "X","7","/"
/// 0,10,10 -> "-","/","X"
/// 10,10,10 -> "X","X","X"
/// </example>
/// <param name="frames">
/// The parameter, frames, is a list of frames, each with a list of integers between 0 and 10 for the numbers of pins.
/// </param>
/// <returns>
/// return value will be exactly the same structure as the parameter but with strings instead of ints
/// </returns>
/// <remarks>
/// This function is an abstraction  (does not refer to local variables or have side effects)
/// </remarks>
private List<List<string>> TranslateFrameScores(List<List<int>> frames)
{ 
    // This function looks a bit daunting but actually it just methodically makes the above example tranlations of the frame pin scores 
    List<List<string>> rv = new List<List<string>>(); 
    int frameNumber = 0;
    foreach (List<int> frame in frames)
    {
        var frameScoring = new List<string>();
        if (frame.Count > 0)
        {
            // The first 9 frames position the X in the second box on a real scorecard - handle this case separately
            if (frameNumber<9 && frame[0] == 10)
            {
                frameScoring.Add("");
                frameScoring.Add("X");
            }
            else
            {
                int ballNumber = 0;
                foreach (int pins in frame)
                {
                    if (pins == 0)
                    {
                        frameScoring.Add("-");
                    }
                    else
                    if (ballNumber>0 && frame[ballNumber]+frame[ballNumber-1] == 10)
                    {
                        frameScoring.Add(@"/");
                    }
                    else
                    if (pins == 10)
                    {
                        frameScoring.Add("X");
                    }
                    else
                    {
                        frameScoring.Add(pins.ToString());
                    }
                    ballNumber++;
                }

            }
        }
        rv.Add(frameScoring);
        frameNumber++;
    }
    return rv;
}
....


==== Tennis


So now that we have these domain abstractions for doing console game scoring applications, let's do tennis:


////
[plantuml,file="diagram-bowling-4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
#subgraph cluster_C {
label="Ten-Pin Bowling"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
game [label="Frame|\"game\"|nFrames==10"]
bonus [label="Bonus||score\<10 \|\| plays==3"]
frame [label="Frame|\"frame\"|frameNum\<9 && (balls==2 \|\| pins==10)\n \|\|\ (balls==2 && pins\<10 \|\| balls==3)"]
ball [label="SinglePlay"]
game -> bonus -> frame -> ball
}
}
@enddot
----
////


[plantuml,file="diagram-tennis-3.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label="Tennis"
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter winner of play\""]

scoreboard [label="Scoreboard| -----++----+----+----+----+----++--------\n\| M0  \|\|S00 \|S10 \|S20 \|S30 \|S40 \|\| G0---  \|\n\| M1  \|\|S01 \|S11 \|S21 \|S31 \|S41 \|\| G1---  \|\n -----++----+----+----+----+----++--------\n"]

gamebind [label="Binding|G"]
setbind [label="Binding|S"]
matchbind [label="Binding|M"]
match [label="Frame|\"match\"|score.Max()==3"]

node [shape=record]
function1 [label="GetScore()"]
function2 [label="GetSubFrames()\n.Select(sf =\> sf.GetSubFrames().First())\n.Select(s =\> s.GetScore()).ToList()"]
function3 [label="GetGameOrTieBreakScore\n(see function)"]

console -> scoreboard [constraint=false, label = "IPullDataFlow"]
console -> match [label = "IConsistsOf"]
scoreboard -> setbind -> function2
scoreboard -> matchbind -> function1
scoreboard -> gamebind -> function3
function1 -> match
function2 -> match
function3 -> match

{rank=same console scoreboard}

}
}
@enddot
----

////
[plantuml,file="tennis4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
// subgraph cluster_C {
label="Tennis scoring"
style=rounded
#node [style=rounded]

node [shape=Mrecord]
match [label="Frame|\"match\"|score.Max()==3"]
wtp1 [label="WTP"]
set [label="Frame|\"set\"|score.Max()\>=6 && \nMath.Abs(score[0]-score[1])\>=2"]
wtp2 [label="WTP"]
game [label="Frame|\"game\"|score.Max()\>=4 && \nMath.Abs(score[0]-score[1])\>=2"]
play [label="SinglePlay"]
switch [label="Switch||(setNumber\<4 &&\n score[0]==6 && score[1]==6"]
wtp3 [label="WTP"]
tiebreak [label="Frame|\"tiebreak\"|score.Max()==7"]
play2 [label="SinglePlay"]
match -> wtp1 -> switch -> set -> wtp2 -> game -> play
switch:s -> wtp3:w
wtp3 -> tiebreak -> play2
{rank=same set wtp3}

// }
}
@enddot
----
////

I left the code out of the GetGameOrTieBreakScore box as it is a little big for the diagram here. It is similar to the other queries but it must first determine if a tie break is in progress and get that if so. Also it translates game scores from like 1,0 to "15","love".

And here is the code for the Tennis diagram:
....
consolerunner = new ConsoleGameRunner("Enter winner 0 or 1", (winner, engine) => engine.Ball(winner, 1))
.WireTo(match)
.WireTo(new Scorecard(
        "--------------------------------------------\n" +
        "| M0  |S00|S10|S20|S30|S40|S50|S60|  G0--- |\n" +
        "| M1  |S01|S11|S21|S31|S41|S51|S61|  G1--- |\n" +
        "--------------------------------------------\n")
    .WireTo(new ScoreBinding<int[]>("M", () => match.GetScore()))
    .WireTo(new ScoreBinding<List<int[]>>("S", () => 
        match.GetSubFrames()
            .Select(sf => sf.GetSubFrames().First())
            .Select(s => s.GetScore())
            .ToList())
    .WireTo(new ScoreBinding<string[]>("G", () => GetGameOrTiebreakScore(match)))
);

....

If you compare this code with the diagram, you can see a pretty direct correspondence. match comes from the scoring engine project in Chapter two.

==== Concluding notes

Although the diagrams must be turned into text code to actually execute, it is important in ALA to do these architecture design diagrams first. They not only give you the application, they give you the architectural design by giving you the domain abstractions and programming paradigms as well. If you try to design an ALA structure in your head while you write it directly in code, you will get terribly confused and make a mess. Using UML class diagrams will make it even worse. Code at different abstraction levels will end up everywhere, and run-time dependencies will abound. Our programming languages, and the UML Class diagram, are just not designed to support abstraction layered thinking - it is too easy to add bad dependencies (function calls or 'new' keywords) into code in the wrong places.

Note that at run-time, not all dataflows have to go directly between wired up instances of domain abstractions. The data can come up into the application layer code, and then back down. This was the case when we did the functional composition example in Chapter One. In this application we are doing that with the code in the square boxes that get the score from the engine. The important thing is that all the code in the application is specific to the application requirements.  




////


////


////
Now let's have a look at some of the code in the two of the new domain abstractions. Here is the essence of the Scoreboard domain abstraction (remember we are down a layer now, so it has no knowledge of bowling):

....
public string GetScorecard()
{
    var matches = Regex.Matches(ASCIITemplate, "(([A-Z][0-9][0-9])|([A-Z][0-9])|([A-Z]))-*"); // The regular expression matches e.g. A, B1, C12, D-, E00--
    var rv = ASCIITemplate;
    foreach (Match match in matches)
    {
        char id = match.Value[0];
        foreach (IScoreBinding sg in scoreGetters)
        {
            if (id == sg.Label[0])
            {
                if (match.Length>=2 && char.IsDigit(match.Value[1]))
                {
                    if (match.Length >= 3 && char.IsDigit(match.Value[2])) // e.g. A11
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0'), Convert.ToInt32(match.Value[2]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                    else // e.g. A1
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                }
                else // e.g just A, no index
                {
                    rv = rv.Replace(match.Value, sg.GetScore().PadLeft(match.Length));
                }
            }
        }
    }
    return rv;
}
....

The ScoreBinding domain abstraction has three overloads of GetScore - one for two indexes, one for one index, and one for zero indexes. Here is the code for the one that has one index. The other two are similar. Because we are given one index, we expect the function that we have been wired to will return a one dimensional something. It could be a List or array, of type int or string. T tells us what type it is. Our job is to index into whatever it is, and return it as a string:

....
public string GetScore(int x)
{
    object temp = function();
    if (typeof(T) == typeof(List<int>))
    {
        List<int> list = (List<int>)temp;
        if (x < list.Count) return list[x].ToString();
    }
    if (typeof(T) == typeof(int[]))
    {
        int[] array = (int[])temp;
        if (x < array.Length) return array[x].ToString();
    }
    if (typeof(T) == typeof(List<string>))
    {
        List<string> list = (List<string>)temp;
        if (x < list.Count) return list[x];
    }
    if (typeof(T) == typeof(string[]))
    {
        string[] array = (string[])temp;
        if (x < array.Length) return array[x];
    }
    return "";
}
....


////

That completes our discussion of the console applications for ten-pin and tennis. The full project code can be viewed or downloaded here:

https://github.com/johnspray74/GameScoring[GameScoring code]

