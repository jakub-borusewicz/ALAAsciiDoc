= Abstraction Layered Architecture
:doctype: article
:encoding: utf-8
:lang: en
:toc: left
:sectnums:
:imagesdir: images
:source-highlighter: highlightjs
:highlightjs-theme: Docco

//:stylesheet: asciidoctor-default.css
//:stylesdir:

[big]*Engineering the structure of software*




image::BOSS_Great_Wall.jpg[BOSS_Great_Wall.jpg,900, title="*The large scale structure of the universe - what should the large-scale structure be for a software application?*"]




// blame J R Spray

John R Spray

Last update: 2021-05-13

---

[big]#*A quick summary*#


Fundamentally, ALA is simply two architectural constraints:


* The only relationship allowed is a dependency on an abstraction. (That abstraction must be significantly more abstract than the abstraction containing the dependency.)

* All abstractions must be small - e.g. 100-500 LOC (or diagram nodes).


*Comments:*

No other relationships are allowed (or needed). This implies that the only unit of code in ALA is an abstraction. The term 'module' is not used because modules tend to collaborate (are loosely coupled). The term "abstraction" is used instead because abstractions are zero-coupled with one another. The dependency is always said to use an instance of the abstraction. Module dependencies tend to also have coupling.

Because an abstraction that is depended on must be significantly more abstract, the first structural property that emerges from the these constraints is that abstractions form into layers. These layers are not the same as the layers found in a conventional layered architecture because the dependencies themselves are different. We give them names that reflect the types of abstractions that tend to go in them like "Application" layer, "Domain abstractions" layer and "Programming paradigms" layer. A small number of other layers are sometimes used for large applications.

There is no 'hierarchical' structure in ALA. Abstractions cannot be contained within abstractions. We use the layers instead because lower layer abstractions, being more abstract, are more reusable, and need to be public for use, not private for hiding. In other words all 'information hiding' is achieved through abstraction, not just encapsulation.

These constraints may seem extreme at first, but it turns out to be surprisingly easy, and rewarding, to write code that conforms to them once the patterns are established. 

Patterns and properties emerge from these two constraints. In many ways the patterns are similar to ones we already know, which is not surprising - such things as Domain Specific Languages, Dependency Injection, Composite and Decorator patterns etc. However, there are often subtle but important differences. For example, in the Observer pattern (publish subscribe), the observer cannot do the subscribing itself if it is in the same layer as the publisher - a higher layer abstraction must do the subscribing for it. 

An emergent property is "zero coupling and high cohesion". This is qualitatively different from the familiar "loose coupling and high cohesion". What was implicit collaboration between modules in conventional code becomes explicit cohesive code contained within a more specific abstraction in a higher layer in ALA.

---


*A tiny example*

(Every chapter has an example, and we do the same here in the summary section. Unlike most pedagogical sized examples, these examples progressively become non-trivial. Yet because of ALA's power, they remain uncomplicated and easy to understand.) 

Requirement: Make a switch control a light. 


[plantuml,file="diagram-switch-light.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="1!"
graph [rankdir=LR]
node [shape=Mrecord]
Switch -> Light
}
@enddot
----

In ALA, the diagram above is not a high-level architectural view of the solution. It is the solution. The diagram is literally compiled. Let's do that now by hand:

*Application layer*

.Application.cs
[source,C#]
....
var application = new Switch().WireTo(new Light());
application.Run();
....

It is not difficult to make that code execute.

In conventional modular code, we would likely have made two modules, one for the switch and one for the light. The switch might directly call a method in the light, or vice versa. In ALA you can't do that. The concepts of Switch and Light, already handed to us as abstractions in the words of the requirements, must remain abstractions. They become domain abstractions and are placed in a domain abstractions layer and folder. They cannot know about each other, nor the applications they are used by.

The application is also an abstraction. It is more specific than the domain abstractions, and its purpose is to know about the system, comprising a light and a switch connected together. It knows about switches and lights as abstract concepts and that they may be wired together but doesn't know anything about implementation details of them. It is simply a direct formal restatement of the requirements. So for this example the application abstraction is the simple diagram shown above. 

The switch and the light can be handed off to different teams. They know nothing about each other. They do know about an even more abstract concept of data-flow, which lives in the programming paradigms layer below.

Here is skeleton code of the two domain abstractions showing how 'ports' might be implemented. 


*Domain Abstractions layer*


.Switch.cs
[source,C#]
....

// domain abstraction
class Switch
{
    // port 1: output
    private IDataFlow<bool> output;
    
    // called from internally when detect hardware change
    private void SwitchChange(bool newState) { output.Send(newState); }
    
}
....



.Light.cs
[source,C#]
....

// domain abstraction
class Light : IDataFlow<bool>
{
    // port 1: input
    IDataFlow<bool>.Send(bool data)
    {
        if (data) // turn on the light
        else // turn off the light
    }
}
....


Our programming paradigms layer has a programming paradigm for data-flow:


*Programming Paradigms layer*


.DataFlow.cs
[source,C#]
....

// Programming paradigm: DataFlow
interface IDataFlow<T>
{
    void Send(T data);
}
....


In ALA, we frequently use a *Wiring pattern*, which consists of instantiating domain abstractions and wiring them together by ports that use an even more abstract interface representing a programming paradigm. The wiring pattern is quite ubiquitous, and therefore comes from a Libraries layer that resides below the Programming Paradigms layer. That is where the WireTo operator resides. 


*Libraries layer*


.Wiring.cs
[source,C#]
// library
....

public static object WireTo(this object a, object b)
{
    // using reflection:
    // 1. Find a private field in object "a" that matches in type an interface implemented by object "b".
    // 2. Assign object "b" to that field.
    // 3. Return object "a".
}
....

Note: You can get the source for the WireTo extension method from one of the example projects of later chapters on GitHub.

Now that we know how to express requirements by composition of domain abstractions, let's quickly demonstrate the ease of maintenance of our application:

Requirement: Turn on a light when both the switch is on and a sensor says it is dark. And give a feedback indication:

(For these small examples, we will manually generate code from the diagram.)


[plantuml,file="diagram-switch-light-sensor.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="2"
graph [rankdir=LR]
node [shape=Mrecord]
AndGate [label="AndGate"]
Main -> Switch
Main -> Sensor
Sensor [label="<f0> Sensor|<f1> 0.5"]
Switch -> AndGate -> Light
Sensor -> AndGate -> Indicator
}
@enddot
----



.Application.cs
[source,C#]
....

var andGate = new AndGate();
new Main
    .WireTo(new Switch()
        .WireTo(andGate
            .WireTo(new Light())
            .WireTo(new Indicator())))
    .WireTo(new Sensor(threshold:0.5)
        .WireTo(andGate))
    .Run();
....


We just invented some new domain abstractions: AndGate and Sensor, again directly implied by the requirements.

We also just invented another programming paradigm. It is used between Main and its children, and could be made to work say by polling:

.Poll.cs
[source,C#]
....

// Programming paradigm: Poll
interface IPoll
{
    void Poll();
}
....

The astute reader will notice that the AndGate can't implement IDataFlow<bool> twice. In later projects, we will show how we solve this implementation problem, and we can allow more than one input port of the same type.

You may also notice that the fanout from the output of the AndGate to both the Light and the Indicator won't work. We show how this implementation problem can be solved in later projects also.

Now that we have some reusable domain abstractions and programming paradigms, let's quickly write another trivial application:


Requirement: Turn on the light from a tick item in the Tools menu of a PC application, and give an indication in the status bar when the light is on.



[plantuml,file="diagram-menu-light-status.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="3"
graph [rankdir=LR]
node [shape=Mrecord]
MainWindow -> Menu1 -> Menu2 -> TickBox -> Light
Indicator [label="<f0> Indicator|<f1> Light is Off | Light is On"]
Menu1 [label="<f0> Menu"]
Menu2 [label="<f0> Menu|<f1> Tools"]
TickBox [label="<f0> TickBox|<f1> Light"]
TickBox -> Indicator
MainWindow -> StatusLine -> Indicator
{rank=same Menu1 StatusLine}}
@enddot
----


.Application.cs
[source,C#]
....

var indicator = new Indicator( {"Light is off", "Light is On"} );
new MainWindow()
    .WireTo(new Menu())
        .WireTo(new Menu("Tools")
            .WireTo(new TickBox(label:"Light")
                .WireTo(new Light())
                .WireTo(indicator)
            )
        )
    )
    .WireTo(new StatusBar()
        .WireTo(indicator) // put the indicator on the UI
    )
    .Run();
....

We just invented another programming paradigm for "UI layout". It is used between all the UI elements: MainWindow, Menu, Tickbox, StatusBar, Indicator. Wiring things together using that programming paradigm means things are arranged inside things on the UI.

Let's do an application to browse for and display a (dynamic content) CSV file on a grid, filtered by a user specified name, and sorted by names. The CSV file has headings that will display in the grid.



[plantuml,file="diagram-csv-to-grid.png"]
----
@startdot
digraph foo {
size="5"
graph [rankdir=LR]
node [shape=Mrecord]
MainWindow -> Menu1 -> Menu2 -> MenuItem -> Browser -> CsvReadWriter -> Filter -> Sort -> Grid
Menu1 [label="<f0> Menu"]
Menu2 [label="<f0> Menu|<f1> File"]
MenuItem [label="<f0> MenuItem|<f1> Open"]
TextBox [label="<f0> TextBox|<f1> Label = Filter by name"]
Filter [label="<f0> Filter|<f1> Column = Name"]
Sort [label="<f0> Sort|<f1> Column = Name"]
Browser [label="<f0> OpenFileBrowser|<f1> extensions=CSV" ]
MainWindow -> TextBox -> Filter
MainWindow -> Grid 
{rank=same Menu1 TextBox Grid}}
@enddot
----


.Application.cs
[source,C#]
....

var grid = new Grid();
var csvReaderWriter = new CsvReaderWriter
var filter = new Filter() {Column = "Name"};
new MainWindow()
    .WireTo(new Menu()
        .WireIn(new Menu("File"))
        .WireIn(new MenuItem("Open"))
        .WireIn(new OpenFileBrowser(extensions = {"csv"} ))
        .WireIn(csvReaderWriter)
        .WireIn(filter) 
        .WireIn(new Sort() { Column="Name" })
        .WireIn(grid) { Column="Name" }
    )
    .WireTo(new TextBox(Label="Filter by name")
        .WireTo(filter)
    )
    .WireTo(grid)
    .Run();
....


Because they are zero-coupled, the domain abstractions are easy to write. The Grid abstraction is able to pull rows of data from a table as needed.

In addition to the new domain abstractions, we have two new programming paradigms, which we can call Events and PullTable.

Note: WireTo() returns its first operand (this). WireIn() is the same as WireTo() except that it returns its second operand. These operators support the fluent coding style being used in these small applications.

The methodology is that you write the application code first (or part of it), just focusing on expressing the requirements in a near 1 to 1 fashion. This causes you to invent domain abstractions and programming paradigms. Then you come up with a way to make the programming paradigms execute. Our experience so far is that this has never been difficult. For example, the two interfaces listed below might be what you would come up with for Event and PullTable. We then expect grid to have a field of type IPullTable<List<string>> and CsvFileReaderWriter to implement it. This interface is abstract. Both Filter and Sort will also have both input and output ports of type  IPullTable<List<string>>. The List represents one row of the table.

.Event.cs
[source,C#]
....
// Programming paradigm: Event driven
interface IEvent
{
    void Execute();
}
....



.PullTable.cs
[source,C#]
....
// Programming paradigm: TableDataFlow
interface IPullTable<T>
{
    event DataReadyDelegate SourceReady;
    List<string> GetHeaderLabels();
    IEnumerable<T> GetIEnumerable<T>();
}
....





Don't worry, we won't be creating new programming paradigm abstractions at this rate for long. In fact we already have most of the ones we will ever use in all our example projects.

Notice how in the above examples, we have used software engineering patterns we already know about, just in a different way. There is DSL (Domain Specific Language), Dependency Injection, Event driven programming, XAML-like UI layout (without the XML), RX (Reactive programming), monad-like wiring up of objects, fluent style. 

Notice how the application diagram in each case is both a direct representation of the requirements and executable. The requirements themselves are cohesive, and so the application code that expresses them should also be cohesive. We do not try to separate UI, I/O, business logic, persistent data etc because they are highly cohesive in the requirements. Most other architectural patterns do separate in this way, which creates coupling. Instead we reduce the problem in a different way - through the use of domain abstractions. All knowledge and details from the requirements ends up in the application layer, but that's all that ends up in there. All implementation is inside domain abstractions.

Note: Although the fluent style is nice for these small applications, code like this with indenting and nested brackets does not scale up well for large applications. (It is still much better than the tangled web of dependencies they would form in conventional modular code though.) But we can do better. We will not be hand-writing code like this for large applications - we will automatically generate the code from the diagrams. A network-like structure is showing up in these small applications because the requirements contain a network of connections. ALA embraces this and makes it explicit.

Note: The Wiring pattern used in the examples above is only one possible way of meeting the fundamental ALA constraints. For example, ALA can also be applied to functional programming. Indeed monads use a comparable wiring pattern. But we will use the wiring pattern shown above quite often. ALA may appear to be synonymous with this wiring pattern, but actually ALA is just the two fundamental constraints stated at the beginning of this introduction. 



---

[big]#*Chapter summaries*#

{empty} +

*Chapter 1, "What problem does ALA solve?"*

The two constraints solve the "big ball of mud" problem by providing a pre-worked reference architecture (a meta-structure for code at the largest granularity scale). 

The meta-structure pre-solves for the following quality attributes:

* Complexity
* Readability
* Maintainability
* Testability


{empty} +

*Chapter 2, "What does the structure look like?"*

Without explaining why, this chapter describes the code structure that emerges from applying the two constraints:

* An abstraction is usually a function or class, but can be a small group of functions, classes, delegates, enums, even variables or objects, etc. The grouping is highly cohesive code that is unrestricted in its internal relationships. An abstraction is usually represented by a source file.

* A small number of discrete abstraction layers emerge. The layers are given the standard names: Application, Domain abstractions, Programming Paradigms, and Libraries, from top to bottom. Folders are used for these layers. Dependencies only go down the layers, not across.

** Application layer

*** All the application layer does is compose instances of the domain abstractions, connect them together in an arrangement and configure each instance with any application specific details.  

*** An emergent property is that the top layer code is a direct expression of requirements. All knowledge specific to the application ends up in the application layer. It is typically around 2% of the total code. 

*** Like a DSL (Domain Specific Language), this direct expression of requirements in the Application layer is executable.

*** An ALA application (top layer) is three things in one: The expression of requirements, the architecture documentation, and the executable.

*** Execution typically occurs in two phases, (similar to monads). In the first phase the application wires together instances of abstractions. In the second phase the network of instances executes. 

** Domain abstractions layer

*** All knowledge for how to actually do anything goes in the Domain abstractions layer. These are reusable in the domain, both within a single application and by other applications.

*** Conventional libraries generally contain good abstractions, not necessarily because their designers set out to create good abstractions, but because they couldn't know anything specific about the code that will use them. So it was not possible for the classes to be specific to anything. ALA asks us to do that for one more layer before we write the application. We call that layer the domain abstractions layer.

*** The use of ports emerges.  A domain abstraction is often implemented as a class with ports. Ports are implemented using plain code. A port is nothing more than a field of a type of an interface from the programming paradigms layer, or an implemtation of such an interface. 

** Programming paradigms layer

*** Domain abstractions know nothing about each other at design-time, yet communication must occur between the instances at run-time. We don't really want the application to directly handle this run-time communication or its data. So we insert a layer below the Domain abstractions called Programming paradigms. This layer allows instances of domain abstractions to communicate directly at run-time (like dependency injection but without dependencies on specific interfaces). 

*** The Programming paradigms layer typically provides a small set of abstract interfaces, each having a separate meaning, for connections between instances of Domain abstractions (polyglot programming paradigms). Examples might be Data-flow, UI Layout, UI navigation flow, Event driven, State machine, Data schema. 

*** Programming paradigms are often implemented just by a simple interface. An example is "Event driven". The corresponding interface might be "interface IEvent { void Execute(); }".


*** Programming paradigms control the way the application actually executes.

*** Programming paradigms provide the grammar for the way instances of domain abstractions can be composed by the application.


** Libraries layer

*** The Libraries layer contains any very general code used to support ALA programs.

*** A common pattern I use is a WireTo() extension method in the libraries layer. The application layer uses it to wire together instances of Domain Abstractions by its ports. e.g. "new A().WireTo(new B());"



* The emergent use of diagrams to describe the instantiation, configuration and wiring of abstractions. Code is auto-generated from the diagram. 

* If the Application becomes large, we can insert a layer called Story Abstrations above the Domain Abstraction layer. It provides abstractions to support separate diagrams for features in the application layer. This supports a plug-in architectural style. For example, the Story Abstractions layer could have an abstraction that is an object "TheMainMenu". Different features can plug heir menus items into it.

* The ALA "composition of instances of abstractions" structure is analogous to real world composition structures such as Lego, electronic schematics, and molecules. 

{empty} +

*Chapter 3, "Why the structure works"*

Explains the theory behind the two fundamental architectural constraints:

* While an increasing number of internal validation experiments show promising results, the claim that ALA pre-solves for the software engineering problems outlined in chapter 1 is based largely on theory.

* In the field of structural engineering, a bridge is designed using theory. The theory gives us confidence that, once built, the bridge will stand. Similarly ALA uses theory to design a software structure. This gives us confidence that, once built, it will stand up to long term maintenance, be readable and testable, and have a controlled level of complexity. The following points describe this theoretical basis.

* Fundamental basis in abstraction

** We distinguish between compile-time and design-time (code-reading-time). One is when the compiler is reading the code, and the other is when the human brain is reading the code.

** Chapter 6 defines 'abstraction', and some of the overloaded meanings the word has in the software industry that cause confusion. For now we can just know that ALA code units are called abstractions (rather than classes, functions, modules, or interfaces) because an abstraction has properties at design-time which the language (compile-time) code units don't necessarily have. However, an abstraction will still usually be implemented using classes, functions or interfaces.

** By using abstractions as its unit of code, ALA shifts the idea of 'information hiding' from compile-time to design-time and from 'information hiding' from the compiler to 'knowledge hiding' from our brain.

** Consider the abstraction, SquareRoot. We can have two pieces of code: code that uses Squareroot and code that implements SquareRoot. The abstraction itself is just a concept. The two sections of code are both dependent only on this concept. At design-time they are as decoupled as the concept is stable. It's a very stable concept because it hasn't changed in thousands of years. So the two sections of code are essentially zero-coupled at design-time. Abstraction is the only mechanism we know of that has this property at design-time.

** Use of abstractions in software engineering is obviously not novel. ALA is a constraint that the only relationship allowed is a dependency on an abstraction (that is more abstract than the abstraction using it). Most conventional code is full of other types of relationships.

** ALA is therefore inherently zero-coupled (depending only on the quality of the abstractions). So ALA is said to have "Zero coupling and high cohesion", not "loose coupling and high cohesion".


* Collaboration

** In conventional code based on classes, functions, modules or interfaces, we rely heavily on compile-time encapsulation. Compile-time encapsulation is not sufficient to hide knowledge. It is entirely possible for code encapsulated inside two modules to be collaborating to achieve a higher purpose, such as a user story.

** Abstractions do not collaborate. The code that implements an abstraction does not collaborate with any other code - it just implements the abstraction. To change conventional modules to ALA we would do the following transformation. To the extent that conventional modules are collaborating to implement a feature, that knowledge is moved to a higher (more specific) abstraction that represents the feature and contains all that collaboration knowledge. There, the collaboration is expressed without coupling between multiple code units, is expressed explicitly, and is cohesive. The code left behind in the modules must be more abstract. They lose all mutual coupling and they become reusable.


* Complexity

** Zero coupling, together with limited abstraction size, keeps complexity level a constant. Most complexity models have complexity increasing at least in proportion to program size, and sometimes worse like L^m where L is program size and m is a factor such as 1.1.


* Dependencies

** Conventional code typically contains both good and bad dependencies. Good dependencies are the ones that are on abstractions, such as Squareroot function or instantiating a Filter class. Bad dependencies are all the others. There are at least two common types of bad dependencies: 1) dependencies that facilitate communication from one part of a system to another at run-time. 2) dependencies that decompose a large component into smaller (but more specialized) pieces. ALA eliminates all these bad dependencies.

** Good and bad dependencies look syntactically the same in code. They are usually function calls, method calls or the 'new' keyword. So distinguishing between good and bad dependencies is not done at the code level, but at a higher level of code structure.

** Dependencies in conventional code that facilitate communication between parts of a program become wirings between instances of abstractions in ALA. These wirings appear as normal lines of code inside another abstraction in a higher layer, where they are not dependencies.  

** Dependencies from decomposing a larger module into more specific pieces in conventional code are also eliminated using abstractions. Conventional architectural design uses a 'decomposition' based methodology. For example, it is common to separate a feature into UI and business logic, neither of which is an abstraction relative to the feature, but a specialized piece of the feature. Such decomposition tends results in coupling. Decomposition methodology has too much flexibility to break modules up in arbitrary ways. ALA first encourages us to not decompose at all, and instead uses a purely 'composition' methodology - compose from a set of abstractions that you invent. If an abstraction does become too large, we either factor out an abstraction or break into pieces that must be themselves abstractions (zero coupled with one another).  

* Gap between requirements and implementation

** ALA puts all code that has knowledge of the specific requirements in the top layer. But only code that carries details of requirements is put in the top layer. Our experience is that this constitutes around 10% of the total code making up an application. So, once the set of domain abstractions is complete, changes to requirements are generally confined to this 10% of code in the top layer.

** Because the job of the top layer is just to express requirements, the gap between stated requirements and their implementation is small. There is usually a much more direct relationship between the requirements expressed in natural language and the requirements expressed as a simple composition of instances of abstractions.

* Diagrams

** Requirements typically contain relationships that form a graph structure (a network). In conventional software, this network of relationships is distributed in the implementation code. This makes the graph itself quite obfuscated. Furthermore, we try to eliminate circular dependencies, which makes the graph even more obfuscated. ALA makes these graph structures explicit. Preferably they become diagrams. The graphs go inside their own abstractions in the top layer.


* Refactoring

** Software failure points are well understood. In addition to the quality attributes, complexity, readability, maintainability, testability, we often identify sub-causes such as coupling, dependencies, unstable classes or interfaces, circular dependencies, the large semantic gap between requirements and code, lack of reuse, syntactic noise, indirection, and the like. (Indirection appears as the common difficulty of tracing though a program that uses dynamic connections, such as the observer pattern.) The problem is we find them difficult to manage when we are also concentrating on getting things working, and doing that under a deadline. 

** Conventional development therefore usually involves two phases. In the first you concentrate on functionality. Then once you have that, you turn your attention to all these other quality attributes, and use refactoring to try to improve them. This refactoring is an ad-hoc process that really only works at a fine grained level. ALA takes a different approach. It starts with a meta-architecture that already takes care of all these quality attributes. You usually don't have to refactor unless you have broken the ALA constraints. The trade-off is that you have to spend some time to work out what the Domain Abstractions and Proramming Paradigms should be. Sometimes this is hard, especially in a new domain.  

Actually, in practice we do some refactoring. We find ourselves improving the description of an abstraction. This description pops up as a tooltip when we hover over an instance on an application diagram. This is especially true when a new person on the team is reading the diagram and needs to understand the domain abstractions without goin to their documenation comments. We also often rename the ports on abstractions so that the external point of view of an instance is easier to understand.


{empty} +

*Chapter 4, "Execution models".*

Explains how the underlying execution for each programming paradigm can be made to actually work.

** Explains the ways that the CPU executes the right code at the right time when the structures that emerge from ALA compose domain abstractions in a different or more declarative way compared to imperative execution flow.

** UI layout

** UI Navigation

** Dataflow

** Event driven

** Real world time activity flow

** Data schema



{empty} +

*Chapter 5, "Methodology"*

Describes ALA in terms of how it fits into Agile software development.

** The primary methodology is that requirements are simply 'described' in terms of 'invented' domain abstractions.

** An "Iteration zero" is used, important to get a starting set of domain abstractions and programming paradigms. The starting set will set the pattern of the whole design.

** How to go about 'inventing' domain abstraction for the first time in a new domain.


{empty} +

*Chapter 6, "The philosophy behind ALA"*

Gives the theory of why ALA works from the perspective of complex systems and how our brains work.

** Describes how the two fundamental architectural constraints are designed to mimic how our brains see the real world.

* Abstractions are learnable, stable and reusable.

** Learnable: In ALA, any code can be read as a stand-alone unit once the dependent abstractions have been learned. For example, we can read code that has a dependency on squareroot because we have learned what the squareroot abstraction is. We don't need to go and read the squareroot code. ALA constrains us to make ALL dependencies work this way.

** Stable: In ALA, all dependencies are on stable concepts. Not stable code, stable concepts, such as the concept of squareroot or the concept of events. Since stable concepts don't change, the dependent code is protected from ripple effects. The stability of the concept of an abstraction is unrelated to the code that implements an abstraction. For example, the concept of squareroot has been stable now for thousands of years.

** Reusable: As Charles Krueger has pointed out, abstraction and reuse are two sides of the same coin. By constraining dependencies to be on abstractions, we then find these abstractions being reused, which creates more dependencies on them (a good thing), which helps us consolidate them as abstractions.  

* An abstraction provides our brain a way to reason about all possible instances at once. The details of any given instance is hidden, . 



** Composition of a small number of abstraction layers in the real world as an analogy: e.g. atoms, molecules, proteins, cells, bodies.

** ALA leverages how our brains have evolved to use abstractions to understand the real world. This enables us to understand our programs in the same way.

** ALA achieves an optimal level of expressiveness in each layer. This includes the application layer which is just a formal expression of requirements in their details, but nothing else. 

** ALA uses layers instead of encapsulation hierarchies. We want public abstractions for maximal reuse, not private specialized parts for a specialized use.

** ALA does not use 'models' for its structure or architecture. Models, as the term implies, can leave out details arbitrarily. These details are unknowns and will come back to bite us. ALA only leaves out details by putting them inside abstractions, which renders them harmless. (Models differ from diagrams, which ALA can use.)



{empty} +

*Chapter 7, "ALA compared with...".*

** Unsurprisingly, the two fundamental constraints of ALA emerge most architectural styles and patterns that we already use in software engineering. 

** ALA makes use of them simultaneously.

** Interestingly, most of the patterns appear in a modified form. 

** Examples are: Layers, Dependency injection, Observer pattern, DSLs, Pipes and Filters, Components and connectors, Monads.

** Very surprisingly, some patterns are odds with ALA. Examples are MVC and UI/Businesslogic/Database tiers. And says the UML class diagrams are completely evil. 

** It is interesting to compare and/or contrast ALA with all these conventional engineering styles and patterns. 

{empty} +


This web site is a work in progress. ALA is a research in progress. Please don't hesitate to provide feedback to the e-nail address given at the end.

I would like to acknowledge the help of Roopak Sinha at AUT (Auckland University of Technology) in the writing of the paper for ECSA 2018 and  his academic perspective. 

// for web site

link:Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]

// for pdf

// https://AbstractionLayeredArchitecture.com/Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]



include::ChapterOne.adoc[]

include::ChapterTwo.adoc[]

include::ChapterThree.adoc[]

include::ChapterFour.adoc[]

include::ChapterFive.adoc[]

include::ChapterSix.adoc[]

include::ChapterSeven.adoc[]

include::ChapterEight.adoc[]





== Feedback

Any feedback about this article is welcomed. Please send to johnspray274<at>gmail<dot>com

