= Abstraction Layered Architecture
:doctype: article
:encoding: utf-8
:lang: en
:toc: left
:imagesdir: images
:source-highlighter: highlightjs
:highlightjs-theme: Docco

//:stylesheet: asciidoctor-default.css
//:stylesdir:

[big]*Engineering the large-scale structure of software*




image::BOSS_Great_Wall.jpg[BOSS_Great_Wall.jpg,900, title="*The large scale structure of the universe - what should it be for software?*"]




// blame J R Spray

John R Spray

Last update: 2021-08-15

Feedback is welcome. Please send to johnspray274<at>gmail<dot>com

---

// [big]#*A quick summary*#

= A quick summary

Intuitively, good quality software would allow you to read and understand any one part of the code without also having to read and understand any other part. I call this zero coupling. We are taught to aim for loose coupling. It is said that a zero coupled system would not do anything. But this is only because we confuse design-time coupling with run-time communications. It is entirely possible for parts of a system to have zero knowledge about one another and still communicate. We therefore define the word _coupling_ to mean design-time coupling for this article. By design-time, we mean any time you are reading, writing or understanding code. ALA is a set of three  architectural constraints to achieve zero coupling. Here they are:

* The only unit of code is an abstraction.

* The only relationship allowed is a dependency on an abstraction that is significantly more abstract.

* All abstractions must be small - e.g. less then about 500 LOC.

Many patterns and properties emerge from these three constraints. These are discussed throughout this article. 


[big]#*The only unit of code is an abstraction*#

Abstractions are fundamental to the constraints. When we use an abstraction, for example, when a function that calculates standard deviation uses a function that calculates squareroot, the coupling is only on the concept of squareroot. As a concept, squareroot has been stable for thousands of years. There is zero coupling between the code that _implements_ standard deviation and the code that _implements_ squareroot.

For this to work, the abstraction being used must be more abstract than the one whose implementation code uses it. If the code implementing sqaureroot were to, say, output the result to a display, it would destroy both abstractions. Both functions would just be specific parts of a specific system.

Instead, a more specific abstraction is required to represent the system itself. This abstraction would call the standard deviation function and then call the display function. Better still, standard deviation and display would be classes with I/O ports. Instances of them would be wired together by the system abstraction. While the instances can communicate at run-time, the abstractions know nothing about each other. 

This first constraint means that the ALA equivalent of a _module_ is an _abstraction_. The distinction is crucial. Modules that are not good abstractions only provide encapsulation. The term _encapsulation_ only means hiding details at compile-time. Abstractions work in the brain. Only abstractions hide details at design-time. 

The distinction between design-time vs compile-time or run-time is critical. In ALA instances of abstractions at a similar abstraction level may communicate at run-time without their corresponding abstractions knowing anything of each other at design-time.

In conventional code, modules, components and classes tend to implicitly collaborate with one another to form a use case, user story, or system. They are like jigsaw pieces, very specific pieces that fit together in a specific way to make a specific picture. Abstractions are like lego pieces. Very general pieces can be composed in an infinite variety of ways, any one of which is a design in itself that makes a specific thing. 

Association relationships in the UML class diagram cause classes to collaborate like jigsaw pieces. The use of an interface doesn't change this if the interface is specific to one of the classes involved. In ALA, more abstract interfaces that don't belong to the classes are used instead.

What is collaboration between classes, modules or components of a system in conventional code becomes explicit code inside a new abstraction in a higher, system level layer in ALA.

Abstractions do design-time _information hiding_. David Parnas' intended that information hiding was at design-time. (Unfortunately there is a popular meme that _information hiding_ means _encapsulation_.) Basically the same idea has other names such as Alistair Cockburn's protected variations, and Robert Martin's version of the OCP (open closed principle). Abstraction is the only mechanism that achieves it. 

In the absence of direct computer language support for abstractions, ALA generally implements  abstractions as source files (like modules in C). The file often contains one class or function, but may contain a small number of classes, interfaces, enums, delegates, typedefs, functions, etc.

There are no dependencies rules, or any organisational rules, imposed by ALA inside an abstraction. It is all considered cohesive code. Internally, abstractions can be small balls of mud.

Unfortunately, there are now two distinct meanings for the meme 'higher level of abstraction' in common usage in software engineering. We need to take a moment to understand the difference. In ALA, abstraction means the original dictionary meaning:

Etymology: abstract literally means _draw away_ [a common idea or concept from specific examples]

Miriam Webster: relating to or involving general ideas or qualities rather than specific people, objects or actions.

Charles Krueger pointed out that _abstraction_ and _reuse_ are two sides of the same coin. More abstract means more reusable. More abstract also tends to mean more stable because a more abstract idea is drawn from more examples, and is therefore a more ubiquitous more fundamental idea. The abstraction 'squareroot' is very stable despite the fact that new instances of its use occur frequently.

The other meaning of 'higher level of abstraction' used in the software engineering community appears to be 'further away from the domain of the computer and closer to the problem domain'. For example, layers are often shown building up from the hardware. They can also build up from the database, or a physical communication medium. The application is considered the most abstract. For example, a 3-tier system or a communication stack uses this type of layering. The perception is that because we no longer have to deal with computer domain details such as data storage, communications protocols, hardware, etc, we must be more abstract. The problem with this is that the problem domain also deals with details. These details come from the real world and are described by detailed requirements. The modules that contain these details are no more abstract than those in the various domains of computing.

Conventional layering tends to use this second meaning of 'abstract'; layers are said to be more abstract as you go up. ALA layers use the original meaning of the word 'abstract'; layers get more abstract as you go down.

The layers are not the same either. To convert conventional layers to ALA, you generally just tip them on their side so that they are not layers but independent disconnected abstractions. Each of them knows about details of something but they no longer communicate directly with one another in either direction. On their own they will do nothing. Then the layer above, whose job is to know the details of a specific application or system, composes instances of them by instantiating them, configuring them, and wiring them together. Conventional layers can be many. ALA layers are few.

A final note about abstractions versus the SRP (single responsibility principle). The SRP is not really a suitable way to think about abstractions. It is better to think about what details an abstraction implementation knows about. It can be a specific user story, a specific feature, a type of UI element, a type of database, a protocol, a hardware device, etc. It will contain all the cohesive knowledge about that thing. In doing so, it may have multiple responsibilities. For example an abstraction that knows about a protocol should have responsibility for both input and output. 


[big]#*The only relationship is a dependency on a more abstract abstraction*#

The second constraint is that dependencies must be on abstractions that are significantly more abstract than the abstraction whose implementation contains the dependency.

In ALA, the word _dependency_ means something different to _coupling_. A dependency is on an abstraction, whereas coupling is about the code that implements the abstraction. A dependency on an abstraction means you must understand the concept the abstraction represents. You could not understand the code that calculates standard deviation without first understanding the concept of squareroot.   

Conventional code typically contains both good and bad dependencies. Normally we don't distinguish between them. Bad dependencies are on non-abstractions or abstraction at a similar abstraction level. Conventional code is typically full of them. They are used to implement all the communications. Bad dependencies cause coupling. Good dependencies don't.

Good dependencies are not just good - they are really good. We want as many of them as possible, because then we are reusing our abstractions. Bad dependencies are not just bad - they are really bad. They cause a growing tangled network of complexity. In ALA all bad dependencies are illegal. When removed, a bad dependency becomes a line of code. That line of code is contained inside an abstraction in a layer above. It connects two instances of abstractions. It is cohesive with other lines of code that connect instances of abstractions to make the system.

 When the idea that zero coupling could be achieved through the stated constraints first occurred to us, we did not know what it would be like, or even if it was possible, to create a working system. Our experience since then is that zero-coupling has always been possible, but coming up with the right abstractions is sometimes not obvious. Also, conventional habits, languages, patterns and architectural styles all conspire against you to break the constraints.
 
 
[big]#*Layers*# 

Because of the constraint that an abstraction that is depended on must be significantly more abstract, abstractions form layers. This gives the architecture its name: abstraction layered architecture. We give the layers names that reflect the types of abstractions that tend to go in them like _application layer_, _domain abstractions  layer_ and _programming paradigms layer_. A small number of other layers come into the picture as the application gets larger.

There is no 'hierarchical' structure in ALA. In other words, abstractions cannot be contained within abstractions. Layers replace hierarchical containment. This is because lower layer abstractions from which things are composed must be public for reuse, not hidden inside an encapsulation hierarchy. 

All UML relationships except one are illegal in ALA. And that one is restricted to being a composition on a more abstract class. Such a relationship is always represented in code by just referring to the abstraction by name. You do not drawing a line on a UML class diagram when using an abstraction. For example, you would never use a library abstraction such as _regex_ by drawing a line on a diagram to a box representing the regex class. You would just use the regex abstraction by name. Therefore if a UML diagram were drawn of an ALA application, there would be no lines at all, just boxes in space arranged in layers.

Finally dependencies on more abstract abstractions are dependencies on ideas or concepts. Concepts are things we can learn and retain. Once you know the set of concepts available in lower layers, it is easy to read and understand code in higher layers that uses them. A use of an abstraction is like any other line of code. We never have to follow the indirection and go and read the code that implements the abstraction. Just like when we see a use of squareroot, our brains can already have learned he concept of squareroot, and can just stay in the context of the code using it. In ALA we are achieving that for every single dependency on the program. 


[big]#*All abstractions must be small*#

The final constraints prevents us from conforming to the first two constraints by simply putting everything into one big abstraction. That's obviously not desirable, so we need this obviousl constraint to force the program us to create abstractions. 

Abstractions are internally cohesive, which means that all code inside them is related. Internally they are a small ball of mud. If all that inter-related code is to be understood, it needs to be small. 

A rule of thumb is around 200 to 500 lines of code. If the code is in diagram form (which will often be the case for reasons we will explain later), we should limit the size to 200-500 nodes and edges.

If abstractions contain more than 500 lines, it is getting too complicated for our brains to understand. If abstractions average less than 200 lines of code, we will have many of them. We will burden ourselves with an unecessarily high number of them to learn. The sweet spot is somewhere inbetween.

When ALA is first applied, we start with three layers - application, domain abstractions, and programming paradigms. We start with a single application abstraction in that top layer. Our experience is that that as the system grows, the application abstraction gets larger. This makes sense because the application layer is where requirements are expressed. Domain abstractions and programming paradigms are stable and so do not grow larger with overall program size. They may increase in number, but it is the application that will go over the 500 line limit.

When that happens, you have to apply the ALA constraints again, and find abstractions from which an application can be composed. Requirements usually already contain such abstractions in the form of features, use cases, or user stories. A new layer is introduced to contain these types of abstractions. The application then becomes a composition of these features. Features may have some communication going on between them at run-time. The application will wire them together. Also, a layer below the features which resembles a 'plug-in' architecture layer can be useful. It provides abstractions that the features can plug into, such as a main menu.

[big]#*Other emergent patterns*#

ALA emerges many other patterns and properties, many of which we already know about in software engineering, which is not surprising - such things as DSLs (Domain Specific Languages), Dependency Injection, Composite and Decorator patterns, etc. However, there are often subtle but important differences. For example the observer pattern (publish/subscribe) can be used to achieve calls going up layers at run-time, but may not be used within a layer. The subscribers's reference to the publisher within a layer would be an illegal dependency. 

Inheritance is not used in ALA. We only use composition because inheritance breaks abstractions.

---


*A tiny example*

 Every chapter has an example, and we do the same here in the summary section. Unlike most pedagogical sized examples, these examples progressively become non-trivial. Yet because of ALA's power, they remain uncomplicated and easy to understand.) 

Requirement: Make a switch control a light. 


[plantuml,file="diagram-switch-light.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="1!"
graph [rankdir=LR]
node [shape=Mrecord]
Switch -> Light
}
@enddot
----

The diagram above is not documentation. Nor is it a high-level architectural view of the solution. It is the solution. It contains all the detail needed for an executable application. The diagram is literally compiled. Let's do that now by hand:

*Application layer*

.System.cs
[source,C#]
....
var system = new Switch().WireTo(new Light());
system.Run();
....

It is not difficult for any programmer to write the necessary abstractions to make that code execute.

In conventional modular code, we would likely have made two modules, one for the switch and one for the light. The switch might directly call a method in the interface for the light, or vice versa. In ALA you can't do that. The concepts of Switch and Light, already handed to us as abstractions in the words of the requirements, must remain as abstractions. They can't know about or communicate with one another. They can't know about the system. That job belongs somewhere else. They are _domain_ abstractions and are placed in a domain abstractions layer and folder.

The _system_ is also an abstraction. It is more specific than the domain abstractions, and its purpose is to know about the specific system comprising a light and a switch connected together. It knows about Switches and Lights as abstract concepts and that they may be wired together but doesn't know anything about their implementation details. 

The diagram is a direct, formal restatement of the requirements. So the diagram is three things in one: The formal statement of requirements, the high level architecture, and the executable. One source of truth for all three. Conventional software engineering usually has three different documents for these which must be kept synced.  

When the program is this small, it looks like we just created three modules when two would have done. However, by creating an abstraction to represent the system level knowledge, we make several powerful improvements to the code that are important as the application scales:

. There is now an explicit place that cohesively implements the requirement instead of having the requirement implementation distributed in an obviscated way inside Switch and Light. What is loose coupling between modules in conventional code becomes cohesive code inside a higher (more specific) abstraction in ALA. Changes to the system are made in this one place.

. The code inside System, Switch and Light are zero-coupled with one another. 

. Being abstractions, Switch and Light are reusable. They are reusable in the same application or in other applications in the domain.

. Switch and Light are testable with unit tests.

. Testing the system is acceptance testing. In ALA, you always test with dependencies in place (but mock the ports). Just as you would not mock out a dependency such as on squareroot, you do not mock any dependencies in ALA. 

. The Switch and the Light can be handed off to different individuals or teams because the as abstractions they know nothing about each other, and they know nothing about the System. In fact abstractions will be better quality if the teams do not collaborate with each other on their implementations so that the abstractions themselves do not collaborate.

. Switch and Light both know about an even more abstract abstraction called data-flow. It lives in the layer below. We think of this abstraction as a programming paradigm. Programming paradigms provide the _meaning_ of connecting together two instances of domain abstractions. We can use multiple different programming paradigms in the one top level abstraction. ALA is said to be polyglot in programming paradigms. This makes it very expressive.

. In terms of methodology, instead of _decomposing_ the Switch-Light system into parts, we _composed_ it from abstractions. This point may seem subtle at first, but it is profoundly important. The method of dividing a system into smaller parts until the parts are small enough to implement is arguably the prevalent approach in traditional software engineering. However it tends to result in parts that are more specific than the system (can't be reused for anything).

Here is skeleton code of the two domain abstractions. 


*Domain abstractions layer*


.Switch.cs
[source,C#]
....

// domain abstraction
class Switch
{
    // port
    private IDataFlow<bool> output;
    
    // called from internal code (not shown) when it detects a hardware change
    private void SwitchChange(bool newState) { output.Send(newState); }
    
}
....



.Light.cs
[source,C#]
....

// domain abstraction
class Light : IDataFlow<bool>
{
    // port
    IDataFlow<bool>.Send(bool data)
    {
        if (data) // turn on the light
        else // turn off the light
    }
}
....


Each of these abstractions implements a _port_, which allows instances of them to be wired using the programming paradigm, _data-flow_.

Here is our programming paradigms layer which contains a programming paradigm for data-flow:


*Programming Paradigms layer*


.DataFlow.cs
[source,C#]
....

// Programming paradigm: DataFlow
interface IDataFlow<T>
{
    void Send(T data);
}
....


In ALA, we frequently use a *wiring pattern*, which consists of instantiating domain abstractions and wiring them together by ports that use an even more abstract interface representing a programming paradigm. The wiring pattern is quite ubiquitous, and therefore comes from a foundation layer that resides below the Programming Paradigms layer: 


*Foundation layer*


.Wiring.cs
[source,C#]
....

public static object WireTo(this object a, object b)
{
    // using reflection:
    // 1. Find a private field in object "a" that matches in type an interface implemented by object "b".
    // 2. Assign object "b" to that field.
    // 3. Return object "a".
}
....

Note: You can get the source for an example WireTo extension method from one of the example projects of later chapters on GitHub.

Now that we know how to express requirements by composition of domain abstractions, let's quickly demonstrate the ease of maintenance of our application:

Requirement: Add a sensor to turn on the light when the switch is on and it is dark. And give a feedback indication:

(For these small examples, we will manually generate code from the diagrams.)



[plantuml,file="diagram-switch-light-sensor.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="1.5"
graph [rankdir=LR]
node [shape=Mrecord]
AndGate [label="AndGate"]
Sensor [label="<f0> Sensor|<f1> 0.5"]
Switch -> AndGate -> Light
Sensor -> AndGate -> Indicator
}
@enddot
----


.Application.cs
[source,C#]
....

var andGate = new AndGate();
new Main
    .WireTo(new Switch()
        .WireTo(andGate
            .WireTo(new Light())
            .WireTo(new Indicator())))
    .WireTo(new Sensor(threshold:0.5)
        .WireTo(andGate))
    .Run();
....


We just invented some new domain abstractions: AndGate and Sensor, again directly implied by the requirements.

One of the domain abstraction instances has a configuration of 0.5. This is a threshold for expressing the requirement clause "is dark". 

Notice that this application is easier to write in this way than it would be in C code. This is because the programming paradigm we are using, data-flow, suits the expression of these requirements.

The astute reader will notice that the AndGate can't implement IDataFlow<bool> twice for its two inputs. In later projects, we will show how we work around this language constraint.

You may also notice that the fanout from the output of the AndGate to both the Light and the Indicator won't work. We show how this implementation problem can be solved in later projects as well.

Now that we have some reusable domain abstractions and programming paradigms, let's quickly write another trivial application:


Requirement: Turn on the light from a tick item in the Tools menu of a PC application, and give an indication in the status bar when the light is on.




[plantuml,file="diagram-menu-light-status.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="3"
graph [rankdir=LR]
node [shape=Mrecord]
MainWindow -> Menu1 -> Menu2 -> TickBox -> Light
Indicator [label="<f0> Indicator|<f1> Light is Off | Light is On"]
Menu1 [label="<f0> Menu"]
Menu2 [label="<f0> Menu|<f1> Tools"]
TickBox [label="<f0> TickBox|<f1> Light"]
TickBox -> Indicator
MainWindow -> StatusLine -> Indicator
{rank=same Menu1 StatusLine}}
@enddot
----

.Application.cs
[source,C#]
....

var indicator = new Indicator( {"Light is off", "Light is On"} );
new MainWindow()
    .WireTo(new Menu())
        .WireTo(new Menu("Tools")
            .WireTo(new TickBox(label:"Light")
                .WireTo(new Light())
                .WireTo(indicator)
            )
        )
    )
    .WireTo(new StatusBar()
        .WireTo(indicator) // put the indicator on the UI
    )
    .Run();
....

We just invented another programming paradigm for "UI layout". It is used between all the UI elements: MainWindow, Menu, Tickbox, StatusBar, Indicator. Wiring things together using that programming paradigm means things are arranged inside things on the UI.

Notice how ALA is polyglot in programming paradigms. We use UI layout and data-flow in the same diagram. Notice also that we don't separate UI from business logic and data models. These are highly cohesive things from the perspective of user stories. Instead we separate their implementations. It is still easy to swap out, for example, the UI implementation. The diagram above could be implemented as a web application or a desktop application by swapping between two sets of UI domain abstractions.  

Let's do an application to browse for and display a (dynamic content) CSV file on a grid, filtered by a user specified name, and sorted by names. The CSV file has headings that will display in the grid.



[plantuml,file="diagram-csv-to-grid.png"]
----
@startdot
digraph foo {
size="5"
graph [rankdir=LR]
node [shape=Mrecord]
MainWindow -> Menu1 -> Menu2 -> MenuItem -> Browser -> CsvReadWriter -> Filter -> Sort -> Grid
Menu1 [label="<f0> Menu"]
Menu2 [label="<f0> Menu|<f1> File"]
MenuItem [label="<f0> MenuItem|<f1> Open"]
TextBox [label="<f0> TextBox|<f1> Label = Filter by name"]
Filter [label="<f0> Filter|<f1> Column = Name"]
Sort [label="<f0> Sort|<f1> Column = Name"]
Browser [label="<f0> OpenFileBrowser|<f1> extensions=CSV" ]
MainWindow -> TextBox -> Filter
MainWindow -> Grid 
{rank=same Menu1 TextBox Grid}}
@enddot
----

The wiring between the CSVReadWriter, Filter, Sort and Grid uses a new programming paradigm alloes dynamic row and columns of data to flow.  The Grid abstraction is able to pull rows of data.

The wiring between the MeniItem and the OpenFileBrowser is uses an Event-driven programming paradigm.


.Application.cs
[source,C#]
....
var grid = new Grid();
var csvReaderWriter = new CsvReaderWriter
var filter = new Filter() {Column = "Name"};
new MainWindow()
    .WireTo(new Menu()
        .WireIn(new Menu("File"))
        .WireIn(new MenuItem("Open"))
        .WireIn(new OpenFileBrowser(extensions = {"csv"} ))
        .WireIn(csvReaderWriter)
        .WireIn(filter) 
        .WireIn(new Sort() { Column="Name" })
        .WireIn(grid) { Column="Name" }
    )
    .WireTo(new TextBox(Label="Filter by name")
        .WireTo(filter)
    )
    .WireTo(grid)
    .Run();
....


Note: WireTo() returns its first operand (this). WireIn() is the same as WireTo() except that it returns its second operand. These operators support the fluent coding style being used in this hand compiled code so that we do't have to think of names for every instance of an abstraction.

Because they are zero-coupled, the domain abstractions themselves are easy to write.

The methodology we have been following is that you write the application code (diagram) first (or part of it), just focusing on expressing the requirements. This causes you to invent domain abstractions and programming paradigms. Then you come up with an interface or execution model that will make the programming paradigms execute. Our experience so far is that this has never been difficult. For example, the two interfaces listed below might be what you would come up with for Event and PullTable. 
.Event.cs
[source,C#]
....
// Programming paradigm: Event driven
interface IEvent
{
    void Execute();
}
....



.PullTable.cs
[source,C#]
....
// Programming paradigm: TableDataFlow
interface IPullTable<T>
{
    event DataReadyDelegate SourceReady;
    List<string> GetHeaderLabels();
    IEnumerable<T> GetIEnumerable<T>();
}
....


We then expect Grid to have a field of type IPullTable<List<string>> and CsvFileReaderWriter to implement it. This interface is abstract. Both Filter and Sort will also have both input and output ports of type  IPullTable<List<string>>. The List represents one row of the table. If the columns are known at compiletime, T can be a tuple.



Don't worry, we won't be creating new programming paradigm abstractions at this rate for long. In fact we already have most of the ones we will use in all our example projects.

Notice how in the above examples, we have used software engineering patterns we already know about, just in a different way. There is DSL (Domain Specific Language), Dependency Injection (which is what the WireTo operator does), Event driven programming, XAML-like UI layout (without the XML), RX (Reactive programming), monad-like wiring up of objects, and the fluent style. 

Notice how the application diagram in each case is both a direct representation of the requirements and executable. 
Application diagrams do not leave out details from requirements because ultimately they are a complete expression of them. Instead, they leave out details of implementation.

To the extent that the requirements are cohesive, so the code that expresses them should be. For example, we do not try to separate the specific UI, I/O, business logic, persistent data etc into different modules because they are highly cohesive for a given requirement. Most other architectural patterns do separate in this way, which creates coupling. Instead we reduce the problem in a different way - through the use of domain abstractions which provide reusable aspects of implementation. All knowledge and details from the requirements end up in the application layer, but that's all that goes there. 

Note: A network-like structure is showing up in these small applications because each requirement in itself contains a network of relationships. ALA embraces this and makes it explicit, which is why the requirements are best expressed as diagrams.

Although the fluent style is a nice way to hand-compile these small diagrams, code like this with indenting and nested brackets does not scale up well for large diagrams. (It is still better than the tangled web of dependencies they would form in conventional modular code though.) But we can do better. We will not be hand-writing code like this for large applications - we will automatically generate the code from the diagrams. 

Finally, the wiring pattern used in the examples above is only one possible way of meeting the fundamental ALA constraints. For example, ALA can also be applied to functional programming. Indeed monads use a comparable wiring pattern. But we will use the wiring pattern shown above in most of our examples. ALA may appear to be synonymous with this wiring pattern, but actually ALA is just the three fundamental constraints stated at the beginning of this introduction. 

---

////

[big]#*Chapter summaries*#

{empty} +

*Chapter 1, "What problem does ALA solve?"*

* The Big Ball of Mud

** The two constraints solve the "big ball of mud" problem by providing a pre-worked reference architecture (a meta-structure for code at the largest granularity scale). 

* Simplify down the overwhelming set of architectural styles, patterns, principles and paradigms

** ALA coherently combines a myriad of architectural styles, patterns, principles and paradigms

* An optimal reference architecture for quality attributes

** Complexity
** Readability
** Maintainability
** Testability

* The software engineer's trap

** Describes the Create, Repair, Abandon, rePeat cycle that ALA breaks.

* A short history of ALA

** How ALA was developed 

* An example

** This chapter concludes with an example that implements a thermometer. In this example, we start with typically written C code, and then refactor it step by step into ALA organised code.


{empty} +

*Chapter 2, "What does the structure look like?"*

Without explaining why, this chapter describes the code structure that emerges from applying the two fundamental ALA constraints:

* Units of code are abstractions

* ALA uses just one relationship type

** The code inside an abstraction may have a dependency on a more abstract abstraction. What to do instead for all other conventional relationship types is explained.

* Abstraction Layers

** Application layer

** Domain abstractions layer

** Programming paradigms layer

** Libraries layer

* Code organisation into folders

* How files, classes and interfaces are used

* Executable expression of requirements

* Composition not decomposition



* The emergent use of diagrams to describe the instantiation, configuration and wiring of abstractions. Code is auto-generated from the diagram. 

* If the Application becomes large, we can insert a layer called Story Abstrations above the Domain Abstraction layer. It provides abstractions to support separate diagrams for features in the application layer. This supports a plug-in architectural style. For example, the Story Abstractions layer could have an abstraction that is an object "TheMainMenu". Different features can plug heir menus items into it.

* Polyglot programming paradigms



* The ALA "composition of instances of abstractions" structure is analogous to real world composition structures such as Lego, electronic schematics, and molecules. 

{empty} +

*Chapter 3, "Why the structure works"*

Explains the theory behind the two fundamental architectural constraints:

* While an increasing number of internal validation experiments show promising results, the claim that ALA pre-solves for the software engineering problems outlined in chapter 1 is based largely on theory.

* In the field of structural engineering, a bridge is designed using theory. The theory gives us confidence that, once built, the bridge will stand. Similarly ALA uses theory to design a software structure. This gives us confidence that, once built, it will stand up to long term maintenance, be readable and testable, and have a controlled level of complexity. The following points describe this theoretical basis.

* Fundamental basis in abstraction

** We distinguish between compile-time and design-time (code-reading-time). One is when the compiler is reading the code, and the other is when the human brain is reading the code.

** Chapter 6 defines 'abstraction', and some of the overloaded meanings the word has in the software industry that cause confusion. For now we can just know that ALA code units are called abstractions (rather than classes, functions, modules, or interfaces) because an abstraction has properties at design-time which the language (compile-time) code units don't necessarily have. However, an abstraction will still usually be implemented using classes, functions or interfaces.

** By using abstractions as its unit of code, ALA shifts the idea of 'information hiding' from compile-time to design-time and from 'information hiding' from the compiler to 'knowledge hiding' from our brain.

** Consider the abstraction, SquareRoot. We can have two pieces of code: code that uses Squareroot and code that implements SquareRoot. The abstraction itself is just a concept. The two sections of code are both dependent only on this concept. At design-time they are as decoupled as the concept is stable. It's a very stable concept because it hasn't changed in thousands of years. So the two sections of code are essentially zero-coupled at design-time. Abstraction is the only mechanism we know of that has this property at design-time.

** Use of abstractions in software engineering is obviously not novel. ALA is a constraint that the only relationship allowed is a dependency on an abstraction (that is more abstract than the abstraction using it). Most conventional code is full of other types of relationships.

** ALA is therefore inherently zero-coupled (depending only on the quality of the abstractions). So ALA is said to have "Zero coupling and high cohesion", not "loose coupling and high cohesion".


* Collaboration

** In conventional code based on classes, functions, modules or interfaces, we rely heavily on compile-time encapsulation. Compile-time encapsulation is not sufficient to hide knowledge. It is entirely possible for code encapsulated inside two modules to be collaborating to achieve a higher purpose, such as a user story.

** Abstractions do not collaborate. The code that implements an abstraction does not collaborate with any other code - it just implements the abstraction. To change conventional modules to ALA we would do the following transformation. To the extent that conventional modules are collaborating to implement a feature, that knowledge is moved to a higher (more specific) abstraction that represents the feature and contains all that collaboration knowledge. There, the collaboration is expressed without coupling between multiple code units, is expressed explicitly, and is cohesive. The code left behind in the modules must be more abstract. They lose all mutual coupling and they become reusable.


* Complexity

** Zero coupling, together with limited abstraction size, keeps complexity level a constant. Most complexity models have complexity increasing at least in proportion to program size, and sometimes worse like L^m where L is program size and m is a factor such as 1.1.


* Dependencies

** Conventional code typically contains both good and bad dependencies. Good dependencies are the ones that are on abstractions, such as Squareroot function or instantiating a Filter class. Bad dependencies are all the others. There are at least two common types of bad dependencies: 1) dependencies that facilitate communication from one part of a system to another at run-time. 2) dependencies that decompose a large component into smaller (but more specialized) pieces. ALA eliminates all these bad dependencies.

** Good and bad dependencies look syntactically the same in code. They are usually function calls, method calls or the 'new' keyword. So distinguishing between good and bad dependencies is not done at the code level, but at a higher level of code structure.

** Dependencies in conventional code that facilitate communication between parts of a program become wirings between instances of abstractions in ALA. These wirings appear as normal lines of code inside another abstraction in a higher layer, where they are not dependencies.  

** Dependencies from decomposing a larger module into more specific pieces in conventional code are also eliminated using abstractions. Conventional architectural design uses a 'decomposition' based methodology. For example, it is common to separate a feature into UI and business logic, neither of which is an abstraction relative to the feature, but a specialized piece of the feature. Such decomposition tends results in coupling. Decomposition methodology has too much flexibility to break modules up in arbitrary ways. ALA first encourages us to not decompose at all, and instead uses a purely 'composition' methodology - compose from a set of abstractions that you invent. If an abstraction does become too large, we either factor out an abstraction or break into pieces that must be themselves abstractions (zero coupled with one another).  

* Gap between requirements and implementation

** ALA puts all code that has knowledge of the specific requirements in the top layer. But only code that carries details of requirements is put in the top layer. Our experience is that this constitutes around 10% of the total code making up an application. So, once the set of domain abstractions is complete, changes to requirements are generally confined to this 10% of code in the top layer.

** Because the job of the top layer is just to express requirements, the gap between stated requirements and their implementation is small. There is usually a much more direct relationship between the requirements expressed in natural language and the requirements expressed as a simple composition of instances of abstractions.

* Diagrams

** Requirements typically contain relationships that form a graph structure (a network). In conventional software, this network of relationships is distributed in the implementation code. This makes the graph itself quite obfuscated. Furthermore, we try to eliminate circular dependencies, which makes the graph even more obfuscated. ALA makes these graph structures explicit. Preferably they become diagrams. The graphs go inside their own abstractions in the top layer.


* Refactoring

** Software failure points are well understood. In addition to the quality attributes, complexity, readability, maintainability, testability, we often identify sub-causes such as coupling, dependencies, unstable classes or interfaces, circular dependencies, the large semantic gap between requirements and code, lack of reuse, syntactic noise, indirection, and the like. (Indirection appears as the common difficulty of tracing though a program that uses dynamic connections, such as the observer pattern.) The problem is we find them difficult to manage when we are also concentrating on getting things working, and doing that under a deadline. 

** Conventional development therefore usually involves two phases. In the first you concentrate on functionality. Then once you have that, you turn your attention to all these other quality attributes, and use refactoring to try to improve them. This refactoring is an ad-hoc process that really only works at a fine grained level. ALA takes a different approach. It starts with a meta-architecture that already takes care of all these quality attributes. You usually don't have to refactor unless you have broken the ALA constraints. The trade-off is that you have to spend some time to work out what the Domain Abstractions and Proramming Paradigms should be. Sometimes this is hard, especially in a new domain.  

Actually, in practice we do some refactoring. We find ourselves improving the description of an abstraction. This description pops up as a tooltip when we hover over an instance on an application diagram. This is especially true when a new person on the team is reading the diagram and needs to understand the domain abstractions without goin to their documenation comments. We also often rename the ports on abstractions so that the external point of view of an instance is easier to understand.


{empty} +

*Chapter 4, "Execution models".*

Explains how the underlying execution for each programming paradigm can be made to actually work.

** Explains the ways that the CPU executes the right code at the right time when the structures that emerge from ALA compose domain abstractions in a different or more declarative way compared to imperative execution flow.

** UI layout

** UI Navigation

** Dataflow

** Event driven

** Real world time activity flow

** Data schema



{empty} +

*Chapter 5, "Methodology"*

Describes ALA in terms of how it fits into Agile software development.

** The primary methodology is that requirements are simply 'described' in terms of 'invented' domain abstractions.

** An "Iteration zero" is used, important to get a starting set of domain abstractions and programming paradigms. The starting set will set the pattern of the whole design.

** How to go about 'inventing' domain abstraction for the first time in a new domain.


{empty} +

*Chapter 6, "The philosophy behind ALA"*

Gives the theory of why ALA works from the perspective of complex systems and how our brains work.

** Describes how the two fundamental architectural constraints are designed to mimic how our brains see the real world.

* Abstractions are learnable, stable and reusable.

** Learnable: In ALA, any code can be read as a stand-alone unit once the dependent abstractions have been learned. For example, we can read code that has a dependency on squareroot because we have learned what the squareroot abstraction is. We don't need to go and read the squareroot code. ALA constrains us to make ALL dependencies work this way.

** Stable: In ALA, all dependencies are on stable concepts. Not stable code, stable concepts, such as the concept of squareroot or the concept of events. Since stable concepts don't change, the dependent code is protected from ripple effects. The stability of the concept of an abstraction is unrelated to the code that implements an abstraction. For example, the concept of squareroot has been stable now for thousands of years.

** Reusable: As Charles Krueger has pointed out, abstraction and reuse are two sides of the same coin. By constraining dependencies to be on abstractions, we then find these abstractions being reused, which creates more dependencies on them (a good thing), which helps us consolidate them as abstractions.  

* An abstraction provides our brain a way to reason about all possible instances at once. The details of any given instance is hidden, . 



** Composition of a small number of abstraction layers in the real world as an analogy: e.g. atoms, molecules, proteins, cells, bodies.

** ALA leverages how our brains have evolved to use abstractions to understand the real world. This enables us to understand our programs in the same way.

** ALA achieves an optimal level of expressiveness in each layer. This includes the application layer which is just a formal expression of requirements in their details, but nothing else. 

** ALA uses layers instead of encapsulation hierarchies. We want public abstractions for maximal reuse, not private specialized parts for a specialized use.

** ALA does not use 'models' for its structure or architecture. Models, as the term implies, can leave out details arbitrarily. These details are unknowns and will come back to bite us. ALA only leaves out details by putting them inside abstractions, which renders them harmless. (Models differ from diagrams, which ALA can use.)



{empty} +

*Chapter 7, "ALA compared with...".*

** Unsurprisingly, the two fundamental constraints of ALA emerge most architectural styles and patterns that we already use in software engineering. 

** ALA makes use of them simultaneously.

** Interestingly, most of the patterns appear in a modified form. 

** Examples are: Layers, Dependency injection, Observer pattern, DSLs, Pipes and Filters, Components and connectors, Monads.

** Very surprisingly, some patterns are odds with ALA. Examples are MVC and UI/Businesslogic/Database tiers. And says the UML class diagrams are completely evil. 

** It is interesting to compare and/or contrast ALA with all these conventional engineering styles and patterns. 

{empty} +

////

This web site is a work in progress. ALA is a research in progress. Please don't hesitate to provide feedback to the e-nail address given at the end.

I would like to acknowledge the help of Roopak Sinha at AUT (Auckland University of Technology) in the writing of the paper for ECSA 2018 and  his academic perspective. 

// for web site

link:Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]

// for pdf

// https://AbstractionLayeredArchitecture.com/Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]


:partnums:
:sectnums:

include::ChapterOne.adoc[]

include::ChapterTwo.adoc[]

include::ChapterThree.adoc[]

include::ChapterFour.adoc[]

include::ChapterFive.adoc[]

include::ChapterSix.adoc[]

include::ChapterSeven.adoc[]

include::ChapterEight.adoc[]







