:imagesdir: images

== Chapter three - Why the structure works

In the previous chapter we described what the structure, the anatomy, of ALA looks like as if we were dissecting a dead body. We see where things are but we don't yet understand why they are there. In this chapter we explain why that structure works. Why does this way of organising code result in software that meets those non-functional requirements we listed in Chapter one?



=== A thought experiment

Imagine you are reading the following function, abc123, and trying to understand it:

 float abc123(float[])
 {
     ...
     b = xyz789(a)
     ...
 }

 float xyz789(float)
 {
     ....
     // complicated code
     ....
 }

You don't know what xyz789 is. It may as well be called fubar (fubar stands for messed up beyond all recognition), so you follow the indirection, an inconvenience at the least because you are really just wanting to understand abc123. You have to mentally stack where you were in abc123, including everything you understand about it so far. 

You begin reading the code at xyz789. It only has about 20 lines but it is complicated. You need to use the code in abc123 to try to unravel what need xyz789 might be proiding to it. A comment mentions that it uses a CORDIC algorithm and gives a reference. But before following that indirection as well, you note that both abc123 and xyz789 have the following properties:

* modules
* apparently loosly coupled 
* have a simple interface
* encapsulated
* use no external variables
* have no side effects
* hide information
* probably separate two concerns
* is small
* follows coding guidelines
* have comments

Despite having all these great properties that we are all taught, still we are forced to read both functions to understand the code in either of them. They are effectively fully coupled - understanding any of the code involves understanding all of the code.  

Now we make a small change: 


 float StandardDeviation(float[])
 {
     ...
     b = Sqrt(a)
     ...
 }

 float Sqrt(float)
 {
     // complicated code
 }

Suddenly understandability is absolutely transformed. All we did was make the two functions abstrations.

All those other attributes that we listed above seemingly made no difference. The quality attribute that really mattered was abstraction. The others are still good to have, but they are insufficient. The abstraction property is the only one that our brains are designed for. The quality of abstraction is subjective. Software engineers must invent good quality abstractions. No compiler or tool can yet check that quality, although, as Robert Martin points out, the number of reuses of an abstraction can be used as a indicator.


The code inside each of the two functions goes from fully coupled to zero coupled. 

* In the downward direction, coupling goes to zero because the standard deviation function need only know the concept of the squareroot abstraction, not the code inside the squareroot abstraction.

* In the upward direction, coupling goes to zero because squareroot is more abstract and therefore can't know anything about the more specific Standard deviation abstraction that happens to use it. 

There are other benefits too:

* Abstraction and stability go hand in hand. The Sqrt abstraction is as stable as the concept of squareroot. That's a concept that's been stable for thosands of years. All dependencies in an ALA program go in the direction of the more stable.  

* Abstraction and reuse go hand in hand (as pointed out by Krueger). The more abstract an abstraction is the more reusable. Code reuse in ALA programs increases markedly.  

The complicated code inside SQRT no longer matters. It is completely isolated by the abstraction. If your brain already knows the SQRT concept (I had to choose one that everyone knows), there is no need to follow the indirection when reading the code inside StandardDeviation. The reader just continues reading the next line of code after the Sqrt invocation as if Sqrt is just like any other line of code in their base language. That's what abstraction is.



With this new understanding, we will now define the word dependency to be compile-time relationships, and coupling to be the design-time or understanding-time relationships. One is what the compiler sees, the other is what our brain sees. 

Using these definitions, you can have coupling without dependencies (sometimes called implicit coupling). The reverse is also true - it is possible to have dependencies without coupling. ALA makes use of this by simply making a constraint all dependencies must be on abstractions. When you do that, every artefact (abstraction) in the program is zero-coupled with every other. 

Doing this isn't always easy because unfortunately there are many established architectural methods, patterns and styles that break this constraint. On the other hand, applying this constrain emerges some patterns that we will immediately recognise. DSLs and dependency injection are two examples. We will also emerge some less well known ones that are none-the-less not novel. There already exists an "abstract interactions" pattern, for example.


There are two situations that commonly cause coupling in conventional code:

. In the above example, if xyz789 is just a source or destination for messages, then abc123 cannot be an abstraction because it cannot be reused without dragging xyz789 with it. abc123, as an abstraction, doesn't care where the data comes from or goes to. To fix this, xyz789 must be passed into abc123 by something else above both of them. This can be passing in a function, passing in an object (dependency injection), or other mechanism such as the WireTo operator that we will use a lot in our ALA example projects.
+
A benefit over and above the zero coupling is that the data flow relationship between abc123 and xyz789 used to be hidden inside abc123. In ALA that relationship has to be an explicit line of code (inside another abstraction above) that wires together two instances. There, it will be cohesive with other similar relationships that work together in a collaborative way to make the application. 
+
Often these collected together wirings form a graph, making diagrams rather than code an even better way to describe the application.

. If xyz789 provides a part of the implementation of abc123 such that it is specific to abc123, then xyz789 is more specific than abc123. Sometimes such a function or class is called a helper or submodule. This is because abc123 could be reused many times, whereas xyz789 could only ever be used once (only by abc123). xyz789 needs to be more abstract than abc123 or it will be coupled to it.
+
This is contrary to what we are taught. We are taught to "divide and conquer" or to separate out the responsibilities in abc123. If we do this arbitrarily, we will end up with specific pieces (such as UI and business logic) which are highly coupled with each other, and with the specific application. We need to work hard to separate only by finding abstractions - potentially reusable artefacts. Then we configure instances of those abstractions for each specific use by passing the application specific details into them.  

In summary, ALA's starting premise is a constraint. The constraint is that you can only use one type of dependency - a dependency on an abstraction that is more abstract. This results in zero coupling throughout the abstractions of the entire program. 

The rest of this chapter expands on the points we mentioned briefly in this first section. 




=== Abstraction as design-time encapsulation

[IMPORTANT]
====
[green]#*Abstractions*# are the human brain's version of [green]#*encapsulation*#.
====

The maintainability quality attribute is often thought of in terms of ripple effects of change. I don't think that is quite the right way to look at it. I have often had to make changes across a number of modules in poorly written code. The changes themselves just don't take that long. The problem I see is the time you have to spend understanding enough of the system to know where to make a change, even if it is one line of code. To make that small change with confidence that it wont break anything can take a long ime. The problem is coupling. Even if the change is one line of code (which it often is), you may have had to understand a lot of code to figure that out. You have to understand all the code that is potentially coupled to that one line of code, which is essentially the complexity.

Unlike modules or encapsulation, abstractions contain and hide complexity at design-time. They give boundaries to how far you have to read code to understand it.


==== Abstractions and Instances

[IMPORTANT]
====
[green]#*Software architecture*# should contain [green]#*two concepts*# for its [green]#*elements*#  equivalent to [green]#*abstractions*# and [green]#*instances*#.
====

ALA makes abstraction and instances fundamental. 

Abstractions are separate, zero coupled, design-time elements. Abstractions, therefore, cannot exchange data themselves. The concept of instances must be added. An instances is nothing more than the use of an abstraction by referring to its name. 

Object oriented programming has these two concepts as classes and objects. Functional programming has the two concepts in terms of the function definition and the function invocation. But many discussions on software architecture seem to combine them into one term, such as modules, components or layers. They may implicitly contain the separate concepts, as components may, but not having them explicit will inevitably lead to confusion. 

The problem is that when we become vague about the difference, we will create dependencies between the abstractions, such as to get or put data, that should just be using two instances in a line of code somewhere. Adding dependencies between abstractions destroy them as abstractions. Composing two Instances of abstractions does not. If we don't have two separate and clear terms for abstractions and instances, we will end up with no abstractions.

Nearly all architectural styles have this problem. For example, in layering, we put 'modules' into layers and then create unnecessary dependencies to move data between them. No, put abstractions into one layer. Then compose instances of them inside a new abstraction in the layer above.  

Another common example of the problem is the UML, which already has the separate concepts of objects and classes. But we tend to ignore objects and create associations between classes instead. The most important idea that OOP brought us was the idea of classes and objects. It has been ruined by the UML class diagram. Instead of associations between classes, instantiate objects and wire them together. Do that completely inside another class in the layer above. 

****
The quality of an abstraction's _concept_ or _idea_ is important. It is the existence of the concept that allows the brain to learn it and not have to know how it's implemented each time it comes across it. It is the stability of the idea of the abstraction that blocks coupling. ALA requires effort to conceive good abstractions, especially for the first application in a new domain.
****


=== Zero coupling and higher cohesion

ALA has zero coupling between the code inside (or the code that implements) all abstractions. This is the case both horizontally between peers in the same layer, and vertically up or down the layers. 

In software design we are only interested in design-time coupling. This means that to understand one piece of code, how much do we need to understand other pieces of code? This is the coupling that matters. We will use the word coupling to refer to design-time coupling. 


****
Wikipedia defines coupling as "the degree of interdependence between software modules". It doesn't really distinguish between design-time, compile-time or run-time coupling, and the given formula for coupling seems to reflect compile-time. We prefer to think of coupling as a design-time property. The use of abstractions instead of modules changes the way we should think about coupling. 

Consider the principle of compositionality. As stated in Wikipedia, "In semantics, mathematical logic and related disciplines, the principle of compositionality is the principle that the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them."

In ALA we use abstractions as the 'constituent expressions', and we have the objective that all code conforms to the principle of compositionality. We then define coupling as anything that compromises this principle.
****

[TIP]
====
[green]#*To understand any one part of the code should involve understanding only that one part of the code, and the abstractions it uses.*#
====

Unfortunately there is a meme in the software engineering industry that there must be some coupling between 'modules'. The argument goes that if the system is to do anything it must have some coupling between its parts in order to do anything. We therefore hear of "loose coupling" as being the ideal. Using the definition of coupling given above, this is completely incorrect. Because of this meme, in conventional code  we are settling for design-time coupling to achieve connections between different parts of a system. This is not necessary. Part of the problem is that the same word is being used for both design-time coupling and _connections_ or _wiring_. 

In our A & B example above, the code inside B knows nothing of A. The code inside A, while it knows about the concept of the abstraction B, knows nothing about the code that is inside B (or implements B). So we already know how to do zero-coupling. ALA is basically a constraint to always have zero coupling.

For example, in conventional code, if function Switch calls function Light, the code inside Switch is coupled with Light. If the light's abstraction level is about the same as that of the Switch, then the abstraction of Switch is destroyed. When you use it you have to know the internal code brings in a Light. To understand the _system_ (a Switch connected to a light), you have to go inside the Switch:


[plantuml,file="switch-light-bad.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=LR]
subgraph cluster_1 
{
label="Switch"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="Light"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=red, label=""]
}
@enddot
----


If instead, an abstraction, System, has code inside it like Light(Switch()), then Switch remains a good abstraction whose internal code is now only concerned with how a switch works. The code inside all three abstractions is now zero coupled. Understanding the system no longer requires looking inside Switch.  

[plantuml,file="diagram-collaboration-A-B-C.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
A [label="System\n\nx=Switch(); Light(x);"]
}
@enddot
----

{empty} +

[plantuml,file="diagram-collaboration-B-C-invis.png"]
----
@startdot
digraph foo {
size="1.5!"
graph [rankdir=LR]
Switch -> Light [style=invis]
}
@enddot
----




A similar argument applies if Switch and Light are classes. In conventional code they will commonly have an association relationship. Even if Light is injected into Switch by a higher entity called System, Switch still knows the specific interface of a light (LightOn(), LightOff()). This interface is not abstract enough to prevent Switch knowing about Light, and Switch knowing about the System. If you instead have a class System that has code like new Switch().WireTo(new Light()) using a generic interface then all three abstractions are zero coupled.

ALA _never_ uses coupling for connections or wiring between parts of a system. A larger system typically consists of many  connections. These connection are typically cohesive, and belong in one place. In conventional code they tend to be distributed and buried inside the modules. A smell is that you are doing 'all files' searches to unravel them   

[TIP]
====
"[red]#*Collaboration*# becomes [green]#*cohesion*#".
====

In ALA, collaboration between modules becomes cohesion. A call from one module to another becomes two cohesive calls in adjacent lines of code. A method call on a peer's classes interface is first transformed to two abstract interface ports. Then a line of creates the two parts and wires them. This line is cohesive with other such wirings needed for that requirement.  

Cohesion also increases in a different way. An abstraction is closely aligned with the single responsibility principle. We can think of abstration as a single concept principle. Using abstractions increases the cohesion of the code that implements the abstraction.


Zero coupling and high cohesion limits ripplle effects of change, whether in higher layers or lower ones. A ripple generally stops at an abstraction concept because of the inherent stability of the concept. What does happen though is that the abstraction can be improved. They are hard to get right in the up-front design. Often you can generalize an abstraction further by adding a configuration that has a default behaviour, so it doesn't affect other uses of the abstraction (convention over configuration).

In our experience, the most common type of change that still affects multiple abstractions are changes to conventions. Conventions in the ways abstractions are commented, and their code laid out are effectively abstractions in themselves that live in the bottom layer. So when they change, it makes sense that all abstractions that depend on them change. These types of changes may require a lot of editing, but don't require simultaneous understanding of multiple modules, which is where the real problem with coupling lies. 




=== Good versus bad dependencies

We can distinguish two types of dependencies. One is run-time dependencies. These are dependencies in the code that are there because one module will need another module to be present at run-time for the system to work. The other is design-time dependencies. These are dependencies on the knowledge you must have to even understand a given piece of code. I will often refer to this type as a "knowledge dependency" or "use of an abstraction". It is also sometimes called "semantic coupling".

 
[WARNING]
====
[red]#*Run-time dependencies are bad*#.
====
[TIP]
====
[green]#*Design-time knowledge dependencies on abstractions are good*#.
====

A simple example of a run-time dependency is a module that calculates the average rainfall then calls a display module to display the result. The Display module needs to be present at run-time. But to understand the code that calculates the average rainfall requires no knowledge about displays, nor even where the result will be sent. The dependency is only there to make the system work at run-time.

A simple example of a design-time knowledge dependency is some code that calculates the rainfall using an averaging filter. It uses an abstraction that takes a data stream as input and outputs a running average. To understand the rainfall code needs knowledge of averaging filter. This is a design-time, or knowledge dependency. Any application needing to reduce data to an average could use the same abstraction. 

We find both types of dependencies in conventional code. A typical modular program is full of bad run-time dependencies. But whether a knowledge dependency or a run-time dependency, they all just look like a function call or a 'new' keyword, or a method call on a peer class's interface. We are not taught how to distinguish between them. They are all just called dependencies. We lump them together when we talk about dependency management, loose coupling, layering, fan-in, fan-out, circular dependencies or dependency inversion. Dependency graphing tools cannot distinguish between them because dependencies depend on understanding some abstraction. 

These two different types of dependencies are not just good and bad. They are really good and really bad. So it's doubly important that we learn to tell the difference. What's more it's entirely possible to build a system using only good dependencies. 

[TIP]
====
[green]#*In ALA we eliminate ALL bad dependencies*#.
====

A knowledge dependency is good because it's only dependent on an abstract concept. Good abstractions are easy to learn. The more dependencies you have on such an abstraction, the more abstract it is, the more reuse you are getting, and the easier it is to learn.

Bad dependencies destroy abstractions. They cause explicit and implicit coupling. They obscure the structure of the application by distributing that structure throughout its modules. When we remove all bad dependencies we express what they did in normal cohesive code inside a more specific abstraction above, that composes instances of the abstractions .

Consider the diagram below. It the modular way to write a reanfall meter. An ADC reading is averaged, converted, accumulated, and displayed. One of modules has bad dependencies which it uses to make function calls to pull the data in and push it out. 

[plantuml,file="dependency-diagram.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1

Application

/----\    /----\    /----\    /----\    /----\.
|ADC |<---|Avg |<---|Conv|--->|Accu|--->|Disp|
\----/    \----/    \----/    \----/    \----/


key:   <---(Depends On)


@endditaa
----

There are four bad run-time dependencies.

Now consider this diagram.


[plantuml,file="dependency-diagram-1.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1

    /------------------------------\.
    |Application                   |
    |                              |
    |adc---avg---conv---accu---disp|
    |                              |
    \------------------------------/


--------------------------------------------------
Abstractions

/----\  /----\  /----\  /----\  /----\.
|ADC |  |Avg |  |Conv|  |Accu|  |Disp|
\----/  \----/  \----/  \----/  \----/


--------------------------------------------------
Programming Paradigms

            /--------\.
            |Dataflow|
            \--------/
@endditaa
----

There are five good knowledge dependencies (the top layer uses five abstractions in the second layer), but no bad run-time dependencies because the abstractions have no relations with one another. Connections between the instances are completely inside another abstraction as cohesive code that knows about a rain meter.

The code in the application abstraction could look something like this if using functions (although you would likely use some temporary variables in practice):

[source,C#]
....
    Disp(Accu(Conv(Avg(ADC()))));
....

It might look something like this if using classes:


[source,C#]
....
    new ADC().WireIn(new Avg()).WireIn(new Conv()).WireIn(new Accu()).WireIn(new Disp());
....

How this code is done is not what's important. How syntactically succinct this code is is not important. What's important is where it is. We want the code that cohesively and fully expresses a rain meter to be in one place.  

The lower-case letters used in the top layer of the diagram represent instances of the respective abstractions. (In UML they would be underlined.) You never draw arrows for knowledge dependencies - you only ever refer to abstractions by name. (Just as you would never draw an arrow to a box representing the squareroot function - you would just use Sqrt by its name.)

In common programming languages, the run-time dependencies in the first diagram and the knowledge dependencies in the second diagram could both be syntactically written in the same form, either new A() or just a function call, A(). The only difference is in where those new keywords or function calls are, and in the case of classes, using an abstract interface instead of each class having its own specific interface. This difference means the difference between good dependencies and bad dependencies. It has a huge effect on the quality of the architecture as it gets larger.

The application abstraction can move the data between the instances of ADC, Avg, etc itself, as we did in the first code example, however strictly speaking that pollutes it with details of how to move data that actually belongs in the programming paradigms layer. We much prefer the application code just does the composing - just specifies who connects to whom, but is not involved with how it works. That's why in most of the examples, we compose with classes that have ports rather than functions. In the second code example, the dataflow programming paradigm would be implemented with an execution model that know how to actually move data. The application only knows that it is composing a flow of data.

The interface used to connect the instances is called Dataflow. It's important that this interface is abstract. It is two layers down. It is not an interface specific to any one of the domain abstractions, ADC, Avg, etc.. This is the abstract interactions pattern. Many other domain abstractions can either implement it or accept it, or both.


==== Comparison of good versus bad dependencies.


.Comparison of two approaches
[width="100%",options="header,footer"]
|====================

| Run-time dependencies version | Knowledge dependencies version

| Knowledge about the specific application is spread through all modules. | Knowledge about the specific application is only in one place. The abstractions know nothing of each other or the specific application. 

| The class or function names A, B, D and E will relate to what they do (which is fine). For example, they may be the specific hardware chips used in the case of drivers. The calling module must know these names, creating a fixed arrangement between the modules. The modules are only loosely coupled. | No abstractions refer to the names of peer abstractions. There is no fixed arrangement between abstractions. The abstractions are zero coupled. The code that knows that a particular hardware chip is used in this application is where it belongs, in the application abstraction.

| Since there is a fixed arrangement, responsibilities can be blurred. For example, it may be unclear whether to add something to B or C. | With no relations between abstractions, responsibilities are clear. Something to be added clearly belongs in one or other of the abstractions, or in a new abstraction that may be wired in between the two.

| The fixed dependency from C to B will encourage implicit coupling. B can make assumptions about details inside B resulting in collaborative coupling. | C cannot make any assumptions about some details of B. It cannot have collaborative coupling with B 

| Although there is no dependency, for example from B to C, the fixed arrangement is likely, over time, to make B implicitly collaborate with C (do what C requires), resulting in collaborative coupling. | No implicit coupling can develop over time because there is no fixed relationship between them. B cannot collaborate with C (do what C specifically requires).

| The arrangement between A, B, C, D and E is not obvious in the code. It is buried inside of B, C and D. All must be read to find the application's data flow structure | The arrangement between instances of A, B, C, D and E is explicitly coded in one place. The data-flow between them is cohesive information that belongs in one place.

| Only A and E can potentially be abstractions. | All of A, B, C, D and E are abstractions.

| Arbitrarily, only the two ends of the data flow chain can be reused independently . | All of A, B, C, D and E are independently reusable.

| Difficult to insert another module between, say, B and C. | Easy to insert a new instance of some operator between B and C, etc. 

| If the observer pattern is used (in the mistaken belief that it reduces the coupling), it only mirrors the same problems. For example B would now have a dependency on C when it registers. But because it adds indirection, the observer pattern makes the program even harder to understand. | If the observer pattern is used (as the means to implement the wiring between the instances), the receivers do not do the registering, the application does (not strictly the observer pattern). The abstractions themselves don't get more difficult to understand because, being abstractions, they only have knowledge as far as their interfaces anyway. The application does not get harder to understand either, because the arrangement of the instances is still explicit and in one place.

| If dependency injection is used with automatic wiring, the arrangement is still somewhat fixed, but is now even more obscure. All classes can still be collaborating with one another. A smell that this is happening is that over time the interfaces, IA, IB, ID and IE change as the requirements of the system change.  | If dependency injection is used, the application does the wiring explicitly. It is the only place that should know who will talk to whom at run-time for this specific application. There are no specific interfaces between pairs of modules to change over time, because they all just use a stable abstract interface.  

| Each module has its own interface. But they are all doing essentially the same thing, getting data. | Uses a single more abstract interface called Dataflow.  

| The arrangement between the modules cannot easily be changed, both because the wiring code is buried inside the modules and because the interfaces are essentially specific to pairs of modules. | The composition can easily be changed. Instances of the abstractions can be re-wired in any combination. New abstraction instances can be inserted.

| There is no diagram of the arrangement between A, B, C, D, E, or if there is, it is likely a high level overview, lacking in detail, and a second source of truth that gets out of date. | There is a diagram that shows the arrangement of the instances of A, B, C, D and E. It is the one source of truth. It includes all details about the specific application. It is executable.
|====================


During code creation, run-time dependencies are easily introduced, and never seem too terrible at the time as they get the immediate job done. But when they accumulate to hundreds or even thousands of them, as they do in most typical applications, that's when the system, as described on the left side of the table, just appears as a monolithic big ball of mud.

==== Free lunch?

When you are comparing the left and right sides of the table above, you may be wondering, where did the free lunch come from? Where did the runtime dependencies go? Is this some kind of magic? Or how can the program work without them? Or haven't I just moved them somewhere else? No there are no tricks. The answer is that we have been taught to do programming in a very bad way. The knowledge that ADC will talk to Avg, etc at run-time is there, but it is now contained within an abstraction, not a dependency between modules. If you really want to find a disadvantage, then it is the need for the abstractions. It only works as well as the quality of the abstractions. Effectively we have replaced the need for dependency management with the need to create good abstractions. Creating good abstractions is a skill that does take time to get used to.

Just to recap the only dependencies we have used are good design-time or knowledge dependencies: 

. The application should and must 'know' at design-time what domain abstractions it needs to compose to make a rain meter application.

. The domain abstractions should and must know at design-time what programming paradigm it needs - the abstract interfaces to use for their input and output ports. 


==== Stable dependencies principle

A dependency on an abstractions is a dependency on the concept or idea of that abstraction. A concept or idea is generally stable. So dependencies are toward the more stable. 

Even if the implementation details inside an abstraction are complicated or change, the abstraction concept itself be stable. The application example above is really just depending on the idea of an ADC or the idea of a Display. If the details inside change it doesn't matter. For example, if the ADC silicon is changed, the ADC abstraction implementation can also change. But the application is still just using an ADC as it's means to get input. 

ALA therefore naturally conforms with the Stable Dependencies Principle (depend in the direction of stability). The SAP is mostly used in relation to packages, but ALA does not use hierarchical encapsulations. Here we are applying it at the level of the abstractions themselves.


==== Dependency fan-in and fan-out

One of the guidelines sometimes used for dependencies in conventional code is that a class that has high fan-in should not have high fan-out (also called afferent and efferent coupling). Another is that modules higher in the layers should have low fan-in and those lower in the hierarchy have low fan-out.

The argument goes that a class with high fan-in should have high stability but one with high fan-out would have low stability (presumably because dependencies are thought to be things that cause changes to propagate).

In ALA, dependencies are on abstractions. Furthermore the abstractions are increasingly abstract as you go down the layers, and therefore increasingly stable. Therefore the conventional fan-in and fan-out recommendations are reversed. In ALA, it is perfectly fine, in fact really good to have both high fan-in and high fan-out. It simply means that the abstractions are useful and are getting reused.  

If we are talking about dependencies in a conventional modular system that are used for communication between modules in the system, of course ALA says we want zero fan-in and zero fan-out, because such dependencies are illegal anyway.

In chapter four we will also talk about fan-in and fan-out. Note that the fan-in and fan-out discussed in chapter four is different. In this chapter fan-in and fan-out is talking about dependencies on abstractions between layers. In chapter four we are talking about fan-in and fan-out in the wiring.


==== Circular dependencies

Of course in ALA, with only knowledge dependencies present in the system, and the dependencies needing to go toward more abstract abstractions, you obviously cannot have circular knowledge dependencies. Nor would that even make sense. (Recursion appears to require circular knowledge dependencies but actually doesn't. We will visit that in the last chapter.) 

Since there are no run-time dependencies, the issue of circular dependencies with them does not arise at all. What might have been circular dependencies in conventional code becomes circular wiring of instances of abstractions inside a user story abstraction in the application layer. Such circular wiring is quite valid, and very common. The potential issues with the execution models are discussed in chapter four.

In conventional software design, run-time communication channels between modules are frequently implemented with dependencies. Then we realize these dependencies are a problem and so we add a rule that we don't like circular dependencies. This is an attempt to mitigate the problem by forcing the modules to have a sort of arbitrary layered structure. That structure does not actually exist in the nature of peer modules themselves. (Many modules will actually have a similar level of abstraction, for example views, business logic and data.) The forced arbitrary layering structure becomes its own nuisance.

So then what happens is circular dependencies are most often avoided by using pushing in one direction and pulling in the other. (Pushing means a function or method call with a parameter, pulling means a function or method call returning a value). This is sometimes actually convenient, and other times a real nuisance. Whether we push or pull should be able to depend on performance or other considerations (which end wants to initiate the communications, which depends on when the source changes, or when we want to receive new a the data, or how often the source changes, or on latency, etc), not on an arbitrary layering of modules.

So, when we do want to push or pull in the reverse direction of the allowed dependency, we end up creating an indirection, such as a callback, virtual function call, or observer pattern (publish-subscribe). This indirection further obscures the already  obscure communication flows through the system.

ALA simply eliminates all this nonsense. In ALA, communication flows:

* are explicit
* can be in both directions
* each set of cohesive flows are contained in one place
* allowed to be push, pull, or asynchronous on a port by port basis
* don't use dependencies at all
* use indirection in the correct way, which is that when you are reading code inside an abstraction, you don't know, and shouldn't know, where your inputs and outputs are wired to. 

That concludes our discussion on why the ALA structure works from the point of view of good and bad dependencies.



=== Knowledge dependencies are on all layers below

Sometimes layers are used incorrectly as partitions or really just modules. We would be better off to just tip all such layering models on their side.  Because of this mistake, there is a meme that we should only have dependencies on the immediate layer below. For ALA layers this is incorrect.

When we write our programs using only knowledge dependencies, the knowledge needed to understand a piece of code can come from all the layers below. 

For example, to understand this application layer code:

[source,C#]
....
    new ADC().WireIn(new Avg()).WireIn(new Conv()).WireIn(new Accu()).WireIn(new Disp());
....

You need to know all of these things from lower layers:

. Understand what the  domain abstractions, ADC, Avg, Disp, etc do.

. Understand the data flow programming paradigm. When you compose these particular domain abstractions, you are composing a flow of data from left to right.

. Understand that the WireTo operator, which comes from the Libraries layer, is what you use to do composition. 

. Understand your general purpose programming language, which sits below the Libraries layer.

. Understand ALA which is an abstraction that sits below the programming language layer.

All of these knowledge dependencies should be explicit. This means that the application folder should contain a readme file explaining all these knowledge dependencies, and link to information about them.

It's nt necessarily the case that all lower layer knowledge is needed to understand something. The application is itself an abstraction. There can be many instances of it being used by different users. These users don't need to understand all the abstractions in all the layers, only the application abstraction by itself.



=== Executable expression of requirements

We have previously discussed this aspect of ALA in terms of structure. It is the top layer. And we have used this aspect as the starting point in the method to develop the example projects. But why does the succinct description of requirements in that top layer work?

In conventional software development, we typically break a user story (or feature or functional requirement) up into different implementation responsibilities. For example, layers like GUI, business logic and database, or a pattern such as MVC (Model, View, Controller). But a user story or feature actually starts out as cohesive knowledge n the requirements. And its not a huge amount of cohesive knowledge, so it doesn't need breaking up. Cohesive knowledge, knowledge that is by its nature highly coupled within itself should be kept together. All we need to do to keep it together is find a way to describe it so that it is executable. Don't try to do any implementation, just get it described in a concise and complete form. If you can do that, the chances are you will be able to find a way to make it execute. 

In ALA we want to find a way to express the user story with about the same level of expressiveness as when the user story was explained in English by the product owner. The language he used would have contained domain specific terms to enable him to explain it concisely. The same thing ought to be possible in the code. Anything that does not come directly from the requirements and starts to look like implementation detail is separated out. It comes out into abstractions. These abstractions typically contain knowledge of how user stories in general are implemented - how things can be displayed, how things can be saved, how data can be processed.

It turns out that abstractions that know how to implement useful things for expressing user stories are not only reusable for different user stories, but can be reusable for other applications. In other words, they are domain level abstractions. A typical user story might be composed of several of them, some to implement the user story's UI, some to implement the user story's business, and some to implement the user story's saving of data. A user story instantiates the abstractions, configures them with the specific knowledge from the requirement, and then wires them together.

Most maintenance is probably changing, adding or fixing user stories or features. When those features are described entirely in one place instead of distributed through a lot of modules, you have a direct understanding of how the user story is represented by code, and therefore of how to change it or fix it.

Of course application code makes heavy use, in fact is entirely composed of, instances of domain abstractions. When fixing a bug, it quickly becomes clear if the application code itself doesn't represent the requirements as intended, or one of the abstractions is not doing its job properly. Again the maintenance is easy.


// sections moved here from chapter 2
==== Requirements are what's left when you factor out all implementation details

This is another way of thinking that comes to the same solution. As we know from the previous section, ALA requires you to break up your entire application only by factoring out abstractions. So what does the application that's left in the top layer look like when this is done? Well if anything abstract has been removed, what remains must be details specific only to this application. Essentially these details equate with the requirements.

The application code becomes a formal re-expression of the requirements. There will be some information there that wasn't explicitly stated in the requirements, but they were requirements all the same. For example, it may not have been stated in the requirements that a number displayed on the UI should not change its value too frequently - it should be slow enough for a human to read successive values. A consequence of that requirement is that it should not contain noise that has a frequency higher than the display update rate. So the application will end up with an instance of a re-sampler abstraction and an instance of a filter abstraction wired into its data-flow before the display. The application will specify the re-sampling rate, and the filter bandwidth.


// section moved here from chapter 2
==== DSL - Domain Specific Languages 

anchor:DSL1[]

ALA's succinct expression of requirements discussed above is obviously a form of DSL (Domain Specific Language). Under the broader definition of a DSL, The domain abstractions and programming paradigms layers are a DSL. But ALA is not just a DSL. ALA is fundamentally about organising all code into small abstractions that are in layers that are increasing abstract. This constrains the organisation of code much more than simply implementing a DSL. 

ALA does not pursue the idea of an external DSL (a new syntax), nor even the syntactic elegance of DSLs. It doesn't try to move application development away from the developer to a requirements team as some DSLs can do. For example, you don't get a new language such as XAML to express UI structure. In fact, expressing the UI structure in ALA moves away from XML back to code. If moving away from code, ALA uses diagrams because they are more flexible and much more readable than XML. 

Seen as a DSL, in ALA you wire together plain old objects or functions while conforming to a grammar. The grammar comes from the 3rd layer programming paradigms and from which classes use which programming paradigm for ports. This grammar defines the rules for their composition.


=== Diagrams vs text

The fundamental rules of ALA don't prescribe the use of diagrams. But diagrams often emerge.
So why do we often use a diagram instead of text in the application (top) layer of an ALA application?

It's because in any non-trivial program, there is structure inherent in the requirements that forms a graph. If you have UI that graph is a tree - still representable with indented text. But the UI must have connections. (These particular connections are often called bindings.) They need connections with data. They need connections with event handlers. These connections must be done symbolically if using text. The connections go further. There are connections to business logic and to some form of persistent data model, and from there to real databases or files. There are arbitrary connections for navigating around different pats of the UI. If text, most of these connections must be done symbolically. On the way, they may need to connect arbitrarily with things that process, reduce, or combine. There may be states involved, with arbitrary transitions needed between those states. There may be activities that have to happen in a prescribed time sequence, which by itself is representable as a linear instructions in text. But there are often loops or alternative routes through the sequence, which is representable as indented text. But then there is always some connection between the activities and some data or the outside world. If text, these connections must generally be done symbolically. 

All these connections are inherent in the requirements. Like or not, they form a graph. And this graph structure is somewhere in your code.

As we said, in text from, this graph needs to use at least some symbolic connections. That is, we can represent some of the graph with indenting and judicious use of anonymous functions or classes, but in general we will need to represent many of the connections by using names of variables, functions or objects.

This is bad enough. In fact this is already really, really bad compared with how the electronics guys do things.

But it gets much worse. In most conventional code, we take all these symbolic connections and distribute them evenly through the files/modules/classes/functions. Now the graph is totally obfuscated. The graph is highly cohesive. Why do we make it harder for ourselves by breaking it up?

But it gets much worse. Graphs have circles in them. There is nothing wrong with that, it's inherent in the connections in the requirements. But circles are at odds with dependency rules. So now what we do is break the cyclic dependencies using principles like dependency inversion or observer pattern. The connections don't go away. We just further obfuscated them. These connections are now done at run-time by code written somewhere else. This is the so called indirection problem.

What a mess we have got into!

ALA tells us how to fix this entire mess. It's really quite simple. ALA breaks up your application by factoring out abstractions. When you have done that to the maximum extent, what's left behind is nothing but the specifics of the requirements, including that (highly coherent) graph.

Now you can choose to go ahead and represent that graph in text in one place, using many symbolic connections, and you would already be way, way better off than how we write conventional code. But even better is to do what the electronics guys do, and just build the tools to handle the graphs as diagrams properly.

==== Diagrams and text are not equivalent


Diagrams and text are sometimes thought of as equivalent - and it's a matter of personal preference which you use. I do not agree with this. From the point of view of how our brain's work best, they are different, and each is powerful at its own job.

Consider an electronics engineer who uses a schematic diagram. Ask him to design a circuit using text and he will think you a simpleton. Electronics naturally has a network structure that is best viewed and reasoned about as a diagram. If you turn a diagram into a textual list of nodes and connections, the brain can no longer work with it directly. It is constantly interrupted to search for symbolic references when it should be free to just reason about the design. 

Most software naturally has an arbitrary network structure. Think about whenever you are working with legacy code - how often to you need to do "all files searches" or "find all references". And even those are foiled by indirections. Try designing or reasoning about a state machine without using a diagram.

Text can readily be used to compose elements in a linear chain or sequence. It is excellent for telling stories. White space is the normal connector between the elements. Sometimes periods or other symbols are used instead. Text can also handle shallow tree structures, simply by using indenting. Compilers may use brackets, usually () or {}. Interestingly, the brackets work for the compiler, but not for the brain. The brain doesn't see them, it just sees the indenting. So I personally don't agree that Python's significant indenting is a mistake as many do. 

When the tree gets deep, the indenting is too deep for our brains to follow. So text is only suitable for linear structures and shallow trees. Structured programming and XAML are examples of tree structured code represented successfully in text.

Text becomes troublesome when there are arbitrary connections across the structure forming a mesh. It must be done with matching names, labels or identifiers. Most imperative programs are actually not a tree structure because of the variables. They must be done with labels. Local variables in a small scope are not too much of a problem. It only requires an editor that highlights all of them. For large scopes we end up spending too much time finding and trying to remember the connections, resorting to many all-files searches. It is a cumbersome way to try to reason about what is usually a simple structure when viewed as a diagram. 

(When we talk about labels, we are talking about labels that are used for connecting two or more points. These labels are not abstractions. References to the names of abstractions are absolutely fine, and we don't draw lines for them even if we are using a diagram. We just use a box with the abstraction name inside it.)

When we need to compose instances of abstractions in an arbitrary network structure, our brains work much better using a diagram. The brain can readily see and follow the lines between the instances of the abstractions. Unlike with text labels, the lines are anonymous, as they should be. Lines don't need encapsulation. To understand all uses of a variable in text, we need an encapsulation scope. To understand all places connected by a line, the brain just sees all the lines instead. Generally lines connect only two points or ports, but sometimes may connect three or four. More than that, and it starts to smell as if a new abstraction may be waiting to be discovered. The spacial positioning of elements is also something the brain readily remembers. So, diagrams can qualitatively do things that text simply cannot.

ALA does not require a diagram per se. It only requires abstraction layering, and it's quite possible for a user story to just consist of a linear sequence of abstracted operations. For example, a sequence of movements by a robot or a "Pipes and Filters" sequence of operations on data. However, ALA is polyglot with respect to programming paradigms because user stories will generally combine multiple programming paradigms: UI, event-flows, data-flows, state machines, data schemas, etc. These aspects of a user story tend to be naturally interrelated (inherent in the requirements), which is what causes the resulting relationships among its instances of abstractions to be a network. Diagrams, then, embrace the bringing together of all these different interrelationships of a user story in one place and view.   

==== No XML as code

If dependency injection is used to implement the wiring, I prefer not to use XML to specify the application. Firstly XML is not very readable. Secondly it only handles tree structures well, not networks, and it becomes more unreadable if the tree is deep. If you must use text for specifying wiring, use normal code. You are still better off with this code in one place than having it distributed inside your modules. But if a network structure is inherent in the requirements, there is really no substitute for the readability of diagrams. 




==== Diagramming tools

The ALA design process (which is describing your requirements and inventing the needed abstractions as you go) is an intense diagram generating activity, especially the first time in a new domain. It requires all your focus. I have found that hand drawing the diagram on paper is not good. The diagram quickly gets into a messy state which requires redrawing, and that interrupts your flow. I have found that a diagramming tool that constantly needs you to control the layout, such as Visio, is also not good.   

So until there is a better tool, I have been using Xmind because as a mind-mapping tool, it is designed to not get in your way as you are creating. It lays itself out as a tree structure, and then allows cross connections on the tree to be added using a key short-cut at the source and a mouse click at the destination node. It has its limitations, however I use some simple conventions to get around these. For example, I use '<' and '>' to represent input and output ports.

Furthermore, the tree structure allows easy hand translation of the diagram into indented, fluent style code. 

More recently we use a simple tool that takes Xmind files and generates the code automatically.

And even more recently, we have in progress a purpose built graphical IDE for ALA.

See the end of this chapter for an example project using Xmind.


// TBD review from here

....
Thoughts on the essentials of a diagramming tool.
  
It would have the low driving overhead of a mind mapping tool. As with a mind-mapping tool, you control the logical layout, and the tool does the actual spacial positioning. It would primarily use keypresses, but allow mouse clicks where it makes sense, for example, to specify the destination of a 'cross connection'. The tool would route the cross conenction for you.

A tree topology can be done with simple key presses. The tree would capture the primary relationships between instances, on their main ports.

You can make mutiple trees for different user stories that are disconnected logically, but for the purpose of automatic layout, are connected to the main tree (just an invisible line).

Abstractions are defined in a separate panel as stand-alone boxes with ports. Once a new abstraction is  defined, it can be instantiated in the diagram by its abstraction name with auto completion. Boxes represent these instances of abstractions with the ports still lablled around their boundary.

The abstractions are fully inegrated with the classes in the code. This is in both directions. So for any existing classes, the IDE shows them with their port, and fully supports the entry of constructor arguments and properties.

In the other direction, if you create a new abstraction in the tool. You can specify its ports and their types and names. You can specify the constructor arguments and properties and their default values. It will create/modify a template for that class.cs.

The tool's purpose is to aid creativity in the ALA process of representing a user story, inventing new abstractions as you go. Of course the tool would also automatically generate the wiring code.
....

In my experience, a low overhead drawing tool is essential during the iteration zero design phase and during subsequent maintenance.   


// TBD two sections on decomposition copied in



=== Composition, not decomposition

The conventional technique for tackling system complexity is "divide and conquer".

Consider this phrase, which has been used as the definition of software architecture:

[WARNING]
====
"[red]#*decomposition*# of a system into [red]#*elements*# and [red]#*_their_*# [red]#*relations*#".
====

Notice the word 'their', which I have italicised to emphasis that the relations are inferred to be between the decomposed elements. It suggests that the decomosed elements know something about each other, that they collaborate to create the whole.  

In ALA we think about building the system in a completely different way. Here is how to reword the meme for ALA:

[TIP]
====
"[green]#*composition*# of a system using [green]#*instances*# of [green]#*abstractions*#".
====

This seemingly subtle shift in thinking leads to a qualitative difference in the resulting structure. 

First let's understand what we mean by composition through a few examples: 

* When we compose musical notes, we create a tune. The structure is linear. The execution is sequential like activity flow below. 

* When we write code in a general purpose programming language, we are composing  statements. Statements are low level (fine grained) elements and only support a single programming paradigm, which we could describe as 'imperative', but by composing enough instances of them we can create a program. The structure is a linear or a tree.

* In functional programming, we are composing with functions, so the elements are higher level things that you create. But the programming paradigm is still imperative (unless you use monads). The structure is either linear or a tree.

* When programming with monads, we are composing with what they call 'amplified data types'. These are usually low-level elements. But the programming paradigm has changed from imperative to data-flow. The structure is usually linear. (You don't need to understand or use Monads to use ALA. however,    
<<Monads,See my method to understand Monads in Chapter Six>>

* When programming using the UML class diagram, we are composing classes. The programming paradigm is associations. The syntax is graphical. The structure is a network.

* When programming using the UML activity diagram, we are composing activities to be done in a set order. The structure is a network, because you can branch, recombine and loop back arbitrarily. Activity diagrams are not imperative (like the old style flow diagrams). The CPU is not necessarily dedicated to each activity being done. Activities may take an arbitrarily long time without the system blocking. 

* When programming with XAML, we are composing UI elements. The programming paradigm is UI layout (what goes inside what and in what order). The structure is a tree.



Let's list the different properties present in these types of composition:

* Low-level or high-level - Sometimes we are composing fine-grained general elements and we need a lot of them. Sometimes we are composing 'higher level' more specific elements, and we need a few of them.
+
Note that sometimes people think of these higher level elements as more abstract. They are actually less abstract. For example, a class that handles complex numbers is less abstract than the fundamental float type. Complex numbers are a more specific case because its only useful when you need complex numbers in your solution. But when you do need complex numbers, then they are obviously more expressive than using pairs of floats everywhere. This means that you need to compose less abstractions to build your solution.

* The meaning of a composition relationship is mostly fixed in each case. It can be one of Imperative, Data-flow, UI layout etc. 

* Linear/Tree/Network: The structure built by the composition relationships can be linear, a tree structure or a general graph or network. 

* Syntax: The syntax for the composition of two joined elements can be using spaces, dots or lines on a diagram. We can use various types of bracketing or indenting for the text form of tree structures.

In ALA, we are setting up to do composition of user stories. We want the composition to have the following properties:

* Composing course grained expressive elements by letting them be specialized to your domain.
* Allow use of many programming paradigms (meaning of composition)
* Allows linear, tree or network structures.
* Allow new programming paradigms with new meaning if that's the best way to express typical requirements.
* Uses the same syntax for all composition relationships.

ALA can therefore be thought of as a 'generalised compose from abstractions' methodology. 



=== No Data coupling

In conventional programming, data coupling is considered unavoidable.

The word coupling here is used for both the fact that one module communicates data with another and the fact that the modules must agree on the meaning of that data.

The actual communication of data at run-time is not a problem. The sharing of the knowledge on how to interpret that data is. In ALA we only refer to the later as coupling (remember coupling occurs at design-time). ALA eliminates this coupling.

There is a misconception meme that two modules have to share the knowledge of the meaning of data if they communicate at run-time. Even if you have a basic understanding of ALA, you may be still trapped by this misconception. This will cause you to write modules in the conventional way and they will have coupling.

To overcome this misconception, we will use a specific example. Let's say there is a temperature sensor on a Mars rover. The temperature is to be displayed at a ground station on Earth.

In conventional programming, to implement this user story, one module resides in the Mars rover and one module resides in the ground station. These two modules must agree on the meaning of data. For example, it is an integer number of tenths of degrees C (Celsius). 

Obviously a lot of other system parts are involved in transporting the data from the sensor module to the display module. These are referred to as middleware. It is common to _containerise_ the data so that none of the middleware needs to know what the data is. But the two end points must have shared knowledge.

How does ALA avoid this shared knowledge. The anwser is that in ALA, you use a single module (application layer abstraction) to implement the user story. 

This single abstraction contains all the knowledge of this user story. What this single abstraction does is instantiate an abstract display, instantiate an abstract ADC converter, and logically wire them together. Since we want to display the temperature in tenths of degrees, we will also wire in an instance of a convert abstraction and configure it to convert raw ADC readings to tenths of degrees.

Then, also inside the user story abstraction, we annotate the three instances with their physical locations. An abstraction that knows about the concept of _physical view_ has already been configured to know about the two physical locations for this application. The physical view engine takes care of deploying the instances of abstractions for the user story to the correct locations, and it takes care of actually connecting both ends through the middleware.  

That's how you do it in ALA. There is no data coupling involved.

This technique fails when the module at one end already exists in a 3rd party system with an API. The 3rd party is not using ALA. Now there must be coupling. The coupling manifests as a design-time communication from one party to the other, probably in the form of a specification.

In this situation it is still possible to mitigate the effects of coupling somewhat. Let's say the display end has been written by the 3rd party, but is written in such a way that it accepts _self describing data_ according to a standard. Without changing the display end, the user story can be implemented from scratch by sending to the display the self describing data. The display then knows how how to receive the label and display format (which can be sent once) as well as the numeric data. The display knows how to create a space for displaying the data. This is how browsers work. 

If the situation is the other way around, if a 3rd party is providing the installed sensors and the API for it, then we can't avoid the coupling. We must know about the API at design-time. It is common for example, for a 3rd party to provide a sensor and publish the data on an MQTT server. Say we are then writing an application to use this data, not only display it, but interpret the data as well. We have no choice but to be coupled with knowledge provided by the 3rd party about the MQTT topic that we need to subscribe to.

But, if the 3rd party is selling you sensors that you install yourself and selling you the MQTT communication infrastructure, then you could be provided with a more abstract 'configuration API' from the 3rd party. You would then write a domain abstraction that knows about that configuration API. Then, whenever you want to do a new user story, you can use an instance of that 'device configuration' abstraction. You can fully configure the MQTT topic itself, and its data format, then subscribe to it and process it. Everything specific to the user story is now cohesively contained inside a single abstraction once again. 

=== Composability and Compositionality

We have used the word _compose_ a lot so far in describing ALA. Now we look at the property of  _composability_ which enables us to compose. Composability means the ability to create an infinite variety of applications by combining instances of a finite number of domain abstractions.

This is a very important property of ALA. Composability uses the Principle of Compositionality which states: In mathematics, semantics, and philosophy of language, the principle of compositionality is the principle that the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them. 

Jules Hedges says of this property "I claim that compositionality is extremely delicate, and that it is so powerful that it is worth going to extreme lengths to achieve it." 

In software engineering, it is described by a pattern called "Abstract Interactions" or "Configurable Modularity" by Raoul de Campo and Nate Edwards - the ability to reuse independent components by changing their interconnections but not their internals. It is said that this characterises all successful reuse systems. 

ALA has these properties by using domain abstractions with ports, which are instances of programming paradigms. The domain abstractions are the constituent expressions, and the programming paradigms are the rules used to combine them. 

As mentioned earlier, there are other software systems that have composability, usually using the data-flow paradigm, such as RX (Reactive Extensions), or more generally monads. Most composability systems are restricted to a single paradigm. For ALA to have the correct level of expressiveness of all requirements multiple different programming paradigms are needed.

We can make an analogy with Lego bricks. Some Lego parts have the familiar little stud and tube connectors. Some will support axles and holes connections, either tight or loose. These different ways of connecting Lego parts are analogous to different programming paradigms. Each has a different behaviour at run-time. 


=== Some real dependency graphs

Our example project for this chapter is a real legacy application (that was maintained for approximately 10 years) that we decided to re-write using ALA. Normally, for reasons I won't go into here, I would never re-write an application. Maintenance had become difficult with this legacy code, and we wanted to run a research experiment to see if a rewrite using ALA could be successful. It would also give us a good basis for comparative metrics of the two code bases.

The original application has around 30 KLOC. Rather than look at any of the details of the application itself, we present here dependency graphs generated by Ndepend for the old legacy application and new ALA application.

==== Legacy application dependency graphs

One of the core tenets of ALA (as discussed in Section 3.2) is "Composition using layers" instead of "Decomposition using encapsulation". Unfortunately Ndepend is designed with the assumption that the application should be built using the latter approach. It likes to present a decomposition structure, starting with assemblies (packages) at the outermost level, then namespaces, and then classes. I'm not sure why it considers namespaces a viable encapsulation mechanism because they don't provide encapsulation. Anyway, here is the namespace dependency graph for the main assembly of the legacy version of the application, as it comes out of ndepend.

image::old-datalink/namespaces.png[namespaces.png, title="Legacy application - namespaces", link=images/old-datalink/namespaces.png]

This graph is quite large, so if you like you can right click on it, and open it in a new tab in your browser. The red arrows are dependencies in both directions.

Each box represents a namespace. The thickness of the arrows is proportional to the number fo dependencies. The size of the boxes is proportional to the number of lines of code in the namespace.

If we drill down into the largest namespace, UIForms, we see the class relationships between classes inside that namespace:


image::old-datalink/classes-in-uiforms-namespace.png[classes-in-uiforms-namespace.png, title="Legacy application - classes in uiforms namespace", link=images/old-datalink/classes-in-uiforms-namespace.png]

Here you can see that ndepend is trying to make out the layers. The layers are vertical columns, going from left to right. I have left them vertical even through ALA abstraction layers are usually drawn horizontal because they come out more readable on the page. Again there are many dependencies in both directions drawn in red.

Here are the classes inside the DataStructure namespace:

image::old-datalink/classes-in-datastructure-namespace.png[classes-in-datastructure-namespace.png, title="Legacy application - classes in datastructure namespace", link=images/old-datalink/classes-in-datastructure-namespace.png]

Again, Ndepend is trying to make out the layers from left to right.

There is one class called Device which actually looks like it might be a good abstraction.


As mentioned, namespaces provide no useful decomposition structure. They do not make abstractions in themselves, nor do they implement a facade pattern or an aggregate root type of pattern with even logical encapsulation. Any classes inside each namespace can have unconstrained relationships with any classes in any other namespace.

So Ndepend is giving us a false picture here, because it is omitting all dependencies that go in or out of the namespaces. To really get an idea of what the big ball of mud looks like, I configured Ndepend to use a query that gives me all the classes in all the namespaces. Here finally is what this application truly looks like: 

image::old-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="Legacy application - all classes in all namespaces",link=images/old-datalink/classes-in-all-namespaces.png]

This graph is very large. Right click on it, and open it in a new tab in your browser, so you can zoom in to see the dependencies in the background. It is truly frightening. Ndepend had no chance to find the dependency layers. There may be vaque onion type layers going outwards from the middle. It makes readily visible why continued maintenance on this application is so difficult. You have to read a lot of code to find even a tiny part of this hidden structure.

The developer who maintains the application tells me this is a fair projection of the complexity that he has to deal with.

To be fair, some of the dependencies in this diagram are 'good' dependencies (as described in Section 3.1 on good and bad dependencies). For example, the box near south-east called ScpProtocolManager has a lot of dependencies coming into it, which means it is possibly used a lot and therefore is a potential good abstraction. Ndepend does not know about the concept of good and bad dependencies, but if it did I would have it just display the bad ones.   


==== New ALA application dependency graphs

Here is the equivalent Ndepend generated class dependency graph for the new ALA version of the application.

image::new-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="New ALA application - classes in all namespaces", link=images/new-datalink/classes-in-all-namespaces.png]

Ndepend has tried to find the three ALA layers which are vertical and go from left to right. Only the Application sits in the top layer. The DomainAbstractions layer contains the next two columns of classes and a few from the next column. And the ProgrammingParadigms layer contains the rest on the right. Actually there were a couple of bad dependencies present when this graph was generated which have since been fixed. (There should be no dependency between Panel and OptionBox, nor between Wizard and WizardItem.) With these removed, the graph would form into the three abstraction layers. 

The newly rewritten application is a work in progress at this point. However, as features are added, this is all the dependencies you will ever see. The Application already uses most of the domain abstractions we will ever need, and the domain abstractions already use the programming paradigm interfaces they need. There are a few DomainAbstractions to be added, but this is essentially what the  class dependency graph will look like.  


This graph has the classes from all namespaces. But just for interest, here is ndpend's namespace dependency graph.


image::new-datalink/namespaces.png[namespaces.png, title="New ALA application - namespaces", link=images/new-datalink/namespaces.png]

Remember in ALA, we do not use decomposition, so namespaces do not represent decomposition of the system. They represent layers. You can clearly see the three layers. The wiring namespace also goes in the programmingparadigms layer.


Let's drill inside the domain abstraction namespace to see the interdependencies within that layer. We expect to see no dependencies:


image::new-datalink/classes-in-domainabstractions-namespace.png[classes-in-domainabstractions-namespace.png, title="New ALA application - classes in DomainAbstractions namespace", link=images/new-datalink/classes-in-domainabstractions-namespace.png]


Ok here we see the two previously mentioned bad dependencies, and two other dependencies. They are on delegates or enums in the same source file, and so don't count as bad dependencies.

And finally, let's drill into the ProgrammingParadigms namespace

image::new-datalink/classes-in-programmingparadigms-namespace.png[classes-in-programmingparadigms-namespace.png, title="New ALA application - Classes in Programming Paradigms namespace", link=images/new-datalink/classes-in-programmingparadigms-namespace.png]

Again we see a few dependencies on delegates in the same source file which are ok. There is a couple of connector classes that depend on interfaces in this same layer. I consider them part of the interface from the programming paradigm point of view. They are in the same source file as a cohesive unit.

As of this writing, the new ALA version of the application is still a research project, but so far everything has gone smoothly with two weeks spent doing the description of the requirements as a diagram, and three months so far spent writing the domain abstractions. So far there are no issues getting it to actually execute. It is expected that we will actually commercialize the project soon and replace the old application.


==== The application's diagram

As we said in this chapter, diagrams can be an important aspect of ALA when the user story naturally contains a network of relationships among its instances of abstractions. In this application this is the case. There are UI relationships between elements of the UI. There are data-flow relationships between UI elements, data processing elements, and data sources. There are event-flows from UI to wizards and between wizards and the SaveFileBrowser. and there are minor data-flows such as a the filepath from the file browser to the csvFileReaderWriter.

Here is a sample section from the application diagram that shows all the relationships that implement the user story:

image::DatalinkApplication.xmind.png[DatalinkApplication.xmind.png, title="Xmind being used to design an application", align="center"]

This diagram was drawn using Xmind. It shows a single user story.  There is a UI with a menu item or a tool bar to start the user story. It then displays a browse dialogue to specify the location of the file. When the filepath has been selected, it gets data off a device on a COM port, using a protocol, and writes it to a CSV file. The data is also routed to be shown on a grid on the UI.

The user story diagram makes use of four different programming paradigms (which become four different interface types). Firstly there is the UI structure consisting of the window with its menubar, grid etc arranged inside it. Secondly, there is an event connection for when the menu is clicked which opens the browse dialog. Thirdly a data-flow connection carries the output of the browse dialog, a string containing the selected filepath, to the CSVFileReaderWriter. Another data-flow connection carries characters between the COM port and the SCPProtocol and another carries SCPcommands from the SessionDataSCP. The forth programming paradigm is a table data flow that carries dynamic columns and rows of data from the SessionDataSCP object to the grid object in the UI and to the CSVFileReaderWriter. 

Having drawn the diagram to represent the user story, we need to make the diagram execute. When we started this particular project we had no tool for automatically generating the code from the diagram, but during the project, one of the interns wrote a tool to do this. It parsed the Json output from Xmind and generated C# wiring code equivalent to what we will show below.

However, at first we were hand generating code, and it is instructive to know what this hand generated code looks like, just so we know how the diagram actually executes. 

When we were hand generating the code, it was important that the code was readable from the point of view of seeing how it corresponds exactly with the diagram. (It wasn't important that the code was readable from the point of view of seeing how the user story works - that was the job of the diagram.)  We had various conventions to support the one to one matching of diagram and code. One of these conventions was to indent the code to exactly mirror the tree structures in the diagram. Another was that whenever a new instance of an abstraction instantiated, all its ports would be wired immediately, and they would be wired in the order they were declared in the abstraction. This implies a depth first wiring strategy, analogous to walking the diagram tree depth first. Any ports with cross connections (the red lines in the diagram) would also be wired to their destinations at the time the abstraction were instantiated. If the destination instance did not already exist it would be pre-instantiated. 

Using these conventions, it is a simple matter to hand generate the code below from the diagram.


....
using System;
using System.Windows.Media;
using DomainAbstractions;
using Wiring;


namespace Application
{
    class Application
    {
        private MainWindow mainWindow = new MainWindow("App Name") { Icon = "XYZCompanyIcon"};

        [STAThread]
        public static void Main()
        {
            new Application().Initialize().mainWindow.Run();
        }

        private Application Initialize()
        {
            return this;
        }

        private Application()
        {
            var getInfoWizard = new Wizard("Get information off device") { SecondTitle = "What information do you want to get off the device?" };
            Grid DataGrid;
            var sessionDataSCP = new SessionDataSCP();
            var csvFileReaderWriter = new CSVFileReaderWriter();

            mainWindow
            // UI
                .WireTo(new Vertical()
                    .WireTo(new Menubar()
                        // XR3000
                        .WireTo(new Menu("File")
                            .WireTo(new MenuItem("Get information off device") { Icon = "GetDeviceIcon.png", ToolTip = "Get session data or LifeData or favourites from the device\nto save to a file or send to the cloud" }
                                .WireTo(getInfoWizard)
                            )
                            .WireTo(new MenuItem("Put information onto device") { Icon = "PutDeviceIcon.png" })
                            .WireTo(new MenuItem("Exit") { Icon = "ExitIcon.png" })
                        )
                        .WireTo(new Menu("Tools"))
                        .WireTo(new Menu("Help"))
                    )
                    .WireTo(new Toolbar()
                        // XR3000
                        .WireTo(new Tool("GetDeviceIcon.png") { ToolTip = "Get information off device" }
                            .WireTo(getInfoWizard)
                        )
                        .WireTo(new Tool("PutDeviceIcon.png") { ToolTip = "Put information onto device" })
                        .WireTo(new Tool("DeleteDeviceIcon.png") { ToolTip = "Delete information off device" })
                    )
                    .WireTo(new Horizontal()
                        .WireTo(new Grid() { InstanceName = "Sessions" })
                        .WireTo((DataGrid = new Grid() { InstanceName = "DataGrid" })
                            .WireFrom(sessionDataSCP)
                        )
                    )
                    .WireTo(new Statusbar()
                        .WireTo(new Text() { Color = Brushes.Green }
                            .WireFrom(new LiteralString("Connected to device"))
                        )
                    )
                );


            getInfoWizard
                .WireTo(new WizardItem("Get selected session files") { Icon = "IconSession.png", Checked = true }
                    .WireTo(new Wizard("Select destination") { SecondTitle = "What do you want to do with the session files?", ShowBackButton = true }
                        .WireTo(new WizardItem("Save selected sessions as files on the PC") { Icon = "SessionDocumentIcon.png", Checked = true }
                            .WireTo(new SaveFileBrowser("Select location to save data") { Icon = "SaveIcon.png", InitialPath = "%ProgramData%\XYZCompany"}
                                .WireTo(csvFileReaderWriter)
                            )
                        )
                        .WireTo(new WizardItem("Send records to NAIT") { Icon = "NAIT.png" })
                        .WireTo(new WizardItem("Send sessions to NLIS") { Icon = "NLIS.png" })
                    )
                    .WireTo(getInfoWizard)
                )
                .WireTo(new WizardItem("Get Lifedata"));

            var comPorts =
                new ComPortAdapter()
                    .WireTo(new SCPProtocol()
                        .WireTo(new SessionDataSCP()
                            .WireTo(DataGrid)
                            .WireTo(csvFileReaderWriter)
                        )

                    );

        }
    }
}
....

We used a 'diagram first' rule to keep the diagram and code in sync. Change the diagram first, then change the wiring code.

As of this writing, a graphical IDE is being developed for these types of ALA applications.








