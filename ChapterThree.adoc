:imagesdir: images

== Chapter three - Why the structure works

In the previous chapter we described what the structure, the anatomy, of ALA looks like as if we were dissecting a dead body. We saw where things are located but we didn't get an understand of why they are there. In this chapter we explain why that structure works. Why does this way of organising code result in software that meets those non-functional requirements we listed in Chapter one?

The organisation of this chapter (and all chapters) is to use different perspectives. We all have different prior knowledge on which we build new knowledge, so we will each have a different best way to understand things. Use the perspective that makes the most sense to you. Because of the use of perspectives, there will be some repetition of ideas between the major sections in this chapter. 


=== A thought experiment

For this first perspective, imagine you are reading the following function, abc123, and trying to understand it:

 float abc123(float[])
 {
     ...
     b = xyz789(a)
     ...
 }

 float xyz789(float)
 {
     ....
     // complicated code
     ....
 }

You see that the function _abc123_ uses function _xyz789_. So you follow the indirection, an inconvenience at the least because you are really just wanting to understand abc123. Following the indirection may involve an all files search to even find xyz789. Then it's also not clear what xyz789 does. You have to mentally stack where you were in the code at abc123, including everything you understand about it so far, and start concentrating on xyz789. 

Despite only having about 20 lines of code, xyz789 is complicated. You need to use the code in abc123 to try to unravel what xyz789 might be providing for it. A comment mentions that it uses a CORDIC algorithm and gives a reference. But before following that indirection as well, you note that both abc123 and xyz789 have the following properties:

* they are modules
* apparently loosely coupled 
* have a simple interface
* use encapsulation of internals
* use no external variables
* have no side effects
* hide information
* probably separate two concerns
* are small
* follow coding guidelines
* have comments

Despite having all these great properties that we are taught our code should have, we are still forced to read both functions to understand the code in either of them. They are effectively fully coupled at design-time - understanding any of the code involves understanding all of the code.  

Now we make one small change: 


 float StandardDeviation(float[])
 {
     ...
     b = Sqrt(a)
     ...
 }

 float Sqrt(float)
 {
     // complicated code
 }

Suddenly understandability is absolutely transformed. All we did was make the two functions abstractions. Now we don't have to read the complicated code inside xyz123 at all. We don't have to follow the indirection. The code inside each of the two functions goes from highly mutually coupled to zero coupled. 

All those other attributes that we listed above seemingly made no difference. The quality attribute that really mattered was abstraction. The others are still good to have, but they are completely insufficient. The abstraction property is _the_ one that our brains have evolved to use.

The quality of abstraction is somewhat subjective. We don't really have a good way to measure it. No compiler or tool can yet check that quality. However, a software engineer's job is inventing good quality abstractions. 

* In the downward direction, design-time coupling goes to zero because the standard deviation function need only know about the concept of the square root abstraction, not about any of the code that implements it.

* In the upward direction, coupling goes to zero because we don't need to know about the caller to try to tease out what we are providing. By being an abstraction, square root is reusable, and can't know anything about the more specific Standard deviation abstraction that happens to use it. 

There are other benefits too:

* Abstraction and stability go hand in hand. The Sqrt abstraction is as stable as the concept of squareroot. That's a concept that's been stable for thousands of years. The Standard Deviation function has a dependency on something that has been stable for thousands of years! All dependencies in an ALA program go in the direction of the more stable.  

* Abstraction and reuse go hand in hand (as pointed out by Krueger). The more abstract an abstraction is the more reusable. Code reuse in ALA programs increases markedly.  

* The complicated code inside SQRT no longer matters at design-time. It is completely isolated by the abstraction. If your brain already knows the SQRT concept (I had to choose one that everyone knows), there is no need to follow the indirection when reading the code inside StandardDeviation. The reader just continues reading the next line of code after the Sqrt invocation as if Sqrt is just like any other line of code in their base language. That's what abstraction does, and only abstraction can do this. If you don't already know what a given abstraction is from it's name, then you need to follow the indirection once and read a comment that should describe each abstraction written just ahead of each abstraction. 

With this new understanding, we will now define the word dependency to be compile-time relationships, and coupling to be the design-time. One is what the compiler sees, the other is what our brain sees. 

Using these definitions, you can have coupling without dependencies (sometimes called implicit coupling). The reverse is also true - it is possible to have dependencies without coupling. ALA makes use of this by simply making a constraint that all dependencies must be on abstractions. When you do that, every artefact (abstraction) in the program is zero-coupled with every other. 

Doing this isn't always easy because unfortunately there are many established architectural methods, patterns and styles that break this constraint. On the other hand, applying this constraint emerges some patterns that we will immediately recognise. DSLs and dependency injection are two examples. We will also emerge some less well known ones that are none-the-less not novel. There already exists an "abstract interactions" pattern, for example, which uses interfaces that are more abstract than the modules using it.


There are two situations that commonly cause coupling in conventional code:

. In the above example, imagine that xyz789 isn't an abstraction that is more abstract than abc123. Lets pretend for a moment that its just a source or destination for messages (in the same abstraction layer as abc123) such as a display. Then abc123 cannot be an abstraction because it cannot be reused without dragging xyz789 with it. If abc123 is an abstraction, it cannot know (or care) where the data comes from or goes to. To fix this, xyz789 must be passed into abc123 by something else above both of them. In other words, they must be composed. This can be passing in a function, passing in an object (dependency injection), or other mechanism such as function composition, monad composition, or the WireTo operator that we will use a lot in our ALA example projects.
+
In conventional code, if abc123 calls directly xyz789, then the connection relationship between abc123 and xyz789 is hidden inside abc123. In ALA that relationship has to be an explicit line of code (inside another abstraction) in the layer above that composes the two instances. There, it will be cohesive with other similar relationships that work together in a collaborative way to make the application. 
+
Often these collected together wirings form a graph, making diagrams rather than code an even better way to describe the application.

. In conventional code, if xyz789 provides a part of the implementation of abc123, it will be more specific than abc123. Sometimes such a function or class is called a helper or submodule because xyz789 could only ever be used by abc123. In ALA xyz789 needs to be significantly more abstract than abc123 or it will be highly coupled to it. If xyz789 is put inside abc123 the complexity inside abc123 is still that of both of abc123 and xyz789 together.
+
This is contrary to what we are taught. We are taught to "divide and conquer" or to separate out the responsibilities. If we do this arbitrarily, we will end up with specific pieces (such as UI and business logic) which are highly coupled with each other, and with the specific application. We need to work hard to separate only by finding abstractions - potentially reusable artefacts. Then we configure instances of those abstractions for each specific use by passing the application specific details into them.  

In summary, ALA's starting premise is a constraint. The constraint is that you can only use one type of dependency - a dependency on an abstraction that is significantly more abstract than the one using it. This is not only quite feasible, but results in zero coupling throughout the entire program. 


=== Abstractions

In this perspective, we look at what abstraction really are. This is itself the most abstract perspective we will take in this chapter.

==== Design-time encapsulation

[IMPORTANT]
====
[green]#*Abstractions*# are the human brain's version of [green]#*encapsulation*#.
====

The maintainability quality attribute is often thought of in terms of ripple effects of change. I don't think that is quite the right way to look at it. I have often had to make changes across a number of modules in poorly written code. The changes themselves just don't take that long. The problem I see is the time you have to spend understanding enough of the system to know where to make a change, even if it ends up being just one line of code in one place. To make that small change with confidence that it wont break anything can take a long time understanding the collaboration between modules. You may have had to understand a lot of code to figure that out. You have to understand all the code that is potentially coupled to that one line of code, which is essentially the complexity.

Unlike encapsulation which works at compile-time, abstractions hide complexity at design-time. They give boundaries to how far you have to read code to understand it.



==== Abstractions and Instances

[IMPORTANT]
====
[green]#*Software architecture*# should contain [green]#*two concepts*# for its [green]#*elements*#  equivalent to [green]#*abstractions*# and [green]#*instances*#.
====

If you are going to have abstraction, it makes sense that you would have instances. 
An instance is nothing more than the use of an abstraction by referring to its name. If your abstraction is a pure function, then an instance is just using the function, or getting a reference to it.

If your abstraction is a class, and if that class contains data, then you need to instantiate the class so that each instance has its own data. Object oriented languages of course already have these two concepts as classes and objects. 

Many discussions on software architecture seem to combine them into one term, such as modules or components. These terms may implicitly contain the separate concepts of abstractions and instances, or they may be intended to have only one instance, in which case it can't be an abstraction. Not having explicit terms, like class and object, will inevitably lead to confusion. In ALA the terms we use are abstractions and instances.

The problem is that when we become vague about the difference between abstractions and instance, we will then create dependencies between abstractions such as to get or put data. If you create dependencies between peer abstractions, they are no longer abstractions. Instead you need to wire the instances. If we don't have two separate and clear terms for abstractions and instances, we will end up with no abstractions. All architectural styles based on a 'divide and conquer' methodology appear to have this problem.

A confusion comes from the UML class diagram, which already has the separate concepts of classes and objects. However it actually encourages you to create relationships between classes, destroying them as abstractions. The most important potential idea that OOP brought us was the idea of classes as reusable abstractions, and objects as their instances. It never happened in part because of the UML class diagram, and the very harmful habit of putting dependencies between abstractions instead of wiring instances. 

****
The quality of an abstraction's _concept_ or _idea_ is important. It is the existence of the concept that allows the brain to learn it and not have to know how it's implemented each time it uses it. It is the concept of the abstraction that blocks coupling. ALA sometimes requires some effort to conceive good abstractions, especially for the first application in a new domain.
****

==== Abstractions enable composability

An important property of abstractions is that instances of abstractions can be composed or assembled in an infinite variety of ways. We call this composability. We discuss composabilty in detail in a section below.

Even the tiniest amount of coupling between two abstractions completely kills composability, meaning they are no longer abstractions. So one test of abstractions is composability of their instances. If any two potential abstractions must work together, then they are not abstractions, they are just modules.



=== Zero coupling and higher cohesion

In this perspective, we look at ALA in terms of coupling.

==== Zero coupling

****
Larry Constantine, who coined the expression "loose coupling and high cohesion" wrote: "The key question is: How much of one module must be known in order to understand another module?". That is the essence of the most useful way to think about coupling in software.
****

ALA has mutual zero coupling between the code inside (the code that implements) all abstractions. This is the case both horizontally between peers in the same layer, and vertically up or down the layers. 

In software development we are only interested in design-time coupling. This means that to understand one piece of code, how much do we need to know about other pieces of code? It is about knowledge, which is about design-time. This is the coupling that matters. 

We will use the word _coupling_ to mean design-time coupling. That's consistent with Larry Constantine's statement. His reasoning came from identifying how to reduce complexity, the time taken to understand software, and reducing the incidence of bugs.

Here is a typical definition of Loose coupling from the internet: "*Loose coupling* refers to minimal dependencies between modules, accomplished through strict, narrow, stable interfaces at the boundaries." 

This definition of coupling differs from ALA's in two respects.

Firstly, we are not minimizing dependencies. We are eliminating bad dependencies and maximizing good dependencies (as discussed later).

Secondly, it's not just about using interfaces. A lot of design-time coupling is what I call _collaboration coupling_. Collaboration coupling is when one module does specifically what another module needs. Collaboration between two modules is often mutual. It's characterised by the modules having a fixed arrangement with each other (for example, an MVC type of arrangement). (To understand what we mean by "a fixed arrangement", see the section below on the opposite of a fixed arrangement, which is composability.)

An interface between two modules that have a fixed arrangement with each other may hide some details, but it doesn't prevent fundamental collaboration between the two modules. When modules have a fixed arrangement with each other, collaboration will tend to increase during maintenance.

Some definitions of coupling are in terms of the ripple effects of change. But even if a change ends up being made in just one place, that doesn't mean you didn't have to understand code in multiple places before you could understand how to make the change. I have many time spent a day understanding code only to end up changing one line. So this is not a good definition.

Wikipedia defines coupling as "the degree of interdependence between software modules". It doesn't really distinguish between design-time, compile-time or run-time coupling, and the given formula for coupling seems to reflect compile-time. We need to think of coupling as a design-time property. It is about knowledge of internals of a module. Compile-time and run-time dependencies do not matter. Only design-time coupling matters. 

Abstractions are the only type of modules that allow us to achieve zero coupling.

Unfortunately there is a meme in the software engineering industry that there must be some coupling between modules. The argument goes that if the system is to do anything it must have some coupling between its parts. We therefore hear of "loose coupling" as being the ideal. Using the definition of coupling given above, this is completely incorrect. It's confusing run-time coupling with design-time coupling. Only design-time coupling does. If I connect an instance of difference table generator to an instance of a printer, that run-time coupling between the instances doesn't create any coupling between the concept of a difference engine and the concept of a printer. I can still understand either concept's implementation in complete isolation, even though it's possible to connect instances of them together to form a working system.   

Because of this bad meme, in conventional code we have developed a habit of using dependencies to implement communications. We are settling for design-time coupling to implement run-time communications between different parts of a system. It is not necessary. Part of the problem is that we are seldom taught the difference between design-time and run-time coupling. So I prefer to use the words _connection_ or _wiring_ used for communications between instances of parts in a system. 

For example, in conventional code, if function Switch calls function Light, the code inside Switch is coupled with Light. If the light's abstraction level is about the same as that of the Switch (which it is), then the abstraction of Switch is destroyed. When you reuse it you have to know the internal code brings in a Light as well. To understand the _system_ (a Switch connected to a light), you have to go inside the Switch:


[plantuml,file="switch-light-bad.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=LR]
subgraph cluster_1 
{
label="Switch"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="Light"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=red, label=""]
}
@enddot
----


If instead, a separate abstraction called "System" has code inside it like Light(Switch()), then Switch remains a good abstraction whose internal code is now only concerned with how a switch works. The code inside all three abstractions is now zero coupled. Understanding the system no longer requires looking inside Switch:  

[plantuml,file="diagram-collaboration-A-B-C.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
A [label="System\n\nx=Switch(); Light(x);"]
}
@enddot
----

{empty} +

[plantuml,file="diagram-collaboration-B-C-invis.png"]
----
@startdot
digraph foo {
size="1.5!"
graph [rankdir=LR]
Switch -> Light [style=invis]
}
@enddot
----




A similar argument applies if Switch and Light are classes. In conventional code they will commonly have an association relationship. Even if Light is injected into Switch by a higher entity called System, Switch still knows the specific interface of a light (LightOn(), LightOff()). This interface is not abstract enough to prevent Switch knowing about Light, and Switch knowing about the System. If you instead have a class, System, that has code like new Switch().WireTo(new Light()) using a generic interface then all three abstractions are zero coupled.

ALA _never_ uses coupling for connections or wiring between parts of a system. A larger system typically consists of many connections. These connections are typically cohesive, and belong in one place. In conventional code they tend to be distributed and buried inside the modules. A smell is that you are doing 'all files' searches to unravel them. In ALA, they are brought out into their own place as a cohesive new abstraction describing a specific user story or system.


==== Cohesion


[TIP]
====
"In ALA, [red]#*Collaboration*# becomes [green]#*cohesion*#".
====

What would be collaboration between modules in conventional code becomes cohesion inside a new abstraction in ALA. A call from one module to another becomes a single line of code inside an abstractoion in a higher layer. Would be collaboration between a group of modules for a single purpose or user story (like MVC pattern) becomes several cohesive lines of code in the higher layer. Those several lines of code are cohesive. 

Cohesion also increases for the modules as they become abstractions. An abstraction is closely aligned with the single responsibility principle. We can think of abstraction as a "single concept principle" instead of "single responsibility principle". Using abstractions increases the cohesion of the code that implements the abstraction.

ALA provides no structure for the internals of an abstraction because the code is cohesive. The internals of an abstraction could be described as a small ball of mud, which is why they should be small. There is no such thing as a sub-abstraction. Instead the code is composed of instances of abstractions from lower layers. So in ALA, layers replace what would be hierarchical encapsulation in conventional code structures.

Zero coupling and higher cohesion blocks ripple effects of change, whether in higher layers or lower ones. A ripple stops at an abstraction concept because of the inherent stability of the concept itself.

What can happen though is that abstractions can be improved to be better quality abstractions. Often you can generalize an abstraction to make it more reusable by adding a configuration. The configuration has a default, so it doesn't affect existing uses of the abstraction (convention over configuration).

In our experience, the most common type of change that still affects multiple abstractions are changes to code _conventions_. Conventions in the ways abstractions are commented, and their code laid out are effectively abstractions in themselves that live in a bottom layer. So when they change, it makes sense that all abstractions that depend on them change. These conventions will mature over time. Besides, while these types of changes may require a lot of editing, they don't require simultaneous understanding of multiple modules, which is where the real problem with coupling lies. 


=== Good versus bad dependencies

In this perspective, we look at ALA in terms of good and bad dependencies.

Often software engineering design is done from the perspective of managing dependencies. 

A dependency is when some code symbolically refers to a class, interface or function or other artefact that's in a separate piece of code. This covers everything from dependencies on classes, interfaces, modules or components, to dependencies on libraries or packages. 

A dependency can be on something public inside a class or interface, usually a method or property. Even if using an object reference, there is still a dependency if there is a reference to something named inside the class or interface. 

We need to distinguish between good and bad dependencies. Good dependencies are  design-time dependencies. These are dependencies on concepts you must know to even understand a given piece of code. I will often refer to this type as a "knowledge dependency" or "use of an abstraction". It is also sometimes called "semantic coupling". This type of dependency effectively adds to the language you use to write code. Here is a diagram showing a good dependency.


[plantuml,file="GoodDependency1.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=TB]
subgraph cluster_1 
{
label="Abstract"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="MoreAbstract"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=green, label=""]
}
@enddot
----



A bad dependency is one that is there to facilitate run-time communications between two modules or components. Here is a diagram representation.



[plantuml,file="BadDependency1.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=LR]
subgraph cluster_1 
{
label="Peer1"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="Peer2"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=red, label=""]
}
@enddot
----



Another type of bad dependency is when a module uses a submodule that is a specific part of it:

[plantuml,file="BadDependency2.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=LR]
subgraph cluster_1 
{
label="Module"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
B [label="Submodule"; shape = rect; style=rounded ]
}
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=red, label=""]
}
@enddot
----

An example is a 'helper' class. The submodule is often thought of as being logically contained inside its parent module, even if it not actually encapsulated inside it, because the module is not used by anything else.


[TIP]
====
[green]#*Dependencies on more abstract abstractions are good*#.
====
[WARNING]
====
[red]#*Dependencies for communciations between peers are bad, as are dependencies on submodules*#.
====

A simple example of a communication dependency is a module that calculates the average then calls a display module to display the result. To understand the code that calculates the average requires no knowledge about displays, nor even where the result will be sent. So it is a bad dependency.



[plantuml,file="BadDependency3.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=LR]
subgraph cluster_1 
{
label="Average"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="Display"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=red, label=""]
}
@enddot
----

The intention of the fixed arrangment between Average and Display was to measure rainfall. To do that, an instance of an Average module needs to be connected to an instance of Display module at run-time, but you don't need a bad dependency to achieve that. Instead you use two good dependenies:

[plantuml,file="GoodDependency2.png"]
----
@startdot
digraph foo {
size="2.0!"
graph [rankdir=TB]
subgraph cluster_1 
{
label="Rainfall"
labeljust=l
style=rounded 
A [shape = "circle", width=0.1, fixedsize=true, style=invis]
#[ style = invis ];
}
B [label="Average"; shape = rect; style=rounded ]
C [label="Display"; shape = rect; style=rounded ]
A -> B [dir="both", arrowhead="open", arrowtail="tee", color=green, label=""]
A -> C [dir="both", arrowhead="open", arrowtail="tee", color=green, label=""]
}
@enddot
----

A simple example of knowledge dependencies occurs in an abstraction that meters rainfall. To understand the rainfall code, you must understand the concepts of average and of display. It's a good thing to build the rainfall meter abstraction using the concepts of averaging and displaying. 

We typically find both good and bad dependencies in conventional code. A typical modular program is full of bad dependencies. But whether a knowledge dependency or a communication dependency, they all look syntactically the same - a function call or a 'new' keyword or a method call. We are not generally taught how to distinguish between them. We lump them together when we talk about dependency management, loose coupling, layering, fan-in, fan-out, circular dependencies or dependency inversion. Dependency graphing tools do not distinguish between them because identifying good dependencies would require understanding the levels of abstraction. 

Good and bad dependencies are not just good and bad. They are really good and really bad.

A knowledge dependency is good because it's only a dependency on an abstract concept, something stable and learnable. Once learned we never have to follow the indirection to understand the code that uses the abstraction. We want more of them, because then we are reusing our abstractions, and that just means they are better abstractions. The more dependencies you have on an abstraction, the more abstract it is. 

Bad dependencies destroy abstractions. They cause explicit and implicit coupling. They obscure the structure of the application by distributing that structure implicitly throughout its modules.

So it's doubly important that we are able to tell good dependencies from bad. 


[TIP]
====
[green]#*ALA is simply the elimination of ALL bad dependencies*#.
====

It's entirely possible to build a system using only good dependencies. 

When we remove bad dependencies, each one is transformed into a normal line of code. That line is inside a more _specific_ abstraction in a higher layer. The line uses two good dependencies that refer to the two abstractions in the layer below, wiring them together by their ports. These lines of code are cohesive with one another instead of being spread throughout the modules, creating a new abstraction that represents the composition. 

Consider the diagram below representing the conventional modular way to write a rainfall meter. An ADC reading is averaged, converted, accumulated, and displayed. The middle three modules have bad dependencies, which they use to make function calls to pull data in and push data out. 

[plantuml,file="dependency-diagram.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1

Application

/----\    /----\    /----\    /----\    /----\.
|ADC |<---|Avg |<---|Conv|--->|Accu|--->|Disp|
\----/    \----/    \----/    \----/    \----/


key:   <---(Depends On)


@endditaa
----

There are four bad dependencies, two from Conv and one each from Avg and Accu.

Now consider this diagram, where we have transformed it to use only good dependencies.


[plantuml,file="dependency-diagram-1.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1

    /------------------------------\.
    |Application                   |
    |                              |
    |adc---avg---conv---accu---disp|
    |                              |
    \------------------------------/


--------------------------------------------------
Abstractions

/----\  /----\  /----\  /----\  /----\.
|ADC |  |Avg |  |Conv|  |Accu|  |Disp|
\----/  \----/  \----/  \----/  \----/


--------------------------------------------------
Programming Paradigms

            /--------\.
            |Dataflow|
            \--------/
@endditaa
----

The lines in this diagram represent wirings not dependencies. The wiring represent dataflow, a very abstract compositional concept. 

The lower-case letters used in the top layer of the diagram represent instances of the respective abstractions. (In UML they would be underlined.) 

Note that, we could have used arrows instead of lines between the instances, but the direction would not represent the direction of dependencies but the direction of the dataflow.  

There are five good dependencies from the Application to the five Abstractions. These are represented by the lower case names using the abstractions with the corresponding uppercase letters. 

There is also a good dependency on the dataflow abstraction used for the wiring.

Connections between the instances of the abstractions are completely described inside the Application abstraction. There it is cohesive code that knows about the rain meter.

The code in the application abstraction could look something like this if using functions (although you would likely use some temporary variables in practice):

[source,C#]
....
    Disp(Accu(Conv(Avg(ADC()))));
....

It might look something like this if using classes:


[source,C#]
....
    new ADC().WireIn(new Avg()).WireIn(new Conv()).WireIn(new Accu()).WireIn(new Disp());
....

How this code is implemented is not what's important. How syntactically succinct this code is is not that important. What's important is where it is. We want the code that cohesively and fully expresses a rain meter to be in one place.  

We never draw arrows on a diagram for good dependencies. Instead we just refer to the abstractions by name. (Just as you would never draw an arrow to a box representing the squareroot function - you would just use Sqrt by its name.)

In common programming languages, the communication dependencies in the first diagram and the knowledge dependencies in the second diagram could both be syntactically written in the same form, either new A() or just a function call, A(). The only difference is in where those new keywords or function calls are.

The application abstraction can move the data between the instances of ADC, Avg, etc itself, as we did in the first code example, however strictly speaking that pollutes it with details of how to move data that actually belongs in the dataflow abstraction in the programming paradigms layer. We much prefer the application code just does composing - just specifies who connects to whom, and does not get involved with how data actually flows. That's why in most of the examples, we compose with classes that have ports rather than functions. In the second code example, the dataflow programming paradigm would be implemented with an execution model that knows how to actually move data. The application only knows that it is composing a flow of data.

The interface used to connect the instances is called IDataflow. This interface is two layers down. It is not an interface specific to any one of the domain abstractions, ADC, Avg, etc. This is called the abstract interactions pattern. Domain abstractions either implement it or accept it, or both.


==== Comparison of good versus bad dependencies.


.Comparison of two approaches
[width="100%",options="header,footer"]
|====================

| Bad dependencies version | Good dependencies version

| Knowledge that is specific to the application is spread throughout the modules. | Knowledge specific to the application is in one place. 

| The class or functions, Avg, Accu and Conv have references to their peers creating a fixed arrangement between all modules. | The abstractions ADC, Avg, Accu, Conv and Disp have no fixed arrangement with each other.

| The fixed arrangement encourages implicit coupling. Avg can make assumptions about details inside ADC resulting in collaborative coupling. | Peer abstractions can make no assumptions about who they are connected to, so there can be no collaborative coupling. 

| Although there is no dependency, for example from ADC to Avg, the fixed arrangement is likely, over time, to make ADC do what Avg requires, making the collaboration coupling go both ways. | ADC remains abstract over time because it can't know what is using it at run-time.

| Since there is a fixed arrangement, responsibilities can be blurred. For example, it may be unclear whether to add extra code to Avg or Conv, or to add a new module in between and change Avg to call it instead of ADC. | Something to be added that doesn't belong in any of the existing abstractions can be a new abstraction, an instance of which may then be easily wired in between the two.

| The overall application being the ADC, Avg, Conv, Accu and Disp wired together in that order is not obvious. It is obscured inside of Avg, Conv and Accu. All must be read to find the application's overall dataflow. | The overall application being  instances of ADC, Avg, Accu, Conv and Disp wired together is explicitly coded in one place.

| Only the two ends of the dataflow chain, ADC and Disp can potentially be reused independently. | All of ADC, Avg, Accu, Conv and Disp are reusable abstractions.

| Difficult to insert another module between wired adjacent modules, e.g. between Avg and ADC. | Easy to insert a new instance into the wiring e.g. a debugging, logging, monitoring, playback, caching, or buffering instance between Avg and ADC, etc. 

| Each module has its own specific interface. | Uses a single more abstract interface called Dataflow.

| The arrangement between the modules cannot easily be changed, both because the wiring code is buried inside the modules and because the interfaces are essentially specific to pairs of modules. | The composition can easily be changed.

| There either no diagram of the arrangement between ADC, Avg, Accu, Conv and Disp or if there is, it is likely a high level overview, lacking in detail, and a second source of truth that needs to be kept in sync. | We can use a diagram for the arrangement of the instances and generate code from it, so we have one source of truth.

| The wiring between modules is represented by matching symbols in two places, one being the function call in the sending module, and one being the function itself in the receiving module. The wiring is implemented by the matching name of caller and function. These matching names must usually be found by a text search in an editor to find the wiring. If the modules are objects, there are two more places in the code involved, because there is also the code with the 'new' keyword and class name, which are also wired by a matching name. | The wiring is represented in one place, often  anonymously, by simply instantiating both objects and connecting them.

| If the observer pattern is used (in the mistaken belief that it reduces the coupling), it just reverses the bad dependency. It also adds another level of indirection. The wiring is then represented by one additional place, the code that does the subscribing of the receiver to the sender. | Observer pattern is not needed between instances of peer abstraction. The abstractions are already zero coupled.

| Consider if dependency injection is used with interfaces that are specific to the modules (or to a small set of substitutable modules), e.g. IADC, IAvg, etc. Although, for example, different ADCs could be used, the arrangement is still fixed. All the above points would still apply. But now the fixed arrangement is even more obscure. | Dependency injection is used, together with instantiating the instances all in the same code. But it uses abstract interfaces such as Dataflow so that the instances can be assembled in an infinite variety of ways. Only one place in the code knows who will talk to whom at run-time for a specific application. There are no specific interfaces between pairs of modules to change over time, because they all just use a stable abstract interface.

| The interfaces will need to change as the requirements of the system change. | Changes to requirements are accommodated by simply changing the composition of abstractions.

|====================


During code creation, run-time dependencies are easily introduced, and never seem too terrible at the time as they get the immediate job done. But when they accumulate to hundreds or even thousands of them, as they do in most typical applications, that's when the system, as described on the left side of the table, just truns into a monolithic big ball of mud.

==== Free lunch?

When you are comparing the left and right sides of the table above, you may be wondering, where did the free lunch come from? Where did the bad dependencies go? Where are the disadvantages on the right side of the table. Is this some kind of magic? How can, for example, the Avg module talk to the ADC module at run-time with no dependency on it, nor any knowledge about it? How can such a program even work? Haven't I just moved the bad dependencies somewhere else? No, there are no tricks. The only answer is that we have been taught to do programming in a very bad way, and have become used to it when we could do a lot better. The knowledge that Avg will talk to ADC at run-time is there, but it is normal code contained within a new abstraction.

If you really want to find a disadvantage, then it is the need to conceive the abstractions: Disp, Accu, Conv, Avg and ADC. It only works as well as the quality of those abstractions. Effectively we have traded the need for dependency management, and all the complexity that bad dependencies cause, with the need to create good abstractions. Creating good abstractions is a skill that does take time sometimes.

Just to recap, the only dependencies we have used are good design-time or knowledge dependencies: 

. The application should and must 'know' at design-time what domain abstractions it needs to compose to make a rain meter application.

. The domain abstractions should and must know at design-time what programming paradigm they need - the abstract interfaces to use for their input and output ports. 


==== Stable dependencies principle

A dependency on an abstraction is a dependency on the concept or idea of that abstraction. A concept or idea is generally stable. So good dependencies are also dependencies on the more stable. 

Even if the implementation details inside an good abstraction need to change, the abstraction concept itself is stable. The application example above is really just depending on the idea of an ADC or the idea of a Display. If the details inside those ideas' implementations change it doesn't matter. For example, if the ADC silicon is changed, the ADC abstraction implementation can also change. But the application is still just using an ADC. 

ALA therefore naturally conforms with the Stable Dependencies Principle (depend in the direction of stability). The SAP is mostly used in relation to packages, but ALA does not use hierarchical encapsulations. (You can use packages, but it's just a collection of abstractions that get distributed together, not an abstraction in itself.) Here we are applying the SAP at the level of the abstractions themselves.


==== Dependency fan-in and fan-out

One of the guidelines sometimes used for dependencies in conventional code is that a class that has high fan-in should not also have high fan-out (also called afferent and efferent coupling). Another is that modules higher in the dependency structure should have low fan-in and those lower in the hierarchy have low fan-out.

The argument goes that a class with high fan-in should have high stability but one with high fan-out would have low stability (presumably because dependencies are thought to be things that cause changes to propagate).

In ALA, all dependencies are on more abstract, more stable, abstractions. Therefore the conventional fan-in and fan-out recommendations are reversed. In ALA, it is perfectly fine, in fact really good to have both high fan-in and high fan-out. It simply means that the abstractions are useful and are getting reused.  

If we are talking about bad dependencies in a conventional modular system that are used for communication between modules in the system, of course ALA says we want zero fan-in and zero fan-out, because such dependencies are illegal anyway.

In chapter four we will also talk about fan-in and fan-out. Note that the fan-in and fan-out discussed in chapter four is different. In this chapter fan-in and fan-out is talking about dependencies. In chapter four we are talking about fan-in and fan-out in run-time communications the wiring. In other words one instance's output port being wired to many instances input ports.


==== Circular dependencies

Of course in ALA, with only knowledge dependencies present in the system, and the dependencies needing to go toward more abstract abstractions, you obviously cannot have circular dependencies. Nor would that even make sense. (Recursion appears to require circular knowledge dependencies but actually doesn't. We will visit that in the last chapter.) 

Since run-time communications is not implemented using dependencies, circular communications in ALA is simply circular wiring. This is perfectly fine. In fact circular wiring is very common. (The potential issues of circular wiring at runtime is a separate issue that exists in both ALA and conventional code, but can be dealt with more easily in ALA's execution models. This is discussed in chapter four.

In both ALA and conventional code, circular communications can be a natural consequence of the requirements. But in conventional software design, run-time communications between modules are frequently implemented with dependencies. Then we realize these circular dependencies are a problem and so we add a rule that we don't like circular dependencies. This is an attempt to mitigate the problem by forcing the modules to have a very arbitrary layered structure. That structure does not actually exist in the nature of the peer modules themselves. (Many modules will actually have a similar level of abstraction, for example views, business logic and data.) 

The forced arbitrary layering structure becomes its own nuisance. Some communications that would naturally be a push have to be changed to a pull.  (Pushing means a function or method call with a parameter, pulling means a function or method call returning a value). Whether we use push or pull should be able to depend on performance or other considerations such as sending data only when data changes, or when we want to receive the latest data, or how often the source changes, or on latency, etc. It should not be driven by an arbitrary layering of modules.

So then what happens is that when we do want to push or pull for performance reasons, but we need to go in the reverse direction of the arbitrary direction that dependencies can go, we end up creating an indirection, such as a callback, virtual function call, or observer pattern (publish-subscribe). This indirection further obscures the already obscure communication flows through the system.

ALA simply eliminates all this nonsense. In ALA, communication flows:

* don't use dependencies
* are explicit
* can be in both directions
* each set of cohesive flows are contained in one place
* allowed to be push, pull, or asynchronous on a port by port basis
* use indirection in the correct way, which is that when you are reading code inside an abstraction, you don't know, and shouldn't know, where your inputs and outputs are wired to. 



==== Knowledge dependencies are on all layers below

Sometimes layers are used incorrectly as partitions. Because of this mistake, there is a meme that we should only have dependencies on the immediate layer below. For ALA's abstraction layers this is incorrect.

When we write our programs using only good knowledge dependencies, the knowledge needed to understand a piece of code can be the abstractions in _all_ the layers below. 

For example, to understand this application layer code:

[source,C#]
....
    new ADC().WireIn(new Avg()).WireIn(new Conv()).WireIn(new Accu()).WireIn(new Disp());
....

You need to know all of these things from lower layers:

. Understand what the domain abstractions, ADC, Avg, Disp, etc do.

. Understand the dataflow programming paradigm abstraction. When you compose these particular domain abstractions, you are composing a flow of data from left to right.

. Understand that the WireTo operator, which comes from the Libraries layer, is what you use to do composition. 

. Understand your general purpose programming language, which sits below the Libraries layer.

. Understand ALA itself which is a very abstract idea that sits below the programming language layer. (Below the programming language abstractions becasue programming languages should be designed with a knowledge of ALA.)

All of these knowledge dependencies should be explicit, in other words the application folder should contain a readme file explaining all these knowledge dependencies, and link to information about them.

It's not necessarily the case that all lower layer knowledge is needed to understand something. The application is itself, for example, is an abstraction. There can be many instances of it being used by different users. These users don't need to understand all the abstractions in all the layers, only the application abstraction by itself.

That concludes our discussion on why the ALA structure works from the point of view of good and bad dependencies.



=== Executable expression of requirements

We have previously discussed the perspective of ALA being an executable expression of requirements in terms of ALA's structure. That is that the top layer is a succinct, executable, expression of requirements. We have also seen this perspective in terms of the methodology in the examples. It is the starting point we used to develop all the example projects. Why does writing software as a succinct, executable, expression of requirements work?

In conventional software development, we typically break a user story (or feature or functional requirement) up into different implementation responsibilities. For example, layers like GUI, business logic and database, or a pattern such as MVC (Model, View, Controller). But a user story or feature actually starts out as cohesive knowledge in the requirements. And it's not generally a huge amount of cohesive knowledge, so it doesn't generally need breaking up. Cohesive knowledge, knowledge that is by its nature highly coupled within itself, should be kept together. All we need to do to keep it together is find a way to describe it so that it is executable. Don't try to do any implementation, just get it described in a concise and complete form. If you can do that, the chances are you will be able to find a way to make it execute. 

In ALA we want to find a way to express the user story with about the same level of expressiveness, and information, as when the user story was described in English by the product owner. The language they used would have contained domain specific terms to enable him to explain it concisely. The same thing ought to be possible in the code. Anything that does not come directly from the requirements and starts to look like implementation detail is separated out. It factors out into the domain abstractions. These abstractions typically contain knowledge of how user stories in general are implemented - how things can be displayed, how things can be saved, how data can be processed.

Many times, abstractions that know how to implement useful things for expressing user stories are not only reusable for user stories, but can be reusable for other applications in the domain. In other words, they are domain level abstractions. A typical user story might be composed of several of them, some that implement UI, some that implement data processing, and some that implement storing of data. A user story simply instantiates some abstractions, configures them with the specific knowledge from the requirement, and then wires them together.

Most maintenance is probably caused by changing, adding or fixing user stories or features. When those features are described entirely in one place instead of distributed through a lot of modules, you have a direct understanding of how the user story is represented by code, and therefore of how to change it or fix it.

ALA application code makes heavy use of, in fact is entirely composed of, instances of domain abstractions and programming paradigm abstractions. There will be no normal programming language code such as assignments and if statements. When fixing a bug, it quickly becomes clear whether it's the application code itself not representing the requirements as intended, or it's one of the abstractions not doing its job properly. Where maintenance in conventional code is usually hard, maintenance in ALA is easy.


==== The meaning of composition

Expressing user stories as a composition of domain abstractions, as discussed in the previous section, is all well and good, but it doesn't work without defining what composion means. That's where programming paradigm abstractions come in. They are composition abstractions.

For example, many applications have displayed values or outputs that need to be updated 'live'. In conventional code, we often write imperative code to implement this live behaviour. The code repeatedly gets data from its source(s), does some manipulation on that data, and updates the output. We really should have a programming paradigm for it. In ALA you think of it simply as dataflow. When wiring together instances of domain abstractions by dataflow ports, the composition  represents data flowing. This programming paradigm is not new, of course, it appears in Unix's pipes and filters, functional programming's monads, when binding GUI display elements to a data source, LINQ, Reactive Extensions, Labview, and function blocks to name a few. Dataflows are often used on distributed systems because implementation over literal wires is naturally a dataflow. But the paradigm is just as applicable inside monolithic systems. What ALA does is make it easy and natural to implement dataflow yourself every time it is the best way to express requirements. We should never be writing imperative code to implement dataflow inherent in our requirements. ALA makes it easy to wire a network of dataflows. 

The same idea applies to the event-driven programming paradigm. It is common these days for GUI elements such as buttons, menu items, etc to have event-driven output ports. But then we often just wire them to imperative methods with a dependency. In ALA you create input ports as well. For example all popup window abstractions such as file browsers, wizards, settings, navigable pages, etc have input ports. The main window has a close input port. Long running tasks that need to be told when to start have an input port. Then you can use the event-driven programming paradigm for composing instances of these types of domain abstractions. 

Another programming paradigm is building the UI. Building the UI by composing abstractions is common using conventional libraries these days. The meaning of composition in this case is "containing one UI element inside another". The composed UI structure is a tree. For example XAML does this using XML. I do not like the use of XML for this. What ALA brings is doing all composition in a consistent way. Composition of the UI is done in the same way as the composition for dataflow, or for event-driven, or any other programming paradigm you care to invent. That way a user story is fully and cohesively expressed inside its own abstraction just by wiring instances of domain abstractions that have various programming paradigm ports.

==== Requirements are what's left when you factor out all implementation details

Requirements are what's left when you factor out all implementation details. This is another way of thinking about executable requirements. As mentioned in the previous section, ALA requires you to build your entire application factoring out all pieces of computing work into domain abstractions and programming paradigm abstractions. So what does the application that's left in the top layer look like? Well if everything abstract has been factored out, what remains must be details specific only to this application. Essentially these details equate with the requirements.

The application code becomes a formal re-expression of the requirements. There typically be some explicit information there that was only implicit in the requirements, but they were requirements all the same. For example, it may not have been explicitly stated in the requirements that a number displayed on the UI should not display decimal places that are not significant, or just contain noise. Or it may not be stated that a displayed value should not change too frequently - it should be slow enough for a human to read successive values. Developer's should know these types of implicit requirements and explicitly implement them without it being stated in the requirements.  

So the application will end up with an instance of a rounding abstraction and an instance of filter abstraction wired into its dataflow before the display. The application will specify the rounding, the filter bandwidth, and the re-sampling rate when it instantiates these abstractions. 

==== DSL - Domain Specific Languages 

anchor:DSL1[]

ALA's succinct expression of requirements discussed above is obviously a form of DSL (Domain Specific Language). Under the broader definition of a DSL, the domain abstractions and programming paradigms layers are a DSL. But ALA is not just a DSL. ALA is fundamentally about organising all code into small abstractions that are in layers that are increasingly abstract. This constrains the organisation of code much more than simply implementing a DSL. 

ALA does not pursue the idea of an external DSL (a new syntax), nor even the syntactic elegance of DSLs. It doesn't try to move application development away from the developer to a requirements team as some DSLs can do. For example, you don't get a new language such as XAML to express UI structure. In fact, expressing the UI structure in ALA moves away from XML back to code. If moving away from code, ALA uses diagrams because they are more flexible and much more readable than code and even more so than XML. 

Seen as a DSL, in ALA you wire together plain old objects or functions while conforming to a grammar. The grammar comes from the 3rd layer programming paradigms and from which classes use which programming paradigm for ports. This grammar defines the rules for their composition.


=== Diagrams vs text

The fundamental rules of ALA don't prescribe the use of diagrams. But diagrams often emerge. But why is this? Why do we often end up using a diagram instead of text in the application (top) layer of an ALA application?

In any non-trivial program, there is structure inherent in the requirements that forms a graph. If you have UI, the graph for the UI elements form a tree structure. Now a shallow tree structure is still representable with indented text. But the UI must have connections. They need connections with data (these particular connections are often called bindings in conventional code), or they need connections with event handlers. There are connections to business logic and to some form of persistent data model, and from there to real databases or files. On the way, these data paths may need to go via operations that transform, reduce, or combine the data. The data may then need to be distributed to multiple destinations. 

Additionally, there may be arbitrary cross connections for navigating around different parts of the UI. 

The business logic will often be inherently a state machine with connections to represent the transitions between various states of the system. 

There may be activities that have to happen in a prescribed time sequence, such as what you might represent with a UML activity diagram. These activities flow in real time, so can contain long running processes, delays, waits for external events or resynchronisation points. These are best not implemented as threads (this will be discussed in chapter four) but as state machines also. Connections are inherent linking the activities.

Such activity diagrams, which often have loops or alternative routes through the sequence, are representable as indented text (as in structured programming). But then there is always some connection between the activities and some data or events in the outer parts of the system. These data and event connections cross cut the activity connections. 

In order to have a cohesive view of all these connections inherent in the requirements, all these connections, are best represented as a graph.

When we write conventional text code, all these connections end up being represents as symbolic connections. A label is used at two or more points to represent the connection. These labels are not generally abstractions. So when we come across them in the code, we typically do a "find all references" in a text editor to see them.

So the cohesion of the inherent graph for given user story is lost as hundreds of symbolic connection buried in your code. We can represent some of the graph with indenting and judicious use of anonymous functions or classes, but in general we will need to represent many of the connections by using labels for variables, functions or objects.

This is bad enough. In fact this is already really bad compared with how the electronics guys do things.

But it gets worse. In most conventional code, we take all these symbolic connections and distribute them evenly through the files/modules/classes/functions. Now the graph is totally obfuscated. The graph itseld is highly cohesive. Why do we make it harder for ourselves by breaking it up?

And it gets worse. The graphs naturally have circles in them. There is nothing wrong with that, it's inherent in the connections in the requirements. But circles are at odds with dependency rules. So now what we do is break the cyclic dependencies using mechanisms like dependency inversion or observer pattern. The connections don't go away. We just further obfuscated them. These connections are now done at run-time by code written somewhere else. This is the so called indirection problem.

The result is a big mess. ALA tells us how to fix this mess. It's really quite simple. ALA breaks up your application by factoring out abstractions that do domain specific pieces of implementation. When you have done that to the maximum extent, what's left behind is nothing but the specifics of the requirements, including that cohesive graph.

Now you can choose to go ahead and represent that graph in text in one place, using many symbolic connections, and you would already be way, way better off than how we write conventional code. But even better is to do what the electronics guys do, and just build the tools to handle the graphs as diagrams.


==== Diagrams and text are not equivalent


Diagrams and text are sometimes thought of as equivalent, as if they have a duality like waves and particles in physics. It is said to be a matter of personal preference which you use, and since graphical tools are hard to produce, why not use text? I do not agree with this. From the point of view of how our brain's work best, they are very different, and each is powerful at its own job.

Consider an electronics engineer who uses a schematic diagram. Ask him to design a circuit using text and he will just laugh at you. Electronics naturally has a network or arbitrary graph structure that is best viewed and reasoned about in diagram form. If you turn a diagram into a textual list of nodes and connections, the brain can no longer work with it directly. It is constantly interrupted to search for symbolic references when it should be free to just reason about the design. 

Try designing or reasoning about a non-trivial state machine without using a diagram. Most software systems naturally have an arbitrary network inherent within it. 

Text can readily be used to compose elements in a linear sequence. It is excellent for telling stories, because stories are a sequence. Our brains are evolved to understand, and even recall stories as long as each sentence relates meaningfully to the previous and the next.

In sequential code, white space is the normal connector between the elements. Sometimes periods or other symbols are used instead. 

Text can also handle shallow tree structures, simply by using indenting. Compilers may use the indenting, or they may use brackets, usually () or {} instead. Interestingly, the brackets work for the compiler, but not for the brain. The brain doesn't see them without specicly concentrating on them. At a glance, it just sees the indenting. So I personally don't agree that Python's significant indenting is a mistake as many do. I think using brackets for the compiler and indenting for our brain in the same code can lead to discrepancies. Fortunately moderne editor tend to keep the two methods in sync. 

Ordinary structured programming (if statements and the like) and XAML are examples of tree structured code represented in text. When the tree gets deep, the indenting is too deep for our brains to follow. So text is only suitable for shallow trees. 

Text becomes troublesome when there are arbitrary connections across the structure forming a graph. It must be done with matching labels. Most imperative programs are actually not a tree structure because of the connections to variables. They must be connected to the code with labels. Local variables in a small scope are not a problem (a small scope being what will fit on your screen and can be understood all at once by the human brain). It only requires an editor that highlights them. For large scopes we end up spending too much time finding and trying to remember the connections, resorting to many all-files searches. It is a cumbersome way to try to reason about what is usually a reasonably simple structure when viewed as a diagram. 
(When I use the term 'labels', I am talking about labels that are used for connecting two or more points in the code. These labels are not abstractions. References to the names of abstractions are absolutely fine, and we don't draw lines for them even if we are using a diagram. We always just use abstractions by their name.)

When we need to compose instances of abstractions in an arbitrary network structure, our brains work much better using a diagram. Our brains not only evolved to be good at understanding and recalling stories, but also spacial graphs, presumably to allow navigation along pathways. 

The brain can readily see and follow lines between the instances of the abstractions. Unlike text labels, the lines are anonymous, as they should be. When label connections are used, the labels themselves need an encapsulation scope. Lines don't need encapsulation. They connect two points with clearly no other code having access to them.

Generally lines connect only two points or ports, but sometimes may connect three or more. To understand all places connected by a label connection requires an all files search. To understand all places connected by lines, the brain just follows the lines, generally a short distance on the diagram. The spacial positioning of elements in a diagram is also something the brain readily remembers better than where things are in text. So, diagrams can qualitatively do things that text simply cannot.

If a lines connects together many ports, it is a smell that a new abstraction may be waiting to be discovered. For example, in a schematic diagram, if there are a high number of lines all connected together at zero volts, that's the ground abstraction. Electronic engineers will use a ground symbol to represent that abstraction instead of drawing long line everywhere. An example in software might be the game score if most instances of domain abstractions interact with it. In this case 'GameScore' could be a domain abstraction in the layer below instead of making it a domain abstraction and wiring every other domain abstraction to it.

The three ALA architectural constraints do not require a diagram per-se. It only requires abstraction layering, and it's quite possible for a user story to just consist of a linear sequence of instances of abstractions. For example, a sequence of movements by a robot or a "Pipes and Filters" sequence of operations on data. However, ALA is a polyglot programming paradigm because user stories will generally inherently contain multiple programming paradigms: UI, event-flows, dataflows, state machines, data schemas, etc. These aspects of a user story tend to be naturally interrelated, which is what causes the resulting relationships among its instances of abstractions to be a graph. The use of diagrams embraces the idea of bringing together of all these different interrelationships of a user story in one cohesive place.   

==== No XML as code

If dependency injection is used to implement the wiring, I prefer not to use XML to specify the application. Firstly XML is not very readable. Secondly it only handles shallow tree structures well, not arbitrary graphs. If I use text for specifying wiring, I use normal code. I try to find a tree structure in the graph as much as possible and represent that as indented text as much as possible. Any nodes in the graph that need cross-tree connections have their instances saved in local variables. The cross connections can then be wired by referring to those variables. You will see this done in many of the examples.

You are still better off with this code in one place than having it distributed inside your modules. But if a graph structure is inherent in the requirements, there is really no substitute for the readability of a diagram.


==== Diagramming tools

The ALA design process is describing your requirements using abstractons and inventing the needed abstractions as you go. It is an intense intellectual activity, especially when doing it for the first time in a new domain. As well as expressing your user stories, you are inventing a set of domain abstractions and programming paradigms that will allow you to express all user stories. It requires all your focus. There is no focus left to deal with tools that are hard to use.

I have found that hand drawing the diagram on paper is not good. The diagram quickly gets into a state where it needs reorganising, which requires redrawing it from scratch. That totally interrupts your design flow. I have found that a diagramming tool that constantly needs you to control the layout, such as Visio, is also not good. The tool must be able to reorganize the diagram (push things out to make room).   

So until there is a better tool, I have been using Xmind because as a mind-mapping tool, it is designed to not get in your way as you are creating. It lays itself out as a tree structure, and then allows cross connections on the tree to be added using a key short-cut at the source and a mouse click at the destination node. It has serious limitations, however I use some simple conventions to mitigate these. For example, I use '<' and '>' to represent input and output ports.

Furthermore, the tree structure allows easy hand translation of the diagram into indented, fluent style code. We also have a tool that takes an XMind save file and gnerates the code from it automatically

While Xmind allows you to be creative in the beginning while you are still inventing domain abstractions (I couldn't imagine doing without it), it is far from ideal once the abstractions have matured. At this point you are rapidly churning out user stories that are fairly obvious how to write, and Xmind's limitations start to slow you down somewhat.

And even more recently, we have a purpose built graphical IDE for ALA. But it is not complete.

In my experience, a low overhead drawing tool is essential during the iteration zero design phase and during subsequent maintenance.   

See the end of this chapter for an example project using Xmind.


// TBD review from here


===== Essentials of a diagramming tool.
  
* Low effort to use like a mind mapping tool. As with a mind-mapping tool, you control the logical layout, and the tool does the actual spacial positioning.

* It would layout as a base tree structure, but allow cross connections that route themselves neatly around the nodes, crossing other lines as necessary.

* It would primarily use keypresses shortcuts, for example to add a new node to the tree, but allow mouse clicks where it makes sense, for example, to specify the destination of a 'cross connection'.

* You can make mutiple trees for different user stories (that may need some connection between them).

* Abstractions are defined in a separate panel. The consist of boxes with lebelled ports. Inside the box, the configuration parameters are defined. Once a new abstraction is  defined, it can be instantiated in the diagram by its abstraction name with auto completion. Boxes represent these instances with the ports lablled around their boundary as they were on the abstraction in the abstractions panel.

* The abstractions in the abstractions panel are fully integrated (synced) with the classes in the code. This syncing goes in both directions. If you change the ports or configuration parameters in the diagram, it changes the class code and vice versa. Configuration parameters are either required or optional types. Required parameters become constructor arguments. Option parameters become properties with default values.

* The tool's purpose is to aid creativity in the ALA process of representing a user story, inventing new abstractions as you go. Of course the tool would also automatically generate the all the code. The generated domain abstraction classes would then need to be completed with normal coding.



// TBD two sections on decomposition copied in



=== Composition, not decomposition

In this perspective, we look at ALA as the antithesis of the prevalent decomposition methodology of software development.

The conventional technique for tackling system complexity is often referred to as "divide and conquer". The theory is that you break a system up into smaller and smaller parts hierarchically until the parts themselves are a manageable complexity to write. The problem is that this doesn't work well. This is because the parts are specific parts of specific parts all the way up the hierarchy. This mean that a lot of contextual knowledge is needed, not only of the parts that contains it all the way up the hierarchy, but of the parts around it that it will collaborate with. I have seen systems that come out even worse than just monolithic code would have been.

Consider this phrase, which has been used as the definition of software architecture:

[WARNING]
====
"[red]#*decomposition*# of a system into [red]#*elements*# and [red]#*_their_*# [red]#*relations*#".
====

Notice the word 'their', which I have italicised to emphasis that the relations are inferred to be between the decomposed elements. It suggests that the decomposed elements know something about each other, that they collaborate to create the whole.  
In ALA we think about building the system in a completely different way. Here is how to reword the meme for ALA:

[TIP]
====
"[green]#*composition*# of a system using [green]#*instances*# of [green]#*abstractions*#".
====

This seemingly subtle shift in thinking leads to a qualitative difference in the resulting structure. 

First let's understand what we mean by composition through a few examples: 

* When we compose musical notes, we create a tune. The structure is linear. The execution is sequential like activity flow in software. 

* When we write code in a general purpose programming language, we are composing  statements and variables. Statements and variables are low level (fine grained) elements and only support a single programming paradigm, which we call 'imperative'. By composing enough instances of them we can create a program. The structure is a graph but is written as an indented tree, but with many labelled cross connections.

* In functional programming, we are composing with pure functions, so the elements are higher level things that you create. But the programming paradigm is still imperative.

* When programming with monads, we are composing functions, but the programming paradigm has changed from imperative to dataflow. The structure is primarily linear. Monads are explained in detail in chapter six.

* When programming using the UML class diagram, we are composing with classes directly (not objects). The programming paradigms are whatever is represented by particular associations.

* When programming using the UML activity diagram, we are composing activities to be done in a set order. The structure is a graph, because you can branch, recombine and loop back arbitrarily. Activity diagrams are not imperative (like the old style flow diagrams). The CPU is not necessarily dedicated to each activity being done. Activities may take an arbitrarily long time without the system blocking. The programming paradigm is sequencing of potentially activities with resyncing.

* When programming with XAML, we are composing UI elements. The programming paradigm is UI layout (what goes inside what and in what order). 


Let's list the different properties present in these types of composition:

* Low-level or high-level - Sometimes we are composing fine-grained general elements and we need a lot of them. Sometimes we are composing 'higher level' more specific elements, and we need relatively few of them.
+
 Note that sometimes people think of these higher level elements as _more_ abstract. This is completely incorrect. They are more specific to a particular application and therefore _less_ abstract. For example, a class that handles the display of a label-data pairs on a graphical display is more specific than the print statement. The misconception is caused by thinking that being further removed from the underlying hardware makes it more abstract because the hardware is concrete. People build layering schemes with the hardware at the bottom with assembler and then the programming language layers above that ("abstracting away the hardware"). In fact the general purpose programming language is the bottom (most abstract) layer on which everything is built. Both the specific application and the specific compiler for the hardware are built in their own sets of layers above it, both getting more specific as you go up.   

* There is usually only one meaning of a composition relationship in each case. It may be sequential, imperative, dataflow, UI layout, or something else. 

* Linear/Tree/Network: The structure built by the composition relationships can be typically linear, a tree structure or a general graph or network. 

* Syntax: The syntax for the composition of two joined elements can be using spaces, dots, or lines on a diagram. We can use various types of bracketing or indenting for the text form of tree structures. Graphs represented in text form use matching pairs of labels for many of their connections.

In ALA, we use composition to create user stories or features. We want the composition to have the following properties:

* Composing more course grained expressive elements by letting them be specialized to your domain.
* Allow use of many programming paradigms (meanings of composition)
* Easily allow for graph or netwrok structures, not just linear or tree.
* Allow the programmer to add new programming paradigms with new meaning if that's the best way to express requirements.
* Use the same syntax for all the different composition relationships.

ALA can therefore be thought of as a 'generalised composition' architecture. 


==== Composability and Compositionality

We have used the word _compose_ a lot so far in describing ALA. The term _Composability_ means the ability to create an infinite variety of things by composing instances of a finite number of things. Composability is a very important property for dealing with complexity. 

The Principle of Compositionality states:

[NOTE]
====
In semantics, mathematical logic and related disciplines, the principle of compositionality is the principle that the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them.
====

The principle of compositionality restated for the context of software might be:

[TIP]
====
[green]#*The meaning of a piece of code is determined by the meanings of its constituent abstractions, and the programming paradigms used to combine them.*#
====

Brian Beckman, in his explanation of monads called "Don't fear the monad" says that composability is _the_ way to deal with complexity.

Jules Hedges says of this property "I claim that compositionality is extremely delicate, and that it is so powerful that it is worth going to extreme lengths to achieve it." 

In software engineering, it is described by a pattern called "Abstract Interactions" or "Configurable Modularity" by Raoul de Campo and Nate Edwards - the ability to reuse independent components by changing their interconnections but not their internals. It is said that this characterises all successful reuse systems. 

ALA has the property of composability by using domain abstractions with ports. The ports are instances of programming paradigms. The domain abstractions are the constituent expressions, and the programming paradigms are the rules used to combine them. 

There are other software systems that have composability, usually using the dataflow programming paradigm, such as RX (Reactive Extensions), or more generally monads. Most composability systems are restricted to a single paradigm. In ALA, to achieve the correct level of expressiveness of requirements, multiple different programming paradigms are used.





=== No Data Coupling

The term _data coupling_ here doesn't mean that one module communicates with another.  _Data coupling_ refers to two modules agreeing on the meaning of that data. This is the cause of a lot of coupling in conventional software systems. ALA has no data coupling.

In conventional programming, data coupling is considered unavoidable. There is a misconception meme that two modules have to share the knowledge of the meaning of data if they are to communicate. Even if you have an understanding of ALAcin general, you may still fall for this misconception unless we are explicitly aware of it. Your abstractions may end up with implicit coupling about how they will interpret data, once again destroying them as abstractions. 

The misconception is especially common when two modules run in different locations. It seems a self-evident truth that the two modules must share some kind of language if they are to communicate, just as people do. 

Let's use an example to show that data coupling is not required. Lets's say there is a temperature sensor on a Mars rover. The temperature is to be displayed at a ground station on Earth.

In conventional programming, to implement this user story, one module resides in the Mars rover and one module resides in the ground station. These two modules must agree on the meaning of data. For example, it is an integer number of tenths of degrees C (Celsius).

Obviously a lot of other system parts are involved in transporting the data from the sensor module on the rover to the display module in the lab on Earth. These are referred to as middleware. It is common to _containerise_ the data so that none of the middleware needs to know its meaning. But the two end points at least seemingly must have shared knowledge.

To break the agreement, let's make the output of the Mars rover sensor degrees Kelvin, and well make a positive number of hundredths of degrees. Now the two ends have no agreement, and clearly have no data coupling.

In ALA, the _meaning_ of the communication is completely contained inside another abstraction, not in the two abstractions it will set up to communicate. That abstraction is the only one that knows about the user story. It knows the ports interfaces of the abstractions on mars and Earth that it wants to connect. So it knows to wire in a converter in-between. 

Here is the user story implementation.

[source,C#]
....
class RoverAmbientTempertureUserStory {
    new TemperatureSensor()
        .WireIn(new OffsetAndScale(-273.15, 0.1))
        .WireIn(new Display("#.#"))
}    
....

The meaning of the temperature data does not need to be known outside of this small abstraction. It does not need to be known by the sensor itself, or the display, or anything in-between. The meaning only needs to be known by the engineer who wants the sensor on the rover and wants to see what it says on the display, and so writes the above code. This user story is cohesive, and so the code that implements it should be cohesive.

Now if he were to change the units of temperature, only this user story abstraction would change. Just change the OffsetAndScale configuration, and change the way the display is formatted.

It doesn't even matter if software needs to interpret the data. For example, let's add an alarm that goes off at 50 C: 

[source,C#]
....
    new TempertureSensor()  // unit is celcius
        .WireIn(new OffsetAndScale(-273.15, 0.1))
        .WireTo(new Display("#.#"))
        .WireTo(new Alarm(500));
....

The interpretation of the data is still contained inside the user story abstraction. Everything about that temperature is cohesive code. 

==== deployment

In the above example, the user story code spans physical locations. I deliberately chose a Mars rover to make this physical reality as extreme as possible. There is obviously a lot of middleware infrastructure in-between to support the communications. And yet in the user story code we have gone ahead and wired the sensor directly to the display with only a conversion abstraction in-between. So how do those instances of abstractions get deployed?

Inside the user story abstraction, we can annotate the three instances with their physical locations. Another abstraction sits in a lower layer that knows about the concept of a _physical view_. It has already been configured to know about the three physical locations. The user story annotates the instances of abstractions it creates with where it wants them to physically run. It can do this because it knows about the physical view abstraction.  

The physical view abstraction takes care of deploying the instances of abstractions for the user story to the correct locations, configuring them, and actually connecting them to the middleware. It also knows how to take care of version compatibility, and updating versions at different times at different locations. 



==== Modules written by different parties

The zero coupling of ALA, and zero data coupling in particular, allows all abstractions to be written by different parties or teams who don't need to communicate with each other. They can even be written at completely different times. Only the _knowledge dependencies_ must be communicated. In the example above, the user story abstraction cannot be completed without knowing about the three abstractions it composes. 

The idea of no data coupling relies on a common programming paradigm. It relies on the teams who write the domain abstractions all using that programming paradigm. And it relies on having a separate team responsible for the user story, and all teams agreeing to use ALA and the common programming paradigm.  

What happens if one of the abstractions to be used is written without knowledge of ALA? It has a conventional API that includes both configuration and data input/output methods. In this case the team responsible for the user story itself will write a wrapper that will make the abstraction into an ALA compatible domain abstraction that has a separate configuration interface and the relevant ports. The wrapper and the abstraction that it wraps become a single abstraction together. 


==== Conway's law

****
Conway's law states: Any organisation that designs a system will produce a design whose structure is a copy of the organisation's communication structure. 
****

If a system spans physical locatons, it is likely that the oranisation will allocate teams to develop code based where the code runs. Whether it's frontend / backend or rover / lab, the teams are likely to be repsonsible for a deployed location. The teams then communicate with each other their APIs. It is highly unlikely that the teams will be told, in the interests of creating better abstractions, not to communicate with each other. And yet this is precisly what should be done to get the best architecture. Then there should be a team responsible for each user story. That team writes the cohesive user story code by composing using the set of domain abstractions provided by the other teams.

Unless these extra teams dedicated to user stories are put in place, the modules at different locations will end up with a lot of data coupling and collaboration coupling in general, just because the teams that write them will need to collaborate.

There will need to be be contracts that describe all this implicit coupling. The contracts will be a second source of truth, which must be kept updated.

////
JRS The following seems wrong or at best confusing the issue

In this situation it is still possible to mitigate the effects of coupling somewhat. Let's say the display end has been written by the 3rd party, but is written in such a way that it accepts _self describing data_ according to a standard. Effectively this is just making it more abstract. Without changing the display end, the user story can be implemented from scratch by sending to the display the self describing data. The display then knows how how to receive the label and display format (which can be sent once) as well as the numeric data. The display knows how to create a space for displaying the data. This is how browsers work. 

It is common, for example, for a 3rd party to provide a sensor and publish the data on an MQTT server as self describing data. Say the other team is writing an application to use this data, not only display it, but interpret the data as well. They will subscribe to the topic. They will write code that is coupled with design knowledge provided by the 3rd party about the MQTT topic.

However, if the 3rd party is selling you abstract sensors that you install yourself and sell you the MQTT communication infrastructure, then you could be provided with a more abstract 'configuration API' from the 3rd party. You would then write a domain abstraction that knows about that configuration API. Whenever you want to do a new user story, you can use an instance of that 'device configuration' abstraction. You can fully configure the MQTT topic, and its data format, then subscribe to it and process it. Everything specific to the user story is now cohesively contained inside a single abstraction once again. 
////

////
==== 3rd party library abstractions

All the above applies when teams are supplying peer modules for a system. The modules have a similar level of abstraction. If the 3rd party is providing something more abstract like a library, we can choose to be directly dependent on it, if it is abstract enough to be considered part of the language we want to write user stories in. The canonical example is a relational database with the abstraction being SQL, although not all SQLs are equivalent so many prefer not to be dependent on it. 

The common problem here is that if the abstraction comes from a 3rd party, we are making ourselves dependent not only on the abstraction, which is ok, but on the provisioning of the implementation. This may be okay when we choose to depend on, for example, the windows or MacOS operating system, but is dubious decision for a specific database. (Actually its not ok for Windows either, but being able to swap out windows is considered too hard). So it's become good practice to allow swapping out of the database. And since SQL is not quite as abstract as it should be between vendors, it means we don't want to be dependent on SQL either. 

Clean architecture or hexagonal architecture suggests to do this by using interfaces specific to the user stories, and then writing adapters for every interface to SQL.

In ALA, you probably already have a 'tabular dataflow' type of programming paradigm. All abstractions that deal with tabular data already use ports of that type.

It is a matter of writing one adapter that is configured with the schema. The adapter then generates the appropriate SQL queries.

//TBD provide code example of a lazy dynamic tabular programming paradigm, something like:
[source,C#]
....
    interface ITabularDataflow : IQueryable<dynamic>
    {
    }
....

We can write a Query domain abstraction that takes a LINQ query as its configuration. This one abstraction allows us to use LINQ's From, Select, SelectMany, Sort, Where, Join etc in ALA applications. The query abstraction has ports to make it composable as part of user stories in ALA. Since LINQ is already compliant with ALA from the point of view of composing data manipulation abstractions, there is no reason not to use it directly in this way.

TBD Write a query abstraction that takes a LINQ query as a parameter and has ITabularDataflow<T> ports. Shouldn't be too hard so full code can go here.

TBD Write an abstract adapter for SQL Lite database with a special port that is used directly by the Query abstraction. 
////


=== From procedural programming to ALA

How does ALA compare with procedural programming?

(Brian Will advocates pre-OOP procedural programming style in his Youtube video.) 

In procedural programming, data is always passed into procedures. Structs are passed in if there is a natural grouping of data items. 


Starting from pure procedural programming, we will make five incremental changes to get to ALA. In this progression, you will see that we introduce objects but not object oriented programming per se.

. To begin with, you can apply ALA directly to procedural programming style. Abstractions are implemented as groups of procedures. You must structure the code so that you only call procedures in an abstraction that is significantly more abstract. You will have user story abstractions in the top layer, and domain abstractions in a second layer. Procedures that directly code a given user story are put together to form a user story abstraction. Procedures that are cohesive in the domain layer, such as configure/read/write sets, are grouped together as abstractions. Such abstractions could be bounded as a code source file or a static class. Such abstractions are reusable just by calling the procedures because the abstraction itself does not yet have any data.

. Instances of abstractions often need configuring. Configuring requires storing some configuration parameters that are passed in when the abstraction is instantiated. We can put the configuration data in a struct, and provide a constructor with parameters or setters. The struct is passed as the first parameter to all the procedures belonging to the abstraction. The struct is immutable.
+
For example, a filter abstraction needs configuring with a cutoff frequency and a stop band rejection. If the abstraction consisted only of a single function, then that configuration data would need to be passed in every time the function is used. That would be awkward. It would also mix the data parameters of the function with the configuration parameters, breaking the Interface Segregation Principle. By using a struct to represent an object, ALA can configure an abstraction once, and then the contained function can be used may times. This separation of configuration and function use is important for abstractions - the configuration is done once at instantiation time of the abstraction, whereas the function can be used many times.
+
Effectively we now have objects.  

. In procedural programming, the user story will frequently call one procedure to get some data and then pass it straight to another procedure. This handling of data is not really something the user story code wants to do. It should just compose the procedures, declaratively. 
+
What we need is another piece of data in the abstraction for doing direct wiring. That can be another two fields in the struct. Now the user story sets who it is wired to so that instances can communicate at runtime without the user story having to handle the data itself. The field points to the procedure of the abstraction it is wired to and the struct instance. The fields are immutable after they are set.
+
Effectively we now have two reasons for having objects. 

. In procedural programming, you will often need some state because the user stories themselves inherently are a state machine. (That is, the user story reacts to external events, and how it acts depends on past events.) We would normally store this state in variables and pass these variables into the procedures as required. This creates extra parameters for our procedures. Some procedures will need extra parameters even though they don't need the data, because they need to pass it through to other procedures that they call. 
+
Sometimes these state variables are used only by one abstraction. For example, a running average abstraction needs to hold past values. In procedural programming, the array of past values is kept in the top layer and is passed into the function every time. This breaks the running average as an abstraction. In ALA, abstraction is all important, so we keep the state and code together where they are cohesive. This gives us a third reason to use objects.
+
In a multithreaded environments, it would be prudent for only one thread to be using each instance of such objects. 
+
For user story abstractions, there is probably one instance per application, so the class could be static. But once again we need objects.

. Lastly, there may still be state data that does not belong to a specific abstraction. This will be sitting around in a top layer looking like a global. In object oriented programming, this is the type of data we would stuff into a class anyway, and then have almost pointless accessor methods. The other classes then have harmful dependencies on these data classes. Furthermore, the dataflows through such a network of objects is completely obfuscated. 
+
In ALA, what we do is create a domain abstraction for such state. This abstraction has dataflow input/output ports. Instances of the abstraction can then be a source/destination of data. These are wired into data flows in the same way as any other dataflow domain abstraction. We can create instances of it for each item of state data needed by the application. Such state objects are not globals, nor do they need to be passed around. Other domain abstractions do not even know about them. Instead they are wired to them by the user story abstractions using dataflow ports. This is another legitimate reason for using objects. 
+
If the type system is dynamic, a state abstraction could hold any complex data structure, and the user stories it is wired to can use the data in a dynamic way.
Only the application layer would know the actual structure of the data at design-time. Or it may be completely dynamic until run-time.
+
If the type system is static, and we want to group data together in a single instance of a state abstraction, The application layer can use an explicit or implicit struct type. If explicit, the state abstraction will be a generic, and the struct type is passed to it at compile-time. User stories that are wired to the state instance will also have the struct type passed to them. The other way to do it is type inferencing if your language supports this. The source of the dataflow is given a type at compile-time, and the rest of the dataflow gets their types from type inference.
// TBD example of type inference between two domain abstractions.


Through the five steps above, we have transformed procedural code into ALA code. We have used objects, but we did not use object oriented design. The resulting ALA version has these properties:

* No class knows of the existence of state in any other class. If a UML diagram was drawn, it have no association relationships between peer domain abstraction classes.

* Despite the fact that we use objects, the ALA constraints avoid most of the problems of conventional object oriented programming. For example, both the configuration data, and the wiring data stored in an instance can be immutable. Only instances of abstractions that contain state data are mutable, and this is clear from very nature of the abstraction. 


////
==== Immutable state

In the previous section in point 5, we talked about a state abstraction.

The state abstraction should be immutable. At first this does not seem to make sense. What use is state that is immutable? This is the big idea behind the proramming language Clojure. Think of the state domain abstraction as being a time series of all its previous states. When the output dataflow port is used to get the state, it returns a reference to the data (or boxed data if it's a simple type). The data at that reference will now never change. It is a snapshot in time, and all subsequent processing of that state data by the user story can be done taking its time. User stories can take time, for example when waiting for external inputs. Other user stories can run at the same time. So we can have concurrency even in a singe threaded application. These other user stories can change the state in the same instance of the state abstraction, without affecting the first user story that has not completed yet.

When the input port of the state abstraction is used to change the state, it, in effect, copies the state and then stores the reference as the new latest state. For performance reasons, the implementation should not actually copy large amounts of data - it should use the same idea of optimized immutable data containers that clojure uses. The parts of a data container that are changed are copied, and the new container refers to the older containers for the rest of the data.    
+
It is an advantage of having a state abstraction that you can implement immutability once and then reuse it for all wired state that your application needs.
////






=== ALA compared with Object oriented programming

Before we compare ALA with object oriented programming, let's first discuss what object oriented programming is.

 It is said that using a struct as the first parameter to the procedures is equivalent to classes with it being only a syntactical difference. I do not agree. Classes have a fundamental advantage over structs and procedures because with structs and procedures, the caller must specify the struct and the procedure both from among all visible in the scope. With classes, the caller specifies primarily the object and then a method from among the methods of that class only. That changes the way we think of objects. Primarily we just think of objects as a single reference - that object then contains its own small number of possible behaviours.
 
 It is also interesting to note a misconception meme around object oriented programming. It is said that OOP = encapsulation + inheritance + polymorphism. Well encapsulation predates objects. Inheritance is now seen as a big mistake. That means that polymorphism in the form of virtual methods are also a mistake. That leaves interface polymorphism, which also predates OOP. The thing that OOP actually brought to the table has nothing to do with encapsulation, inheritance, or polymophism. It was to think about programming as passing messages. The idea is that the object decides the behaviour it will do when it gets a given message. With procedures you are specifying directly what to do. With objects, you are sending it a message and what it does with it is decided by the object. This difference is subtle - it involves only a difference in the way we name procedures or methods. A procedure's name describes what it does. A method's name is a message name describing something that has happened elsewhere. This is a sort of half step toward polymorphism. You don't know what the receiver will do as a reult of getting the message. Full polymorphism is not even knowing what the receiver is. Read about Alan Kay to understand what he meant when he coined the term 'object oriented'. 

ALA uses this message emphasised view of object oriented programming. In fact in ALA, all messages are sent fully polymorphically. So we have no choice but to think of them as message rather than procedure calls. This is from the point of view of the sender and the receiver. The receiver also does not know where the message comes from. From the point of the code in a higher layer that wires the sender to the receiver, it may or may not be thought of as a message depending on the programming paradigm in use. More generally it is just a compositional idea that gives meaning to the relationship. For example if the instances of abstractions being wired are UI elements, then the meaning of the relationship is one element being laid out inside another on a graphical display.

Brian Will makes an argument that OOP is crap and procedural programming is better on his Youtube channel:

https://www.youtube.com/watch?v=QM1iUe6IofM[https://www.youtube.com/watch?v=QM1iUe6IofM]

I am in agreement with Brian in so far that trying to associate _all_ data with code and all code with data causes inappropriate fragmentation of the code, encourages a model of highly coupled, collaborating agents, and creates dependency hell. 

The idea of encapsulation is only partially realized because objects effectively know about the existence of another object's state and collaborate with that state. They reach into each other's data indirectly. But this can be seen as breaking the half step to polymorphism idea discussed above. It's not how OOP was meant to be done. 

Also, the UML class diagram encourages relationships directly between classes, which should be uncoupled abstractions. It encourages mutable data. And it encourages a horrendous model of agents interacting with each others data in a multithreaded environment. To solve this, Brian advocates a return to procedural programming and provides several examples which demonstrate that procedural programming is better.

Although ALA uses objects, it is not object-oriented in this way. Firstly you don't try to model everything with objects. It uses objects as a language feature, not a design philosophy. Secondly, you can't create associations between classes. So classes literally cannot tell other classes what to do in a similar way to calling a procedure, and they cannot access another class's data. ALA is always fully polymorphic. All messages are sent polymorphically.


Objects are used in ALA for the following four reasons. 

. Objects store references to other objects to which they are wired. A form of dependency injection is used to receive the references to the other objects. 

. Domain abstractions, being reusable entities, often need configuring. The object stores its own configuration data passed in the constructor or via setters.

. Some abstractions naturally have state. For example an abstraction that implements a low pass filter for a dataflow needs to keep some kind of historical value or values. It is inherent in the nature of the abstraction that it has state.

. There is usually some state data that doesn't belong with any code. In ALA we often create a special domain abstraction called 'State<T>' that acts as a source or destination for dataflows.


==== Dependency injection

The dependency injection pattern was introduced as an attempt to clean up the dependency mess created by OOP. It came too late to make the famous GOF patterns book. The authors wish they had included it instead of singleton. But dependency injection alone does not solve OOPs problems.

Previously we mentioned the use of dependency injection in ALA by using the wiring pattern to wire up instances of abstractions by their ports. The way this dependency injection is done is quite different to container based dependency injection. 

Container based dependency injection works by matching interface types. The interfaces are implemented by one class, and required by another. The matching of this interface type is the implicit wiring of the two classes. There is no place where you can see the wiring explicitly. This is really bad. It is very difficult to trace the flow of a user story through the classes.

Now a class may be substitutable with another class that implements or provides the same interface. That's why there is a container. You instantiate an object of the class you want to wire in, and put it into the container. But this is a far cry from general composability.

In ALA interfaces do not belong to the classes being wired. They are more abstract and represent a compositional concept which we call a programming paradigm. When a domain abstraction uses one of these abstract interfaces, either implementing it or using it, we call it a port. The abstraction has no implicit fixed arrangement with other abstractions. A separate abstraction in a higher layer is needed to specify how instances of abstractions with ports should be composed.

Note that this makes ALA not only fully polymorphic, but, in a way, extremely polymorphic. That's because from the point of view inside an abstraction sending a message out of it port, there is potentially an infinite number of different abstraction types that it could go to. In conventional OOP, it's typically a finite set, usually just a few. A finite set potentially allows the sender to have some implicit knowledge of those receivers.  

Despite the extreme use of polymorphism in ALA, there is none of the usual disadvantage of indirection. Often indirection makes the flow of a program difficult to trace. But in ALA it is way easier to trace through a program. Consider it from two points of view. The first point of view is from inside an abstraction that is sending a message out via an output port. The abstraction doesn't need or want to know where the message goes. That's because along with extreme polymorphism comes zero coupling. You don't need to know anything about the outside world to understand the sending code. The second point of view is outside the abstraction that is sending the message, the view of where it is wired to. Well that's explicit and cohesive wiring to do with a given user story is in one place. You don't have to trace through modules, you just reading normal code in one place in ALA. 




==== Multithreaded programming with mutable state

Some abstractions are about describing change over time. ALA uses mutable state within such abstractions because these are abstractions that naturally contain state.

In functional programming, the way to express change over time is to pass the state into the function that represents the change over time, and the function returns the next state. The problem is it breaks the abstraction. Functional programming overcomes this problem by using monads. Monads can contain state, but are composed by pure functions. This hides the state in the more abstract and well tested monad itself. ALA uses this same principle. Domain abstractions completely hide their contained state in well tested code and are composed by pure functional code.

Monads vs domain abstraction is discussed in detail in chapter six. Here we are concerned with multithreading issues that can occur because we are using instances of domain abstractions that contain state.

We need multithreading strategies or rules to avoid the usual threading issues: race conditions, deadlocks or priority inversions. Unlike with conventional OOP programming, ALA's zero coupling between abstractions makes it easier to put in place these strategies.

(In functional programming, the issues of multithreading are handled by using immutable data. I suspect that systems that only use immutable state also have problems when using multiple threads. For example one thread could be using and inconsistent or outdated copy of the current actual state.)

The strategies I use in ALA do not use locks. Making classes thread-safe with locks is highly problematic because insufficient use of locks results in race conditions, but liberal use of locks results in deadlocks or priority inversions. Successful locking requires detailed knowledge of the specific threading allocations of all objects. So if locks are implemented in the classes themselves it introduces coupling, destroying the abstractions. Locks would need to be implemented by the user story abstractions in the higher layer. That would encumber the user story code execution specific details.



===== Single threaded strategies

The first strategy in ALA is to use a single thread by default.

Many times in conventional code, multiple threads and stacks are used to solve problems that they should not be used for, such as to implement activity flows where the activities are broken up in time. For example, there may be a built in delay or waiting for I/O. The only valid reasons to use multiple threads and stacks is when one CPU cannot handle the total workload, so work is done on a background thread, or when one or a few high priority threads are needed for low latency response.

If everything runs on a single thread, then mutable data used in good abstractions do not cause problems. Even when using synchronous message passing between the instances of those abstractions, there is no problem. Effectively, this is equivalent to locking the entire system until the each task runs to completion and returns to the main loop.

The second single threaded strategy allows for concurrency. It deals with cases where processing a message synchronously would take a long time. It may have to wait for I/O, for example in communicating over a physical network. It may simply contain a built-in delay. Or it may need to wait for the work to be done on a  different process (processes are like threads that share no memory). In any of these cases, we want to allow the single thread's CPU to do other work during such waits. Sometimes this other work is allowing the sender of the message to continue execution, but it could be any work in any other instances of abstractions where a message is waiting in a queue. 

Implementing concurrency in this way effectively requires a state machine inside the abstraction that allows for the time discontinuities in its execution as states. Often that state machine is best implemented by the compiler using *async* and *await*. Or you can use callback functions, or use task, future or promide objects that can be chained together. 

Even if none of these patterns is available, it is still better to implement a state machine manually than to resort to multiple threads to solve the problem. In fact it can often be advantageous for understanding the system to represent it as a state machine rather than a flow of activities, because then different events can easily transition to any other state. For example, when waiting for a response to a message that has been sent to another, you probably only want to continue on to the next activity if you get a valid response. You will also typically need to handle cases where you get an error response or a timeout, and go to different states for those. Also, a different message could arrive while you are waiting for a response message, such as a cancel message. That would also take you to a different states. This type of state machine does not code elegantly in imperative sequential code running on a dedicated thread. 

The main drawback of explicit state machines is usually in manually transforming loops into state machines, and in handling what would be local variables and parameters whose scope now spans multiple event handling methods. Breaking a method into two methods at a point that is inside a loop involves also transforming the loop into a state machine.

Whether we use *async*/*await*, callbacks, tasks, or manually written state machines, it requires asynchronous messaging. Asynchronous means that a method call can return to the caller before the message is fully processed. This is usually achieved by simply putting the message in a queue to be acted upon later by the main loop of the single thread.



===== Using push dataflows

In ALA, for the dataflow programming paradigms we usually default to using a push execution model. This makes it easier to wire for either synchronous or asynchronous messages. 

The zero coupled nature of ALA abstractions means that senders often do not need to know when receivers have completed processing a message. Many messages can be purely one way. For example an ADC abstraction can send a message, and it can be wired to a display. The ADC never needs a response. 

The preference to push data is made possible because ALA does not have dependency issues that would normally cause about half of all calls to use pull in conventional code. So all calls can default to push unless there are performance reasons for using pull.

When abstractions don't care if a message is processed before or after the call returns, it means that we can make a late decision on the execution model. The choice is not bound until instances of the abstraction are wired together to make an application. Then we can chose to wire instances of abstractions with either a synchronous or an asynchronous execution model. If synchronous, the wiring connects the sender instance directly to the receiver instance. If asynchronous, the sender is connected to a message queue that queues messages to the receiving instance. How these execution models work is discussed in the next chapter.

Whether an instance is wired to use a synchronous or an asynchronous execution model, the same calling code can be used in the sender. From the point of view of the abstraction, the call only goes as far as its output port. The call can return immediately and asynchronously before the message is processed or it can return synchronously after the message has been processed by the wired receiver. If it returns before, then the sending instance can continue on with its own execution.



===== Using pull dataflows

As mentioned, in ALA, for the dataflow programming paradigms we usually default to using a push execution model. However, sometimes we want to use a pull dataflow programming paradigm for performance reasons. For example, the source data may change very frequently, but the receivers of the data only need the latest value infrequently. Or the source may be logically passive such as a database. 

When the receiver needs to pull the data, and we need to use asynchronous messaging, and we don't want the sender to have its own dedicated thread, the sender domain abstraction must be written to use asynchronous code style. That is it must send the request message, and then return to the main loop and wait passively for the response.

By far the easiest way to implement asynchronous pull calls is to use *async*/*await*. This allows the domain abstraction to be written to look like synchronous style (except for the addition of *async* and *await* keywords), but it executes asynchronously.

If async/await is not available, then you can use task, future or promise objects. A Bind function on theses object allows you to chain the response handling function so that it looks close to sequential code. This is effectively the monad pattern for asynchronous calling. Monads are explained in detail in chapter six. 

If you can't even use the task monad, such as being restricted to using C with no heap, then the domain abstractions can be written in the style of a state machine. 

Chapter four has an in depth discussion on these execution models together with how abstractions can be written so that their instances can be wired for either synchronous or asynchronous messaging.





==== Multiple thread strategies

Sometimes we need to use multiple CPUs for the shear amount of computing load, or we need to react to events faster than the single threaded model will allow. With a single threaded model, the maximum latency for the highest priority task is the time taken to process the longest of all tasks. This will be the longest compute bound task. In these performance cases we use either interrupts or multiple threads.

The ALA strategy is that synchronous message passing may only be used between instances of abstractions allocated to the same thread. Instances that are allocated to different threads must be wired using asynchronous message passing. As described in the previous section for the single threaded case, it is already easy in ALA to  use either synchronous or asynchronous wiring for one way messages without changing the abstractions themselves.

. If one or two high priority threads are added for latency performance reasons, we can use synchronous message passing between all instances allocated to the main thread, and only use asynchronous message passing to the high priority threads. 

. If one or more back-ground threads are used to handle long running CPU bound work, we can use again use synchronous message passing for all instances on the main thread, and asynchronous message passing to the instances on the background threads.

. the majority of instances of abstractions usually run on the main thread. However, there is nothing stopping us from using asynchronous message between these instances as well. This will make the longest running task shorter by only processing within a single abstraction at a time. 

Effectively this strategy is a knowledge dependency on an underlying convention. User stories must know that if they allocate two instances of domain abstractions to different threads, they must be wired using an asynchronous programming paradigm. With knowledge of the underlying convention, domain abstractions can be written without regard to thread safety.

You could argue that this knowledge dependency of user stories adds to the burden of the user stories. User story abstractions should just be about expressing requirements. However the user story is concerned with performance, because performance requirements are requirements too. Therefore, it is valid for user stories to do the allocating of instances to threads. The use of asynchronous message passing between them then follows.    

This is the GALS principle (Globally Asynchronous, locally synchronous) applied to threads.  


===== Messages and processes vs threads, mutable data and locks.

Many have suggested that a *messages and processes* execution model is a safer programming model than multithreading with mutable shared data and locks. 

By *process*, we mean a collection of code that all runs on the same thread, do not share memory with other processes, and communicate with asynchronous messages, that is the process has an incoming message queue.) 

In ALA, when you use multiple threads, you use the messages and processes execution model. This model naturally fits with ALA's wiring concept. The alternative of using synchronous messages and locks would have to be managed by the application or user story code in the higher layer of ALA, because only it knows which instances of abstractions run on which threads. This could be done but we really want the application code to be about describing the requirements, not taking care of all necessary locking.    





=== ALA Compared with functional programming

ALA is, essentially, functional programming. All the top layer code that implements the application itself by wiring up instances of domain abstractions in some combination is pure functional code. Domain abstractions are analogous to monads, but are more versatile than monads. 


==== ALA can be applied to pure functional programming

The fundamental ALA constraints could be applied directly to pure functional programming (not using monads). This would only require that the functions be good abstractions, and that functions would only call or use functions that are significantly more abstract than themselves.

But without monads, some functions would tend to be bad abstractions for two reasons.

1) Functions expose their inputs and outputs to the layer above, but the layer above is not interested in the data itself, only in the abstract concept of what the function does. It just wants to compose the functions with other functions, not deal with the run-time data.

2) Functions, or sets of functions, that naturally associate strongly with some state must have their state passed into and back out of them every time they are used. The layer above needs to handle this state data for the function. This is bad for the abstractions, both for the function and for the code in the higher layer.
+
Functional programming in one way encourages abstractions by not allowing side effects. However, this also destroys any abstractions that would otherwise be highly coherent with their own state. 
+
This problem gets even worse when there are several layers of functions. The middle layer functions end up with extra parameters that don't have anything to do with them, just so they can pass state data through to even lower functions. This makes these intermediate functions not great abstractions in themselves.

To solve these problems, functional programming uses monads. A full explanation of monads is in chapter six. This explanation is for programmers who are familiar with imperative programming in C#. They are compared in detail with ALA. 

Domain abstractions together with programming paradigms are a more versatile, more powerful but conceptually simpler analogue of monads. Domain abstractions are a more general solution than monads that allows any programming paradigms to be supported, and arbitrary networks of communications between them. The fundamental idea of monads, that of separating execution details, state, and I/O into pretested units that are then composed using pure functional code is the same for ALA.  



==== ALA uses state when that makes a good abstraction

The ALA constraints can be used for either object oriented or purely functional programming. Either way, using abstractions that have zero coupling with one another changes how the code is organised.

In pure functional programming, if the data and the functions are separate good  abstractions, then in ALA we would put both the data and the functions in the domain abstractions layer. Then user story functions in a higher layer would pass the data to the functions. However this handling of data by the higher layer functions, data that they themselves do not use, breaks them as good abstractions. Those top layer functions should only be concerned with composing the right data with the right functions, not handling the data itself. 

Also, sometimes pure functions that require state to be passed into them are not good abstractions. An example would be an averaging filter for a stream of data. Passing the running average to the function every time there is new input data breaks an otherwise good abstraction. There are many situations when referential transparency breaks abstractions whose very nature is to describe change over time.

ALA prioritizes abstraction over referential transparency. Each approach is just a method to achieve analysability. Referential transparency attempts to improve analysability by always removing time from the analysis, even when time is a fundamental aspect of what is being described. It will expose implementation details if necessary to do it. In contrast, abstractions attempt to improve analysability by providing a simple learnable, zero-coupled concept, which in turn hides its implementation details completely.

Many systems or subsystems are inherently state machines - they are driven by events and need to change their behaviour according to their history. Programs for such systems ultimately have mutable state. Functional programming tends to separate that state out causing design-time coupling between functions and this state data.

State is a fundamental aspect of a _computation_. I define a 'computation' as some state and a function:

 input + state --> state + output. 

We can associate the state in two ways:

 (input + state) --> (state + output)

 input ( + state --> state +) output

The first form is the pure functional form. The second form is the object oriented form.

In ALA we can use either form depending on where the abstractions are. When there is some state that is used by multiple user stories, then it would be put in its own abstraction. For example, a blackboard pattern or a game score could be an abstraction in itself. This abstraction could then be wired by user story abstractions in a higher layer to various abstractions implemented as pure functions.

In ALA we choose between these two philosophies on a case by case basis. When it makes sense to put state with methods as a class, and that makes a good abstraction, then there is no resulting coupling of that state with other classes. On the other hand, when it makes sense to keep state separate, we can put it in its own separate abstraction (in a class with ports). Either way, what you must not do is create direct associations between these classes. That will break them as abstractions. Instead, top layer user stories wire up instances of those classes by their ports.

In other words, the problem with object oriented programming is not that objects contain state per-se. It is that most classes are not good abstractions of a computation. We allow other objects to 'reach' into them or couple with them at design-time. They know there is state there, even if that 'reaching in' is via methods. This coupling is what makes conventional programs with state so hard to reason about.  

In summary, ALA works by preferring abstraction over referential transparency.






==== ALA compared with monads

In chapter six, there is an explanation of monads in terms of concrete code for people familiar with imperative programming. Here we assuming prior familiarity with monads in comparing them with ALA. ALA includes the power of monads, but in a more powerful, more flexible and more straight-forward way that can be applied to all parts of the code. 

When we use the term _monad library_ in this section, we are referring to a whole library based on monads. For the most common monad, which is the monad based on the IEnumerable interface, this library consists of the familiar functions such as Select, Where and Order found in LINQ.  

Strictly speaking, the monad itself only includes the Bind function (which is *SelectMany* in the case of the IEnumerable monad), not all the other map and reduce type functions you find in the library as well. A monad actually has three components, A Type<T> that it works on such as IEmuerable<T>, the bind function, and a function to convert a T to the Type<T>.


===== ALA and Monads are both about composition, but of objects vs functions

ALA and monads are both about composition, the fundamental mental tool of sound software writing. The difference between ALA and monads is that ALA composes objects whereas monads compose functions. Monads often _use_ objects under the covers, but in the application code in the higher layer you are composing functions. ALA embraces the composition of more powerful and flexible objects. 

With a monad library, your application code can combine functions in two different ways.

. Compose generic functions that are passed lambda functions. These more generic functions include Bind (SelectMany), Map (Select), Reduce (Aggregate), Filter (Where), Join, and GroupBy. Each takes a lambda function. The application code is composing the generic functions and confguring them with specific lambda functions.

. Compose more specific functions such as Repeat, Cast, Sum, First, Concat, Order. These functions generally work by themselves without also configuring them with lambda functions passed to them. 

Whether we consider the more generic functions, the lambda functions, or the more specific functions, most all the functions just have two 'ports', an input and an output. The input is the first parameter and the output is the return value. (Some functions such as Join, Zip, Concat, take two inputs.) ALA's domain abstractions, on the other hand, can have many ports for their inputs and outputs. Furthermore, these ports can use different programming paradigms, not just a specific data flow such as IEnumerable. Composing objects with ports is therefore a much more general tool for composition. It allows us to describe an entire application with composition, not just the piecemeal dataflow parts of it.  

Most of the monad library functions are designed to work with finite sequences. (That's why the IEnumerator interface has a Reset() method and the IObserver interface has an OnCompleted method.) Sum, for example, logically requires the input sequence to have a beginning and an end. A data stream can also be an infinite or continuous stream that flows forever like a river, but that is kind of a special case. It just never uses the Reset() method or the OnCompleted() method. The monad chain is usually used once per execution of the surrounding code. To be used again the code around it executes again, recreating the monad structure, and immediately running it again once. This is especially true of the monads based on IObservable because they generally stop working as soon as OnCompleted or OnError occurs. Subscribe() must be used to rewire and restart the monad chain execution again.     

In ALA, things are static (or declarative) on a larger scale than just a single line of monad code. In fact the entire application is wired up once at the beginning when the application starts executing, and then all ports are considered infinite steams that work as long as the application is running. To get a finite sequence, you design a port that is an infinite stream of finite sequences.

So the mental model of how ALA domain abstractions and monad libraries work is different. In ALA, the application code builds an entire application that is set then set running. With monads, this is done only on the scale of a single monad chain.  

Having said that, WPF (Windows Presentation Foundation) provides a declarative way to build the UI in addition to the dataflows. When WPF is used with bindings to LINQ expressions, much of a user story can be expressed declaratively. ALA just takes this declarative viewpoint to its logical completion and allows you to build the entire application. You can make any port types you like that go beyond just UI composition and dataflow composition.

To use an analogy, ALA's domain abstractions are somewhat analogous to wiring integrated circuits in electronics. Like domain abstractions, integrated circuits can have multiple ports (pins) of different types to suit the overall abstraction of the part. A part might have analogue, boolean and I2C protocol ports for example. ALA domain abstractions are like these parts. Monad libraries are more like discrete electronic components such as resistors and capacitors, components that just support one type with a single input and output.   


===== Monad versus ALA syntax

In ALA application layer code, you are wiring up instances of _abstractions_ in an _arbitrary network_ to expresses an _entire, cohesive_ user story. In contrast, in monad library application layer code, you are generally chaining _functions_, and only wiring up a _linear chain_ for the _dataflow part_ of a user story.

Because the monad syntax is designed for a linear chain of functions, the syntax using monads can be more succinct for linear parts of the network:

monad version
[source,C#]
....
source.Filter(x => x>0).Select(x => x+1)
....


ALA version
[source,C#]
....
source.WireIn(new Filter(x => x>=0)).WireIn(new Select(x => x+1)
....

However, we wouldn't normally create ALA domain abstractions to do the same jobs as monads if we already have a monad library. Instead, we would create a domain abstraction as an adapter with ALA ports. Into this adapter we can simply plug in a monad chain. Chapter six has details of how to this.

In ALA the usual pattern is to explicitly instantiate domain abstractions using _new_ and then explicitly wire their ports using _WireTo_ or _WireIn_. We could create extension methods to combine these two operations, but we prefer to keep it explicit because conceptually we are wiring up instances into a network analogous to wiring up components of a schematic diagram. A user story generally requires a network to express, not a linear chain of operators.

In ALA, we could write extension methods that would instantiate a specific domain abstraction and wire to the previous one using dot syntax all in one go. If the application code is generated from a diagram, it doesn't make any difference. If you are hand writing the wiring code, these extension methods might be worthwhile for very common cases. Chapter six has examples of how to do this.

Monad library code usually builds large object structures full of delegate objects, closure objects and other objects 'under the covers'. This 'under the covers' structure makes monads difficult to understand, trace and debug. ALA also creates object structures, but it's done explicitly with wiring code, so it's a lot easier to understand, trace and debug what is happening. 


===== Deferred push monads vs classes with push ports

Monads use the _Bind()_ function to combine functions. The Bind() function can work in two different ways. It can either call the functions immediately, evaluating the result as it goes along the chain, or it can wire up little closure objects containing the function and return a structure of objects which can then be evaluated later. I call this second types a deferred monad. For example, a monad based on the List type is an immediate type of monad, whereas a monad based on IEnumerable is a deferred type of monad. Most monads are defferred monads.

Deferred monads can work using either pull or push. The Bind function will return the end object in the chain for the pull form, so you can call it to pull the result out. The Bind function will return the first object in the chain for the push form, so you can give it a value and it will be pushed along the chain.  

A monad based on IEnumerable is a pull type. A monad based IObservable is a push form (except that IObservable is a bit weird - the bind function returns the last object and you subscribe to it, which propagates down the chain to the source which causes the source to start pushing.) See chapter six for code implementation examples of pull and push monads.

In ALA we prefer dataflow ports to work using push. Monads of the deferred push type are therefore what most closely compares with ALA. So that's the type of monad we will concentrate on in this section - monads based on IObservable. 

The deferred versions of monads are more difficult to understand in terms of equivalent imperative code because relatively simple expressions create large object structures containing delegates, closures, and other implicit objects under the covers. You can't really see any of them. I have reverse engineered them to diagrams to show how they work in detail in Chapter six. ALA is easier to understand because it just uses plain explicit objects that you instantiate and wire up. 

There is only one thing that is peculiar to ALA compared with conventional objected oriented programming. But it's so significant a change that it completely changes how you do object oriented programming. That is that the ALA objects must use _ports_. Ports must be wired by something external to the class higher up. In other words you are not allowed to make a class have an association with another peer class. You are not even allowed to make an association with an interface _belonging_ to a peer class. (Peer means in the same ALA layer.)  

Ports can also be thought of as just conventional dependency injection, but with two additional constraints.

. The interface that the port uses must be significantly more abstract. It can't be an interface that belongs to another peer class.

. The dependency injection wiring must be explicit. It must be specified in cohesive user story abstraction in a higher layer. The wiring cannot be done by using a dependency injection container or relying on matching interfaces. Because port interfaces are more abstract and can be used by many disparate classes, there is an infinite number of ways that objects could be wired together using their ports.

Another difference about ALA dependency injection is that I like to use reflection and implement a single WireTo extension method for wiring every port. That way I don't need constructor injection or setter injection methods for every port of every domain abstraction class. 


==== Why prefer deferred/push monads?

Deferred/push monads, as described above, are closest to the preferred ALA dataflow programming paradigm. Deferred/push monads have two useful properties.

. The first property comes from being deferred. Usually people write a deferred query using monads, and then immediately run the query. The deferred nature of the monads is not really utilized because the query is used immediately. Usually it needs to be run immediately because even though the query itself is a declarative description of a dataflow, it is used in a local imperative code context.
+
In ALA we describe the entire program declaratively first, so everything has to be deferred. Once the whole program is built, it can be set running. 
+
Since the program is built once, and then set running, queries built with SelectMany, Select etc, must be designed to be used more than once. The monads based on IEnumerable are fine in this respect because it has a Reset method that can be used to re-run the IEnumerable. However monads based on the IObservable interface are not designed to be able to run more than once. Once that OnCompleted or OnError method is called, the object structure wont run ever again. It has to be reconstructed by re-running the Subscribe method calls. I think this design in reactive extensions is rather limiting and even weird. You can have so called 'hot' observables, but that just means they never call OnCompleted or OnError.
+
So when I use IObservable monads as part of a user story, I need to rebuild the query in imperative code each time it is used. With ALA domain abstractions, on the other hand, I can build the user story once and just set it running forever.

. The other advantage of _deferred/push_ monads is the fact that they use _push_. In ALA we design dataflow or event programming paradigms to use _push_ by default, and only use _pull_ if there is some good reason to use pull.
+
The reason to prefer _push_ is that push can be either synchronous or asynchronous, whereas _pull_ can only be synchronous (unless you use future objects.) Push works when the wiring of instances of domain abstractions will go over a physical network for example. 


////
This method I make a push method, so it initiates from the source. I will often add an additional method that runs at the start of a data transfer as well. This method is to carry information such as header information. To accommodate this additional function, I don't use IObserver as the interface for the port. IObserver becomes something within the interface for the port. 

Sometimes I will add an additional method going in the opposite direction to the dataflow which is used by the destination to request that the data transfer starts. In an IObservable interface, the Subscribe method has two functions. Firstly it is used to wire up the IObserver interface in the opposite direction. Well in ALA, that is done by WireIn which wires IObserver interfaces, so we don't need the IObservable interface. However the other function of Subscribe is to request a data transfer. Sometimes we do want the destination end to request the data, even when the source is going to push it through. So in this case I will add a method to the interface to request a data transfer. 

You may think it would be better to use IEnumerable instead, but there is an advantage to using IObservable even when the destination needs to request the data. And that is that the IObserver interface can execute asynchronously. Since the domain abstractions themselves do not always know when they will be used in situations that need asynchronous communications, it is a great advantage to use push style programming paradigms which can do either synchronous or asynchronous, especially when there may be a lot of data to be transferred. It allows the data to be sent in batches. (IEnumerable can be made to work asynchronously as well, but it a lot more complicated as it involves futures.) 

The method used by the destination to request a data transfer goes in the opposite direction from the interface that actually carries the data. We could implement it as a C# event in that interface. This would mean that we have one interface, and it is wired in the direction of the dataflow. When using this 'request' programming paradigm, it seems more natural to wire in the direction of the request rather than in the direction of the dataflow. Therefore, I use a second interface, which is analogous to the IObservable interface. This new interface has the request method, and is the one we use for wiring. The first time a request is made, the method send the requesting object, which allows the source object to wire the interface that goes in the opposite direction. 

In ALA, because we can create programming paradigms and design the interface for them, it is easy to implement all the aforementioned extra methods and the interface.
////


=== Dependency graphs for ALA vs conventional code

Our example for this chapter compares dependency graphs for a legacy application and one with the same functionality written in ALA.

The legacy application had been maintained for approximately 20 years, so as might be expected, maintenance had become difficult. In fact there were certain new requirements we could not do because of the prohibitive effort. Normally I wouldn't ever re-write an application. But I wanted to run a research experiment to see how ALA would work on it. I had intern students available, and it would give us an opportunity to compare metrics of the two code bases.

The original application has around 70 KLOC. Rather than look at any of the details of the application itself, we present here dependency graphs generated by Ndepend for the legacy application and the new ALA application.

==== Legacy application dependency graphs

One of the core tenets of ALA (as discussed in an earlier section) is "Composition using layers" instead of "Hierarchical decomposition using encapsulation". Unfortunately Ndepend is designed with the assumption that the application should be built using the latter approach. It likes to present a decomposition structure, starting with assemblies (packages) at the outermost level, then namespaces, and then classes. I'm not sure why it considers namespaces a viable encapsulation mechanism because they don't provide encapsulation. 


////
Anyway, here is the namespace dependency graph for the main assembly of the legacy version of the application, as it comes out of Ndepend.

image::old-datalink/namespaces.png[namespaces.png, title="Legacy application - namespaces", link=images/old-datalink/namespaces.png]

This graph is quite large, so if you like you can right click on it, and open it in a new tab in your browser. The red arrows are dependencies in both directions.

Each box represents a namespace. The thickness of the arrows is proportional to the number fo dependencies between pairs of namespaces. The size of the boxes is proportional to the number of lines of code in the namespace.

If we drill down into the largest namespace, UIForms, we see the class relationships between classes inside that namespace:


image::old-datalink/classes-in-uiforms-namespace.png[classes-in-uiforms-namespace.png, title="Legacy application - classes in uiforms namespace", link=images/old-datalink/classes-in-uiforms-namespace.png]

Here you can see that Ndepend is trying to make out the layers. The layers are vertical columns, going from left to right. I have left them vertical even through ALA abstraction layers are usually drawn horizontal because they come out more readable on the page. Again there are many dependencies in both directions drawn in red.

Here are the classes inside the DataStructure namespace:

image::old-datalink/classes-in-datastructure-namespace.png[classes-in-datastructure-namespace.png, title="Legacy application - classes in datastructure namespace", link=images/old-datalink/classes-in-datastructure-namespace.png]

There is one class called Device which actually looks like it might be a good abstraction.
////

Namespaces provide no useful decomposition structure. They do not make abstractions in themselves, nor do they implement a facade pattern or an aggregate root type of pattern with even logical encapsulation. Any classes inside each namespace can have unconstrained direct relationships with any classes in any other namespace.

So Ndepend out of the box gives us a false picture, because it omits all dependencies that go in or out of namespaces. To really get an idea of what the class dependency graph looks like, I configured Ndepend to use a query that gives me all the classes in all the namespaces. Here is what the legacy application truly looks like: 

image::old-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="Legacy application - all classes in all namespaces",link=images/old-datalink/classes-in-all-namespaces.png]

This graph is very large. Right click on it, and open it in a new tab in your browser, so you can zoom in to see the dependencies in the background. It is truly frightening. Ndepend had no chance to find the dependency layers. There may be vague onion type layers going outwards from the middle. It makes readily visible why continued maintenance on this application is so difficult. You have to read a lot of code to find even a tiny part of this hidden structure.

The developer who maintains the application tells me this is a fair reflection of the complexity that he has to deal with.

To be fair, some of the dependencies in this diagram are 'good' dependencies (as described in an earlier section on good and bad dependencies). For example, the box near south-east called ScpProtocolManager has a lot of dependencies coming into it, which means it is possibly used a lot and therefore is potentially good abstraction. Ndepend does not know about the concept of good and bad dependencies, but if it did I would have it just display the bad ones.   


==== New ALA application dependency graphs

Here is the equivalent Ndepend generated class dependency graph for the new ALA version of the application. This graph has the classes from all namespaces.


image::new-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="New ALA application - classes in all namespaces", link=images/new-datalink/classes-in-all-namespaces.png]

You can see the three ALA layers which are vertical and go from left to right. Only the Application sits in the top layer. The DomainAbstractions layer contains the next two columns of classes and a few from the next column. And the ProgrammingParadigms layer contains the rest on the right. Actually there were a couple of bad dependencies present when this graph was generated which have since been fixed. (There should be no dependency between Panel and OptionBox, nor between Wizard and WizardItem.) With these removed, the graph would form into the three abstraction layers. 

The newly rewritten application is a work in progress at this point. However, as features are added, this is all the dependencies you will ever see. The Application already uses most of the domain abstractions we will ever need, and the domain abstractions already use the programming paradigm interfaces they need. There are a few DomainAbstractions to be added, but this is essentially what the class dependency graph will stay looking like.  

////
But just for interest, here is Ndepend's namespace dependency graph.


image::new-datalink/namespaces.png[namespaces.png, title="New ALA application - namespaces", link=images/new-datalink/namespaces.png]

Remember in ALA namespaces are layers. The dependencies are correct for the layers. 

Let's drill inside the domain abstraction namespace to see the interdependencies within that layer. We expect to see no dependencies:


image::new-datalink/classes-in-domainabstractions-namespace.png[classes-in-domainabstractions-namespace.png, title="New ALA application - classes in DomainAbstractions namespace", link=images/new-datalink/classes-in-domainabstractions-namespace.png]


Ok here we see the two previously mentioned bad dependencies, and two other dependencies. They are on delegates or enums in the same source file, and so don't count as bad dependencies.

And finally, let's drill into the ProgrammingParadigms namespace

image::new-datalink/classes-in-programmingparadigms-namespace.png[classes-in-programmingparadigms-namespace.png, title="New ALA application - Classes in Programming Paradigms namespace", link=images/new-datalink/classes-in-programmingparadigms-namespace.png]

Again we see a few dependencies on delegates in the same source file which are ok. There is a couple of connector classes that depend on interfaces in this same layer. I consider them part of the interface from the programming paradigm point of view. They are in the same source file as a cohesive unit.

////

As of this writing, the new ALA version of the application is still a research project, but so far everything has gone smoothly with two weeks spent doing the description of the requirements as a diagram, and 18 months so far spent writing the domain abstractions. So far there are no issues getting it to actually execute. It is expected that we will actually commercialize the project soon and replace the old application.


==== The application's diagram

As we said in this chapter, diagrams can be an important aspect of ALA when the user story naturally contains a network of relationships among its instances of abstractions. In this application this is the case. There are UI relationships between elements of the UI. There are dataflow relationships between UI elements, data processing elements, and data sources. There are event-flows from UI to wizards and between wizards and the SaveFileBrowser. and there are minor dataflows such as a the filepath from the file browser to the csvFileReaderWriter.

Here is a sample section from the application diagram that shows all the relationships that implement the user story:

image::DatalinkApplication.xmind.png[DatalinkApplication.xmind.png, title="Xmind being used to design an application", align="center", link=images/DatalinkApplication.xmind.png]

This diagram was drawn using Xmind. It shows a single user story.  There is a UI with a menu item or a tool bar to start the user story. It then displays a browse dialogue to specify the location of the file. When the filepath has been selected, it gets data off a device on a COM port, using a protocol, and writes it to a CSV file. The data is also routed to be shown on a grid on the UI.

The user story diagram makes use of four different programming paradigms (which become four different interface types). Firstly there is the UI structure consisting of the window with its menubar, grid etc arranged inside it. Secondly, there is an event connection for when the menu is clicked which opens the browse dialog. Thirdly a dataflow connection carries the output of the browse dialog, a string containing the selected filepath, to the CSVFileReaderWriter. Another dataflow connection carries characters between the COM port and the SCPProtocol and another carries SCPcommands from the SessionDataSCP. The forth programming paradigm is a table dataflow that carries dynamic columns and rows of data from the SessionDataSCP object to the grid object in the UI and to the CSVFileReaderWriter. 

Having drawn the diagram to represent the user story, we need to make the diagram execute. When we started this particular project we had no tool for automatically generating the code from the diagram, but during the project, one of the interns wrote a tool to do this. It parsed the Json output from Xmind and generated C# wiring code equivalent to what we will show below.

However, at first we were hand generating code, and it is instructive to know what this hand generated code looks like, just so we know how the diagram actually executes. 

When we were hand generating the code, it was important that the code was readable from the point of view of seeing how it corresponds exactly with the diagram. (It wasn't important that the code was readable from the point of view of seeing how the user story works - that was the job of the diagram.)  We had various conventions to support the one to one matching of diagram and code. One of these conventions was to indent the code to exactly mirror the tree structures in the diagram. Another was that whenever a new instance of an abstraction instantiated, all its ports would be wired immediately, and they would be wired in the order they were declared in the abstraction. This implies a depth first wiring strategy, analogous to walking the diagram tree depth first. Any ports with cross connections (the red lines in the diagram) would also be wired to their destinations at the time the abstraction were instantiated. If the destination instance did not already exist it would be pre-instantiated. 

Using these conventions, it is a simple matter to hand generate the code below from the diagram.


....
using System;
using System.Windows.Media;
using DomainAbstractions;
using Wiring;


namespace Application
{
    class Application
    {
        private MainWindow mainWindow = new MainWindow("App Name") { Icon = "XYZCompanyIcon"};

        [STAThread]
        public static void Main()
        {
            new Application().Initialize().mainWindow.Run();
        }

        private Application Initialize()
        {
            return this;
        }

        private Application()
        {
            var getInfoWizard = new Wizard("Get information off device") { SecondTitle = "What information do you want to get off the device?" };
            Grid DataGrid;
            var sessionDataSCP = new SessionDataSCP();
            var csvFileReaderWriter = new CSVFileReaderWriter();

            mainWindow
            // UI
                .WireTo(new Vertical()
                    .WireTo(new Menubar()
                        // XR3000
                        .WireTo(new Menu("File")
                            .WireTo(new MenuItem("Get information off device") { Icon = "GetDeviceIcon.png", ToolTip = "Get session data or LifeData or favourites from the device\nto save to a file or send to the cloud" }
                                .WireTo(getInfoWizard)
                            )
                            .WireTo(new MenuItem("Put information onto device") { Icon = "PutDeviceIcon.png" })
                            .WireTo(new MenuItem("Exit") { Icon = "ExitIcon.png" })
                        )
                        .WireTo(new Menu("Tools"))
                        .WireTo(new Menu("Help"))
                    )
                    .WireTo(new Toolbar()
                        // XR3000
                        .WireTo(new Tool("GetDeviceIcon.png") { ToolTip = "Get information off device" }
                            .WireTo(getInfoWizard)
                        )
                        .WireTo(new Tool("PutDeviceIcon.png") { ToolTip = "Put information onto device" })
                        .WireTo(new Tool("DeleteDeviceIcon.png") { ToolTip = "Delete information off device" })
                    )
                    .WireTo(new Horizontal()
                        .WireTo(new Grid() { InstanceName = "Sessions" })
                        .WireTo((DataGrid = new Grid() { InstanceName = "DataGrid" })
                            .WireFrom(sessionDataSCP)
                        )
                    )
                    .WireTo(new Statusbar()
                        .WireTo(new Text() { Color = Brushes.Green }
                            .WireFrom(new LiteralString("Connected to device"))
                        )
                    )
                );


            getInfoWizard
                .WireTo(new WizardItem("Get selected session files") { Icon = "IconSession.png", Checked = true }
                    .WireTo(new Wizard("Select destination") { SecondTitle = "What do you want to do with the session files?", ShowBackButton = true }
                        .WireTo(new WizardItem("Save selected sessions as files on the PC") { Icon = "SessionDocumentIcon.png", Checked = true }
                            .WireTo(new SaveFileBrowser("Select location to save data") { Icon = "SaveIcon.png", InitialPath = "%ProgramData%\XYZCompany"}
                                .WireTo(csvFileReaderWriter)
                            )
                        )
                        .WireTo(new WizardItem("Send records to NAIT") { Icon = "NAIT.png" })
                        .WireTo(new WizardItem("Send sessions to NLIS") { Icon = "NLIS.png" })
                    )
                    .WireTo(getInfoWizard)
                )
                .WireTo(new WizardItem("Get Lifedata"));

            var comPorts =
                new ComPortAdapter()
                    .WireTo(new SCPProtocol()
                        .WireTo(new SessionDataSCP()
                            .WireTo(DataGrid)
                            .WireTo(csvFileReaderWriter)
                        )

                    );

        }
    }
}
....

We used a 'diagram first' rule to keep the diagram and code in sync. Change the diagram first, then change the wiring code.

As of this writing, a graphical IDE is being developed for these types of ALA applications.








