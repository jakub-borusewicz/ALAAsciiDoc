:imagesdir: images


== Chapter one - What problem does it solve?

If you have already experienced difficult to maintain code, big balls of mud, spaghetti code, or the CRAP principle, you can probably skip this chapter.

However, the example at the end is pretty cool - it starts with the type of typical C code that I see most students write, and then refactors, it step by step, into ALA compliant code - you should take a look at that.

The problem that ALA solves can be seen as any one of the following perspectives.

=== The Big Ball of Mud

[.float-group]
-- 
image::dung.jpg[dung.jpg,400, title="The big ball of mud antipattern", float="right"]


Brian Foote and Joseph Yoder popularized this term in their 1997 paper. It describes the default architecture when no other architecture is used. A similar term is spaghetti code. I think it describes the architecture of most software even when so-called architectural styles, such as layering, are used.

ALA is an in-the-large strategy to organise code. It provides the constraints needed for the code structure to not degenerate into a big ball of mud. As the software  life cycle continues, retaining the organisation becomes easier rather than harder.

--

=== Simplify down the overwhelming set of architectural styles, patterns, and principles

There are many traditional architectural styles, patterns, principles and paradigms. The problem of structuring software code to meet quality attributes involves mastering an overwhelming number of them. Here are some examples:  


* loose coupling and high cohesion, information hiding, separation of concerns
* DSLs, aspects, model driven, MVC, inversion of control, functional programming, UML Class diagrams, sequence diagrams, activity diagram, state diagram.
* Views, Styles, Patterns, Tactics, Models, ADL's, ADD, SAAM, ATAM, 4+1, Decomposition
* CBD/CBSE, Components & Connectors, Pipes & Filters, n-tier, Client/Server, Plug-in, Microservices, Monolithic, Contracts, Message Bus
* Modules, Components, Layers, Classes, Objects, Abstraction, Granularity 
* Semantic coupling, Syntax coupling, Temporal coupling, existence coupling, Good and bad dependencies, Collaboration
* Interfaces, Polymorphism, Encapsulation, Contracts, Interface Intent
* Execution models, Event-Driven, Multithreaded, Mainloop, Data-driven, Concurrency, Reactor pattern, Race condition, Deadlock, Priority Inversion, Reactive 
* Principles: SRP, OCP, LSP, ISP, DIP; MVC, MVP, etc 
* Design Patterns: GOF patterns, GRASP patterns, Layers, Whole-Part, Observer, Strategy, Factory method, Wrapper, Composite, Decorator, Dependency Injection, Callbacks, Chain of Responsibility, etc
* Expressiveness, Fluency, DDD, Coding guidelines, Comments
* Programming Paradigms, Imperative, Declarative, Object oriented design, Activity-flow, Work-flow, Dataflow, Function blocks, Synchronous, State machine, GUI layout, Navigation-flow, Data Schema, Functional, Immutable objects, FRP, RX, Monads, AOP, Polyglot-Programming Paradigms
* Messaging: Push, Pull, Synchronous, Asynchronous, Shared memory, Signals & Slots
* Memory management, Heap, Persistence, Databases, ORMs
* Waterfall, Agile, Use cases, User stories, TDD, BDD, MDSD

Mastering all these topics takes a lifetime. Even if you can, juggling them all and being able to use the right ones at the right time is extremely taxing on any developer. Add to that the mastering of technologies and tools, keeping to agile sprint deadlines, and commitment to your team and management, it is an almost impossible task. 'Working code' tends to be what the team is judged on, especially by project managers or product owners who have no direct interest in architecture or even the Definition of Done. They don't want to know about the rather negative sounding term, "technical debt".

Most texts will tell you that these are all tools and that you need to use the right tools for each job. It all depends, they say, on the particular system, and its particular functional and non-functional requirements. In most cases they end up being used in an ad-hoc manner that doesn't work well. In some cases their use is actually harmful.

Being a pre-worked recipe of the aforementioned styles and patterns, ALA probably contains no truly novel ideas. Every aspect of what ALA does can be found already done by someone. However the combination that ALA uses is as far as I know unique.

Some ingredients from the above list are accentuated in importance more than you might expect (such as abstraction). Some are relatively neutral. The biggest surprise for me during the conception process of ALA was that some well-established software engineering memes seemed to be in conflict. Eventually I concluded that they were in-fact bad (such as UML class diagrams). We will discuss these in detail in subsequent chapters.

Like any good recipe, the ingredients work together to form a whole that is greater than the sum of the parts. The resulting code quality is significantly ahead of what the individual memes do by themselves. It continues to surprise me just how effective, and enjoyable, the simplified view is. 


=== An optimal solution for quality attributes

ALA is an optimal solution for these quality atributes:

** Readability
** Complexity
** Maintainability
** Testability
** Understandability
** Modifiability
** Extensibility
** Dependability
** Reusability

It is independent of any specific domain, so it is a general reference architecture. By optimal, I mean that it makes these qualities as good as they can be.


If other non-functional requirements are also important, ALA provides a good starting point. 

** Performance
** Availability
** Scalability
** Portability
** Distributability
** Security
** Usability
** Fault-tolerance

Even if the ALA structure must be compromised in places for other qualities, it is still better to start with these quality attributes optimised and deviate from them as necessary. As it happens, the maintainability resulting from ALA frequently makes other quality attributes easier to achieve as well. For example, in an ALA application it is often easy to make performance optimizations in the execution model that don't affect the application code. For example, an application first written to run on a single processor can more easily be distributed to multiple processors. Or, you can port an application by swapping out domain abstractions without changing the application code.



==== Readability 


[.float-group]
-- 
image::close_up_code.jpg[close_up_code.jpg,400, title="One big program", float="right"]

Modules don't necessarily make pieces of code that are readable in isolation.  

ALA code is readable, not because of style, convention, comments or documentation, but because any one piece of code appears to you as a separate uncoupled little program that is readable in complete isolation. 
--



==== Complexity

There is a meme in the software industry that says that the complexity of software must be some function of its size. This need not be so. With proper use of abstraction it is possible to have complexity that is constant regardless of program size. ALA makes use of this.

anchor:ComplexityGraph1[]

// [chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC,legend=bottom"]
[chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC"]
--
//Big ball of mud

1,	10
2,	20
5,	50
10,	100
20,	200
50,	500

//Loosely coupled

1,	10
2,	14
5,	22
10,	32
20,	45
50,	71
100,100
200,141
500,224
1000,316

//ALA

1,	10
2,	11
5,	12
10,	13
20,	13
50,	15
100,16
200,17
500,19
1000,20

//Code writer's brain limit

1,	100
2,	100
5,	100
10,	100
20,	100
50,	100
100,100
200,100
500,100
1000,100


//Code reader's brain limit

1,	50
2,	50
5,	50
10,	50
20,	50
50,	50
100,50
200,50
500,50
1000,50
--

This is a qualitative graph comparing the complexity of an ALA application with that of a big ball of mud and an average loosely coupled application. This is further explained in chapter seven <<Dijkstra1,here>>.


==== Maintainability

The maintainability effort over time should qualitatively follow the green curve in the graph below because as software artefacts are written, their reuse should reduce the effort required for other user stories. Product owners seem to have an innate sense that we manage to organise our code such that this happens. That is why they get so frustrated when things seem to take longer and longer over time, and they often ask us "haven't we done this before". In practice, too often we follow the red curve. Maintenance eventually gets so difficult that we want to throw it away and start again. We reason we can do better. My experience is that we don't do better when we rewrite. We just create another mess. It is just a psychological bias on the part of the developer caused by a combination of a) the Dunning Kruger effect and b) the fact that it is easier to read our own recently written code than someone else's.

If we apply all the well known styles and principles, the best we seem to be typically manage is the orange curve, which comes from the COCOMO models, and which still has maintenance effort continuously increasing.

When we did an experimental re-write of a legacy application using ALA, and measured its maintainability attribute, it comes out as improving over time by several different measures.



[chart,line,file="effort_curve.png", opt="title=Effort per user-story,x-label=months"]
--
//Big ball of mud
1,	5
2,	5
3,	6
4,	6
5,	7
6,	8
7,	9
8,	10
9,	12
10,	13
11,	15
12,	17
13,	19
14,	21
15,	24
16,	28
17,	32
18,	37
19,	43

//Cocomo
1,	16
2,	17
3,	17
4,	18
5,	18
6,	19
7,	19
8,	19
9,	19
10,	20
11,	20
12,	20
13,	20
14,	20
15,	20
16,	20
17,	21
18,	21
19,	21
20,	21
21,	21
22,	21
23,	21
24,	21

//ALA
1,	30
2,	21
3,	17
4,	15
5,	13
6,	11
7,	10
8,	9
9,	8
10,	8
11,	7
12,	7
13,	6
14,	6
15,	5
16,	5
17,	4
18,	4
19,	3
20,	3
21,	3
22,	2
23,	2
24,	2
--

ALA is based on the theoretical architectural constraints needed to follow the green curve. 


==== Testability

In ALA all code is testable. ALA makes it clear when to mock and when to test with dependencies in place. All dependencies are left in place, because all dependencies are design-time or knowledge dependencies. 

Therefore, when testing the application layer abstractions, they are tested with their domain abstraction dependencies. In other words, testing the application is acceptance testing.

Testing domain abstractions is easy with units tests because abstractions are zero-coupled. Mocks objects are wired to ports.



=== Structure hidden inside the modules

The problem in most large code bases is that the system structure, the in-the-large structure, is not explicit. It is distributed inside the modules themselves. Collaboration between modules is implicitly hidden inside them. Finding this structure, even for a single user story can be time consuming. I have often spent a whole day doing that, doing countless all-files searches following function calls or method calls of the user story through many modules just to end up changing one line of code. Many developers I have spoken to can identify with this experience.

It can get a lot worse as the system gets larger. In a seemingly bizarre twist, the more loosely coupled you make the elements, the harder it gets to trace a user story because of the indirections. Some people conclude that loose coupling and being able to trace through a user-story are naturally in conflict.

I call this situation SMITA (Structure Missing in the Action). The internal structure is sometimes drawn as a model - high-level documentation of the hidden structure. But such models are a secondary source of truth.

ALA completely eliminates this problem and this conflict. The structure is explicitly coded in one place, without any indirections. Yet the abstractions are zero-coupled. 







=== The CRAP cycle

Typical bright young engineers come out of university knowing C++ or Java (or other C*, low-level, imperative, language that mimics the silicon), and are confident that, because the language is Turing-complete, if they string together enough statements, they can accomplish anything. At first they can. There hardly seems a need for a software architect to be involved. And besides, we are told that a design can emerge through incremental refactoring.

image::Cynefin.jpg[Cynefin.jpg,800, title="Code can quickly follow the Cynefin quadrants into the complex",link=images/Cynefin.jpg]

As the program gets larger, things get a little more complicated, but the young developer's brain is still up to the task, not realizing he has already surpassed anyone else's ability to read his code. He is still able to get more features working. One day parts of the 'transition'. It becomes somewhere you don't want to go. On the Cynfin diagram, it has transitioned from the complicated quadrant to the complex quadrant. And now it is trapped there. It is too complex for refactoring.  

The incremental effort to maintain starts to eat away and eventually exceed the incremental increase in value. This now negative return causes the codebase itself to eventually lose value, until it is no longer an asset to the business. 

It has transitioned to chaos. It will be abandoned. When a new bright young engineer who knows C* arrives, he looks at the legacy codebase and is convinced that he can do better. And the cycle repeats. This is the CRAP cycle (Create, Repair, Abandon, rePlace). ALA is the only method I know that can prevent the CRAP cycle.


==== A short history of ALA

From early on in my career, I experienced the CRAP cycle, not so much rewriting applications, but trying to avoid the mess when writing new ones. When starting from a blank piece of paper, I would research all the architectural styles and principles. I would come across things like 'loose coupling', and I remember asking myself, yes but how does one accomplish that? Each time I would still fail.

I started searching for a pre-worked, generally applicable, 'template architecture' that would tell me what the organisation of the code should look like for any program. I searched for such a thing many times over a long career and never found one. Some would say that this is because the highest level structure depends on project specific requirements.

Finally, near the end of my career, I have that template meta-structure that's applicable to all programs. The turning point was when I noticed two (accidental) successes in parts of two projects. These successes were only noticed years later, 15 years in one case and 5 years in the other. They had each undergone considerable maintenance during that time. But their simplicity had never degraded and their maintenance had always been straightforward. It was like being at a rubbish dump and noticing two pieces of metal that had never rusted. "That's weird", you think to yourself. "What is going on here?"

One of them had the same functionality as another piece of software that I had written years earlier. That software was the worst I had ever written. It was truly a big ball of mud, and maintenance had become completely impossible, causing the whole product to be abandoned. So it wasn't what the software did that made the difference between good and bad. It was how it was done.

Analysing the common properties of those two code bases, gave clues that eventually resulted in a theoretical understanding of how to deal with complex systems. This meta-structure is what I now call Abstraction Layered Architecture.

Subsequently, I ran some experiments to see if the maintainability and non-complexity could be predictably reproduced. These experiments, which have worked spectacularly well so far, are discussed as a project at the end of every chapter.


=== Example project - Thermometer

In this example project, we will first do conventional C code using functions, then refactor it into abstraction layers, and finally improve on that using classes.  

// Applying ALA to functional composition means three things:

// *  Functions (or small groups of them) are abstractions.

// For our purpose here, an abstraction means that our brain can easily learn (by reading the function name or a comment) and retain what a function essentially does. It means that when other programmers are reading your code where a function is called, they don't have to 'follow the indirection' - they can stay with the code unit they are in, and read it like any other line of code. It means a single responsibility. It means it knows nothing about the content of any other abstractions. It means reuseable, and it means stable. The name of the function should not be generic ProcessData, or CalculateResult. It should not be the name of the event that caused it to be executed like PulseComplete. If it calculates a result, it does not know where that result goes. It does not directly call another abstraction at the same level. Instead, it either returns it, or calls a function that was passed to it (like the functional programming guys do).

// * Functions go in a small number of discrete abstraction levels.

// This implies that function call depth is at most three (not counting library functions at a 4th level).

// The first level function contains all knowledge about the application requirements. No implementation here, just describe the requirements in terms of other functions.

// The second level is functions that contain knowledge about reusable operations in the problem domain. It has all the abstractions needed to make it possible for the first level to describe the requirements. No function at this level knows anything about the specific application. An example would be calculate mortgage repayments, or filter data.

// The third level functions are at an even greater level of abstraction, things that would be potentially reusable in many domains. It should have the abstraction level of the types of programming problems being solved. Examples might be communications, persistence, logging. None of these functions can have any knowledge of the specific application, nor the domain. So the persistence functions are not persistence of specific domain objects. With configuration, they would know how to persist anything.  

// A function that doesn't clearly belong at one of these abstraction levels should be split in two. Specific application knowledge generally becomes configuration parameters in the higher layer of a more abstract function in the domain layer.

// For completeness, a 4th level would be your programming language library. Nowhere in these levels is the underlying hardware, nor data. Later we will see where they go, but for now forget all preconceived notions of layers such as UI, business logic and Database. In ALA, these are not layers, just abstractions in the domain layer (that know nothing about each other) that get wired together by the application in the top layer.  

// * The top layer just describes the requirements.

// The top layer describes requirements and that's all it does (like a DSL). It composes functions from the lower layers, and configures them for a specific purpose according to the requirements. 

Functions have an execution model we are already familiar with, making this first example easier to understand. However, keep in mind that, for whole programs, this execution model does not usually make a good programming paradigm. An emergent property of ALA is its support of multiple and diverse programming paradigms including your own. We do this to improve expressiveness of the requirements. 

Nevertheless, functional composition is a passable programming paradigm for a tiny, dedicated embedded program in a micro-controller such as our thermometer. Let's have a look at some typical code:


==== Bad code

.configurations.h
[source,C]
 #define BATCHSIZE 100
 
.main.c
[source,C]
 #include "configurations.h"
 void main()
 {
    int temperatures[BATCHSIZE];
    ConfigureTemperaturesAdc();
    while (1)
    {
        GetTemperaturesFromAdc(temperatures); // gets a batch of readings at a time
        ProcessTemperatures(tempertures)
    }
 }

.process.c
[source,C]
 void ProcessTemperatures(int adcs[])  
 {
    float temperature;
    for (i = 0; i<BATCHSIZE; i++) {  
        temperature = (adcs[i] + 4) * 8.3; // convert adc to celcius  
        temperature = SmoothTemperature(temperature);  
        ResampleTemperature(temperature);
    }
 }

.Resample.c
[source,C]
 void ResampleTemperature(float temperature)  
 {
    static int counter = 0;
    counter++;
    if (counter==15)
    {
        DisplayTemperature(temperature);
        counter = 0;
    }
 }

.smooth.c
[source,C]
 // smooth the reading before displaying
 float SmoothTemperature(float temperature) 
 {
    static filtered = 0;
    filtered = filtered*9/10 + temperature/10; 
    return filtered;
 }

.adc.c
[source,C]
 #include "configurations.h"
 void ConfigureTemperaturesAdc()
 {
    // configure ADC channel 2 to do DMA BATCHSIZE values at a time
 }
 float GetTemperaturesFromAdc(int temperatures[]) 
 {
    for (i = 0; i<BATCHSIZE; i++) {
        temperature[i] = ReadAdcChannel(2);  // pseudocode here for the adc read
    }
 }

////
<1> function name is specific to this application, destroying it as a potential abstraction
<2> functions are collaborating to implement the 100 samples at a time requirement
<3> details from requirements appearing inside functions (all the constants), destroying potential abstractions
<4> function name doesn't describe an abstraction
<5> function has three responsibilities, process 100 samples at a time, convert to Celsius, and Filtering
<6> function composition in wrong level (only the application knows this needs doing
<7> function composition too deep (function composition should be shallow)
<8> Temporal problems - if adc readings take 1 ms, main loop time is 100 ms
////

At first this code wont look that bad, but that's only because the whole program is so small. It looks modular, but you still have to read all of it to understand any part of it. That's possible for small programs, but of course that strategy won't scale up.

As we are taught to do, different responsibilities of the thermometer implementation have been separated out into smaller pieces with smaller responsibilities, although ProcessTemperatures appears to have three responsibilities. The problem is that all the pieces are in some way collaborating to make a thermometer. They are all coupled in some way, both explicitly or implicitly. That's why we have to read all the code to understand the thermometer. Scale this up to 5000 lines of code, and we will have a big mess.


We are going to refactor the program using the ALA strategy:

* every piece of knowledge about 'being a thermometer' will be in one function
* that 'Thermometer' function will be at the top
* that function will do no real work itself
* how to do more abstract things will be put into other functions
* those functions will not know anything about temperature or thermometer
* The top layer function will compose the abstract functions it needs to build a thermometer

==== Toward ALA code




.application.c
[source,C]
 #define BATCHSIZE 100
 void main()
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // channel=2
        for (i = 0; i<BATCHSIZE; i++) {
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        }
    }
 }



.offsetandscale.c - (domain abstraction)
[source,C]
 // offset and scale a value
 void OffsetAndScale(float data, float offset, float scale) 
 {
    return (data + offset) * scale;
 }



.filter.c - (domain abstraction)
[source,C] 
 // IIR 1st order filter, higher filterstrength is lower cutoff frequency 
 float Filter(float input, int strength)  
 {
    static float filtered = 0.0; 
    filtered = (filtered * (strength-1) + input) / strength
    return filtered;
 }



.resample.c - (domain abstraction)
[source,C] 
 // Returns true every n times it is called
 bool SampleEvery(int n)  
 {
    static counter = 0; 
    counter++;
    if (counter>=n)
    {
       counter = 0;
       rv = true;
    }
    else
    {
       rv =  false;
    }
    return rv;
 }


The code now begins to be arranged into two abstraction layers, the application layer and the domain abstractions layer. The application is now the only function that knows about being a thermometer. (It is still doing some logic work - the 'for loop' and 'if statement', which we will address soon.) 

All the other functions are now more abstract - they know nothing about thermometers - GetAdcReadings, OffsetAndScale, SampleEvery, Filter, FloatToString, and Display. Notice that the word 'thermometer' has been removed from their names, and none of them contain constants or any other references that are to do with a thermometer or temperature. 

These abstract functions give you six things:

. Abstract functions are way easier to learn and remember what they do
. Abstract functions give *design-time* encapsulation i.e. zero coupling.
. Abstract functions can be understood by themselves
. Abstract function interfaces are way more stable - as stable as the concept of the abstraction itself
. Abstract functions are reusable
. Abstract functions are testable
. As a consequence of 1., the application function can also now be understood by itself


Now let's go one more step and create an abstraction to do what that for loop does: This may seem like a retrograde step, but we need to understand this mechanism to move to our final goal of expressing the requirements through pure composition of abstractions. We want to move the 'for loop' out into its own abstraction, but we don't want to move the code that's inside it. We accomplish this by putting the code inside it into another function and passing that function to the for loop function:  



==== Further toward ALA code


.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // channel=2 
        foreach(adcs, func1);
    }
 }
 void func1(float adc)
 {  
    temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
    smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
    if (SampleEvery(15)) 
    {
        Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
    );
 }



.foreach.c
[source,C]
 void foreach(int values[], void (*f)(int))
 {
    for (i = 0; i<sizeof(values)/sizeof(*values); i++) {
        (*f)(values[i]);
    }
 }




"func1" is not an abstraction - you cannot give it a name and learn a simple concept of what it does. That's why I gave it a non-descript name. The content of func1 is cohesively just part of the thermometer application. The name _func1_ only serves as a symbolic connection within cohesive code - nothing more than a wiring between two points in the program. In this case func1 is immediately below where it is used in the same small file. But as a program grows, these symbolic wirings are always hard to follow. You would need to resort to text searches to find these connections. These types of connections can be numerous and unstructured in larger programs, and the best way to deal with them is diagrams. A line on a diagram is like a symbolic connection between two points, but it's anonymous and easy to follow. However, this particular one can be dealt with in text form. So let's go ahead and remove it by using an anonymous function directly as the second parameter of foreach: 




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // channel=2 
        foreach(adcs, (adc)=>{
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        });
    }
 }


It uses the lambda syntax '()=>{}', which if you are not already familiar with, is worth getting used to. It's a function without a name, so think of the => as being instead of the name of the function, the round brackets as the parameters, and the curly braces as the body of the function. 

The next thing we want to do is get rid of the while loop, get rid of the indenting, and stop handling the data that is being passed from one function to another. None of them have anything to do with a thermometer. All those intermediate holding variables: adcs, temperatureCelcius, etc are all just symbolic connections. They are too much work when we just want to compose our thermometer from abstractions.

The while loop and all the indenting are there only because we have 'execution flow' tied in with our composition of abstractions. Basically we want to make control of execution flow another abstraction so that the thermometer can be built by just composing abstractions rather than writing executing code. 

To do this we will first show how its done using monads. If you don't know about monads just skip the section as we don't need this step to understand our final goal. But for those who do understand monads, it is interesting to visit this step to see why the functional programming guys invented them. Then in the following step we will go to ordinary classes with ports instead of monads.

////
<1> The application function is readable in isolation (without having to go and read code inside any of the abstractions.
<2> The application describes the thermometer, has all the details of the thermometer, and does nothing else. It delegates all the actual work to the domain abstractions. The application knows nothing of how the abstractions work, only what they do.
<3> None of the abstractions know anything about each other or anything about the application. They don't know they are being used to make a thermometer. They are readable in isolation. It easy to remeber what they do. They are more stable. They are reusable.
<4> Application knows the detail of how many ADC readings to get at a time for performance, but not that the adc uses dma to do that. 
<5> Application knows the conversion factor from ADC to Celsius but not how to do offsetting and scaling.
<6> Application knows the amount of filtering needed to get a smooth thermometer but not how to do filtering.
<7> The emphasis is on 'abstraction' not on 'zero side effects'. Filter and SampleEvery are good abstractions despite having a side effect.

These are more properties of the abstraction layered version:

* The application can easily be rewired to do things like the following examples:
** swap the order of processing of the SampleEvery and the filtering to improve performance
** insert a new data processing operation between say the scaling and the filter
** add a logging output destination
** switch to a different type of ADC or display
** add adapters or wrappers for using 3rd party components

* If the requirements of the thermometer change, no domain abstractions would change - because they don't know anything specific about thermometers.  

* In this 'functional composition', at run-time, data comes up into the application code layer and back down into the domain abstractions layer at each step. That's why the application has some local variables to store the data temporarily at various points during the processing. In most other programming paradigms we will use, the data will not come up to the application layer at run-time. Instead, it will go directly between the instances of the domain abstractions. The application will be concerned with wiring them together, not with handling data.
////

////

==== Composing with lambda functions

In the previous code, the application code was handling the data at run-time. It was using those intermediate variables to store the data it received from each function, and then passing that data to the next function. But it wasn't doing anything with the data. It would be much nicer if the application just did the job of composing the functions, but the data passed directly from one to another at rin-time.

This can be accomplished (in a awkward manner) using anonymous lambda functions. Each function has the next function passed into it:




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()
 {
    ConfigureAdc(Channel=2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(Channel=2, DmaBatchSize=DMABATCHSIZE, (values) => 
            {
                foreach(values, (value)=> 
                    { 
                        OffsetAndScale(value, offset=4, slope=8.3, (value)=>
                            {
                                Filter(value, 10, (value)=>
                                    {
                                        SampleEvery(value, 15, Display);
                                    }
                                );
                            }
                        );
                    }
                );
            }
        );
    }
 }






It also allows us to take the for loop logic out of the application and use an abstraction instead, "foreach".
It gets us closer from a composition of abstractions point of view, but all that indenting is impractical. And we needed almost empty lambda functions just to contain the other functions. We need a fluent syntax to express the composition. Lets see how it looks using monads.

////

==== Brief detour: composing with monads

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(channel=2, batchSize=100)
    .foreach()
    .OffsetAndScale(offset=4, slope=8.3)
    .Filter(strength=10)
    .SampleEvery(15)
    .NumberToString(format="#.#")
    .Display();
    
    program.Run();
 }
....



Monads have allowed us to separate execution flow from composition flow. The composition flow is now a pure dataflow paradigm. Data will flow from the ADC to the display, so that is directly represented by the composition. How it executes is separated out, and we will go into how that works shortly. Let's first understand the 'composition' and why this is so important.

Even if you don't understand how the monads work, you can see that syntactically the program is now very nice because all it does is compose instances of abstractions, and configure them with constants to be a thermometer. The composition is not declarative - it is _dataflow_, because dataflow suits how to describe the thermometer. If we let go of how it executes and just trust that the dataflow from one instance of an abstraction to the next works, the program becomes highly readable.

////
It suits where a part of a program has all of these characteristics:

. dedicated CPU 
. process a job as fast as it can in computer time
. doesn't have to wait for anything while it is being done
. nothing else needs doing while this is happening
. the sequence is known ahead of time (proactive not reactive)


An 'algorithm' is an example of something that suits functional composition.

It is common to use multi-threading as the solution to the first four problems in the bullet list. That is a really bad and dangerous way to force what is fundamentally the wrong programming programming paradigm to do the job. Multiple threads are good to solve a small class of performance problems only. The programming paradigms we will use throughout the examples in this book are way better at expressing solutions than multiple concurrent threads exchanong messages. End of rant.

////

We are using the word 'composition' here to mean the things we are joining together in adjacent lines of code. It can also mean joining boxes with lines in a diagram. Think of a composition as analogous to the adjacent notes in a music score, which are always played successively. If the lines of code are statements or function calls, we are composing things for imperative execution by the CPU. If the lines of code are data processors, we are composing things for successive processing of data. The output of one passes directly to the input of the next. 

If we are stuck with thinking in terms of imperative execution flow (the only way of thinking in the C language) we will need to try hard to let that go, and realize that in ALA, 'composition' can be any programming paradigm you want.  

Also notice that the first statement just builds the program. Then the second statement sets it running. This two stage aspect of monads is common in the programming paradigms we will use in ALA. It is because the underlying execution flow is not the same as the flow of the programming paradigm. We first wire it up, and then we tell the wired up structure to 'execute'.

There is a second important difference from the while loop version. The while loop version handled the data itself. Each function returned the data which was stored in a local, otherwise useless, variable and then passed into the next function. The monad code doesn't do that. Instead, it creates and wires together objects which will, at run-time, send the data directly from one to another via an interface. This does not mean that the abstractions themselves know anything about each other - they are still zero coupled. But the application now doesn't have to deal with the mechanics of dataflow. It just has to compose abstractions.

Lastly, here's how monads actually execute - the execution model. Don't worry if this doesn't make sense. 

Each function in the program statement (the function after each dot) executes once at the start. They are not executed when the program is running. Each of these functions first instantiates an object (using new), and secondly wires that object to the previous object. 

The functions wire the objects together using an abstract interface. Common interfaces used for monads are IEnumerable or IObservable. These interfaces support iteration of data, by returning an IEnmerator or IObserver. If using the IEnumerator interface, there is a simple method in the interface that pulls data from the previous object. If using the IObseravble interface, there is a simple method in the interface that pushes data to the next object. So IEnumerable/IEnumerator and IObservable/IObserver as abstractions are pretty much just the concept of dataflow, the same abstract concept we will use in the ALA version. 



==== Composing with plain objects


////
The most common programming paradigm we will likely want to use is dataflow. When we compose domain abstractions together using this paradigm, we mean that at run-time data will pass between adjacently wired instances. There may be waits, thread swaps, or IO along the way. It may take days for the data to flow through. But the flow is directly expressed as adjacent lines of code. A dataflow implementation used in functional programming is monads. We wont learn further about monads here (many have attempted to explain monads and failed), except to say that this is what the Thermometer example might look like using them. 
////

Here is the same program as above, but we are using plain classes with ports instead of monads. We use the 'new' keyword explicitly to create the instances of abstractions, and explicitly wire them together using a wiring function. It's a little less succinct than the monad version, but the idea of "objects with ports that you wire together like electronic components" is easier to understand, and more versatile. It is necessary for developers to be able to write new domain abstractions, so this needs to be easy.

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(channel=2,batchSize=100)
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(strength=10))
        .wireIn(new SampleEvery(15))
        .WireIn(new NumberToString(format="#.#")
        .wireIn(new Display());
       
    program.Run();
 }
....


The wireIn method is doing dependency injection. 

The WireIn method returns the new object, so it is possible to string WireIns together. This is called fluent syntax. 


==== Using multiple programming paradigms:


Monads are generally not versatile enough to handle multiple ports of different programming paradigms, which we will want in ALA programs. Abstractions usually only support dataflow. But what if we want to also compose the UI, or event-driven? What if we want to compose transitions between states of a state machine? In ALA, we are able to do all this in the one application, in the same way - using whatever programming paradigms are the best way to express the requirements. 

Some instances of abstractions will need to take part in multiple paradigms, such as both UI and dataflow. When we boil down the description of our requirements to pure composition, our composition will often be a graph of relationships. And when you have a graph, your composition is best described by a diagram. 

To illustrate this let's add some UI to our thermometer:

image::ThermometerDiagram.png[ThermometerDiagram.png,500, title="Thermometer application complete with UI"]


The diagram has both UI composition and dataflow composition. For the UI part of the composition, the lines obviously don't mean dataflow - they mean 'display inside'. So now different lines in our diagram have different meanings. Here is how that diagram is represented as text. 




.application.c
[source,C]
....
 void main()
 {
    FloatField temperature;
 
    program = new ADC(channel=2)
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(10))
        .wireIn(new SampleEvery(100))
        .WireIn(new NumberToString()
        .wireIn(temperature = new FloatField());
    
    mainwindow = new Window()
       .wireTo(new Label("Temperture:"))
       .WireTo(temperature);

    mainwindow.Run();
 }
....

The text of the ALA thermometer has a symbolic connection for one of the wirings, "temperature". This is ok in this small program, but doing that won't scale up. That is why we consider the diagram to be the source, and this text version is generated from it.

Looking once again at the diagram, you can see that ALA has allowed us to keep all cohesive knowledge about a thermometer together, and quite succinctly. It contains all the details needed to describe a thermometer, but does so in terms of domain abstractions that are not specific to a thermometer at all. There is no implementation in the application code. All implementation is done by domain abstractions. If you can see that point in the example code, then you are pretty much understanding ALA.

Once we have this diagram, it is easy to conceive how we might add features. For example, we could add two radio buttons into the UI, and wire then to a switcher abstraction that switches the data path between two instances of OffsetAndScale to change between Celcius and Faranheit.


