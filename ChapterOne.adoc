:imagesdir: images


== Chapter one - What problem does it solve?



=== The Big Ball of Mud

ALA is an in-the-large strategy to organise code. It provides the constraints needed for the code structure to never degenerate into sphagetti code, or what Brian Foote and Joseph Yoder describe as a "big ball of mud". As the software  life cycle continues, retaining the organisation becomes easier rather than harder. This is because of increasing reuse of software artefacts within the organisation.



=== Existing architectural patterns

There are many existing architectural styles, patterns, or principles: loose coupling and high cohesion, information hiding, layers, decomposition, DSLs, components, aspects, models, event-driven, MVC, composite, inversion of control, functional programming, object oriented design, UML Class diagrams are all examples.

This set is sufficient, but there is no overarching strategy that tells you how to combine tham all in a coherent way. in most cases they are used in an ad-hoc manner that doesn't work. In some cases their use is actually harmful. ALA provides a large scale organisational framework into which all of these fit.

=== An optimal reference architecture

ALA is a reference architecture. It is independent of any specific domain, so it is a general reference architecture. The reference architecture is 'optimal' for certain non-functional requirements. By optimal, I mean that it makes these qualities as good as they can be.

** Complexity
** Readability
** Maintainability
** Testability

If other non-functional requirements are also important, ALA provides a good starting point. Even if the ALA structure must be compromised for other qualities, it is still better to start with these quality attributes optimised and deviate from them as necessary. As it happens, the maintainability resulting from ALA frequently makes other quality attributes easy to achieve as well. For example, in an ALA application it is often easy to make performance optimizations in the execution model that don't affect the application code. Or, you can port an application without changing the application code.  


==== Readability 


[.float-group]
-- 
image::close_up_code.jpg[close_up_code.jpg,400, title="Code quickly becomes a big ball of mud", float="right"]

ALA code is readable, not because of style, convention, comments or documentation, but because any one piece of code appears to you as a separate uncoupled little program. 
--



==== Complexity

There is a meme in the software industry that says that the complexity of software must be some function of its size. This need not be so. With proper use of abstraction it is possible to have complexity that is constant regardless of program size. ALA makes use of this.

anchor:ComplexityGraph1[]

[chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC,legend=right"]
--
//Big ball of mud
1,	10
2,	20
5,	50
10,	100
20,	200
50,	500

//Loosely coupled
1,	10
2,	14
5,	22
10,	32
20,	45
50,	71
100,100
200,141
500,224
1000,316

//ALA
1,	10
2,	11
5,	12
10,	13
20,	13
50,	15
100,16
200,17
500,19
1000,20

//Code writer's brain limit
1,	100
2,	100
5,	100
10,	100
20,	100
50,	100
100,100
200,100
500,100
1000,100

//Code reader's brain limit
1,	50
2,	50
5,	50
10,	50
20,	50
50,	50
100,50
200,50
500,50
1000,50
--

This is a qualitative graph comparing the complexity of an ALA application with that of a big ball of mud and an average loosely coupled application. This is further explained later <<ComplexityGraph2,here>>.


==== Maintainability

The maintainability effort over time should qualitatively follow the green curve in the graph below because as software artefacts are written, their reuse should reduce the effort required for other user stories. Product owners seem to have an innate sense that we manage to organise our code such that this happens. That is why they get so frustrated when things seem to take longer and longer over time, and they often ask us "haven't we done this before". In practice, too often we follow the red curve. Maintenance eventually gets so difficult that we want to throw it away and start again. We reason we can do better. My experience is that we don't do better when we rewrite. We just create another mess. It is just a psychological bias on the part of the developer caused by a combination of a) the Dunning Kruger effect and b) the fact that it is easier to read our own recently written code than someone else's.

If we apply all the well known styles and principles, the best we seem to be able to manage is the orange curve, which still has maintenance effort continuously increasing with an exponential factor.

However, whenever we have done an experimental re-write using ALA, it comes out spectacularly better.



[chart,line,file="effort_curve.png", opt="title=Effort per user-story,x-label=months"]
--
//Big ball of mud
1,	5
2,	5
3,	6
4,	6
5,	7
6,	8
7,	9
8,	10
9,	12
10,	13
11,	15
12,	17
13,	19
14,	21
15,	24
16,	28
17,	32
18,	37
19,	43

//Cocomo
1,	16
2,	17
3,	17
4,	18
5,	18
6,	19
7,	19
8,	19
9,	19
10,	20
11,	20
12,	20
13,	20
14,	20
15,	20
16,	20
17,	21
18,	21
19,	21
20,	21
21,	21
22,	21
23,	21
24,	21

//ALA
1,	30
2,	21
3,	17
4,	15
5,	13
6,	11
7,	10
8,	9
9,	8
10,	8
11,	7
12,	7
13,	6
14,	6
15,	5
16,	5
17,	4
18,	4
19,	3
20,	3
21,	3
22,	2
23,	2
24,	2
--

ALA is based on the theoretical architectural constraints needed to follow the green curve. 


==== Testability


=== Domain oriented

As has been found useful in other methodologies such as Domain Specific Languages, Domain Driven Design, Model Driven Software Development and Language Oriented Programming, ALA provides a way to be 'domain oriented'. 

But unlike most of the other domain oriented methodologies, ALA provides a way to be domain oriented with ordinary code, and with the same development environment. It is just a way to organise ordinary code to be domain oriented.

=== The software engineer's trap

Typical bright young engineers come out of university knowing C++ or Java (or other C*, low-level, imperative, language that mimics the silicon), and are confident that, because the language is Turing-complete, if they string together enough statements, they can accomplish anything. At first they can. Agile methods only require them to deliver an increment of functionality. There hardly seems a need for a software architect to be involved. And besides, we are told that any design can emerge through incremental refactoring.

image::Cynefin.jpg[Cynefin.jpg,, title="Code can quickly get complex", float="left"]

As the program gets larger, things are getting a little more complicated, but the young developer's brain is still up to the task, not realizing he has already surpassed anyone else's ability to read the code. He is still able to get more and more features working. One day the code suddenly 'transitions'. It transitions from the complicated quadrant into the complex quadrant. And now it is trapped there. It is too complex for the in-the-large refactoring that would be required to make it transition back. This pattern happens over and over again in almost all software.

The incremental effort to maintain starts to eat away and eventually exceed the incremental increase in value. This now negative return causes the codebase itself to eventually lose value, until it is no longer an asset to the business. 

When a new bright young engineer who knows C* arrives, he looks at the legacy codebase and is convinced that he can do better. And the cycle repeats. This is the CRAP cycle (Create, Repair, Abandon, rePlace). ALA is the only method I know that can prevent the CRAP cycle.

=== A short history of ALA

From early on in my career, I experienced the CRAP cycle many times. Each time I wanted to find a way to not fall into it. I would research and use all the architectural styles and principles I could find. I would come across things like 'loose coupling', and I remember asking myself, yes but how does one accomplish that?, and still fail.

I started searching for a pre-worked, generally applicable, 'template architecture' that would tell me what the organisation of the code should look like for any program. I searched for such a thing many times and never found one. Some would say that this is because the highest level structure depends on project specific requirements.

Forty years worth of mistakes later, I finally have that template meta structure that all programs should have. The turning point was when I noticed two (accidental) successes in parts of two projects. These successes were only noticed years later, 15 years in one case and 5 years in the other. They had each undergone considerable maintenance during that time. But their simplicity had never degraded and their maintenance had always been straightforward. It was like being at a rubbish dump and noticing two pieces of metal that had never rusted. "That's weird", you think to yourself. "What is going on here?"

One of them had the same functionality as another piece of software that I had written years earlier. That software was the worst I had ever written. It was truly a big ball of mud, and maintenance had become completely impossible, causing the whole product to be abandoned. So it wasn't what the software did that made the difference between good and bad. It was how it was done.

Analysing the common properties of those two code bases, gave clues that eventually resulted in a theoretical understanding of how to deal with complex systems. This meta-structure is what I now call Abstraction Layered Architecture.

Subsequently, I ran some experiments to see if the maintainability and non-complexity could be predictably reproduced. These experiments, which have worked spectacularly well so far, are discussed as a project at the end of every chapter.


=== Simplify the overwhelming software architecture styles, patterns & principles

Currently the problem of structuring software code to meet quality attributes involves mastering an overwhelming number of software engineering topics. Here are just a few examples:  

* Understandability, Readability, Maintainability, Modifiability, Testability, Extensibility, Dependability, Performance, Availability, Scalability, Portability, Security, Usability, Fault-tolerance
* Views, Styles, Patterns, Tactics, Models, UML, ADL's, ADD, SAAM, ATAM, 4+1, Decomposition
* CBD/CBSE, C&C, Pipes & Filters, n-tier, Client/Server, Plug-in, Microservices, Monolithic, Contracts, Message Bus
* Modules, Components, Layers, Classes, Objects, Abstraction, Granularity 
* Information hiding, Separation of Concerns, Loose Coupling & High Cohesion 
* Semantic coupling, Syntax coupling, Temporal coupling, existence coupling, Dependencies, Interactions, Collaboration
* Interfaces, Polymorphism, Encapsulation, Contracts, Interface Intent
* Execution models, Event-Driven, Multithreaded, Mainloop, Data-driven, Concurrency, Reactor pattern, Race condition, Deadlock, Priority Inversion, Reactive 
* Principles: SRP, OCP, LSP, ISP, DIP; MVC, MVP, etc 
* Design Patterns: Layers, Whole-Part, Observer, Strategy, Factory method, Wrapper, Composite, Decorator, Dependency Injection, Callbacks, Chain of Responsibility, etc
* Expressiveness, Fluency, DDD, Coding guidelines, Comments
* Programming Paradigms, Imperative, Declarative, OO, Activity-flow, Work-flow, Data-flow, Function blocks, Synchronous, State machine, GUI layout, Navigation-flow, Data Schema, Functional, Immutable objects, FRP, RX, Monads, AOP, Polyglot-Programming Paradigms
* Messaging: Push, Pull, Synchronous, Asynchronous, Shared memory, Signals & Slots
* Memory management, Heap, Persistence, Databases, ORMs
* Up-front design, Agile, Use cases, User stories, TDD, BDD, MDSD

Mastering all these topics takes time. Even if you can, juggling them all and being able to use the right ones at the right time is extremely taxing on any developer. Add to that the mastering of technologies and tools, keeping to agile sprint deadlines, and commitment to your team and management, it is an almost impossible task. 'Working code' tends to be what the team is judged on, especially by project managers or product owners who have no direct interest in architecture or even the Definition of Done. They don't want to know about the rather negative sounding term, "technical debt".

ALA works by pre-solving most of these software engineering topics into a single 'meta-style'. This meta-style provides a simple set of architectural constraints. 

Being a pre-worked recipe of the aforementioned list of styles and patterns, ALA contains no truly novel ideas. Some ingredients are accentuated in importance more than you might expect (such as abstraction). Some are relatively neutral. Some are purposefully left out. The biggest surprise for me during the conception process of ALA was that some well-established software engineering memes seemed to be in conflict. Eventually I concluded that they were in-fact plain wrong. We will discuss these in detail one at a time in subsequent chapters. But to wet your appetite here is one meme that ALA definitely banishes to furtherest of evil kingdoms: the UML class diagram. Read on to find out why.

Like any good recipe, the ingredients work together to form a whole that is greater than the sum of parts. The resulting code quality is significantly ahead of what the individual memes do by themselves. It continues to surprise me just how effective, and enjoyable, it is. 


=== Example project - Thermometer

In this example project, we will first do it a version using functions, then later we will do a version using classes. The ALA layering rules work the same for both.  

// Applying ALA to functional composition means three things:

// *  Functions (or small groups of them) are abstractions.

// For our purpose here, an abstraction means that our brain can easily learn (by reading the function name or a comment) and retain what a function essentially does. It means that when other programmers are reading your code where a function is called, they don't have to 'follow the indirection' - they can stay with the code unit they are in, and read it like any other line of code. It means a single responsibility. It means it knows nothing about the content of any other abstractions. It means reuseable, and it means stable. The name of the function should not be generic ProcessData, or CalculateResult. It should not be the name of the event that caused it to be executed like PulseComplete. If it calculates a result, it does not know where that result goes. It does not directly call another abstraction at the same level. Instead, it either returns it, or calls a function that was passed to it (like the functional programming guys do).

// * Functions go in a small number of discrete abstraction levels.

// This implies that function call depth is at most three (not counting library functions at a 4th level).

// The first level function contains all knowledge about the application requirements. No implementation here, just describe the requirements in terms of other functions.

// The second level is functions that contain knowledge about reusable operations in the problem domain. It has all the abstractions needed to make it possible for the first level to describe the requirements. No function at this level knows anything about the specific application. An example would be calculate mortgage repayments, or filter data.

// The third level functions are at an even greater level of abstraction, things that would be potentially reusable in many domains. It should have the abstraction level of the types of programming problems being solved. Examples might be communications, persistence, logging. None of these functions can have any knowledge of the specific application, nor the domain. So the persistence functions are not persistence of specific domain objects. With configuration, they would know how to persist anything.  

// A function that doesn't clearly belong at one of these abstraction levels should be split in two. Specific application knowledge generally becomes configuration parameters in the higher layer of a more abstract function in the domain layer.

// For completeness, a 4th level would be your programming language library. Nowhere in these levels is the underlying hardware, nor data. Later we will see where they go, but for now forget all preconceived notions of layers such as UI, business logic and Database. In ALA, these are not layers, just abstractions in the domain layer (that know nothing about each other) that get wired together by the application in the top layer.  

// * The top layer just describes the requirements.

// The top layer describes requirements and that's all it does (like a DSL). It composes functions from the lower layers, and configures them for a specific purpose according to the requirements. 

Functions have an execution model we are already familiar with, making this first example easier to understand. However, keep in mind that, for whole programs, this execution model does not usually make a good programming paradigm. Another rule of ALA is that we accommodate any programming paradigm, and we use the one that best expresses the requirements. 

Nevertheless, functional composition is a passable programming paradigm for a tiny, dedicated embedded program in a micro-controller such as our thermometer. Lets have a look at the type of code I typically see:


==== Bad code

.configurations.h
[source,C]
 #define BATCHSIZE 100
 
.main.c
[source,C]
 #include "configurations.h"
 void main()
 {
    int temperatures[BATCHSIZE];
    ConfigureTemperaturesAdc();
    while (1)
    {
        GetTemperaturesFromAdc(temperatures); // gets a batch of readings at a time
        ProcessTemperatures(tempertures)
    }
 }

.process.c
[source,C]
 void ProcessTemperatures(int adcs[])  
 {
    float temperature;
    for (i = 0; i<BATCHSIZE; i++) {  
        temperature = (adcs[i] + 4) * 8.3; // convert adc to celcius  
        temperature = SmoothTemperature(temperature);  
        ResampleTemperature(temperature);
    }
 }

.Resample.c
[source,C]
 void ResampleTemperature(float temperature)  
 {
    static int counter = 0;
    counter++;
    if (counter==15)
    {
        DisplayTemperature(temperature);
        counter = 0;
    }
 }

.smooth.c
[source,C]
 // smooth the reading before displaying
 float SmoothTemperature(float temperature) 
 {
    static filtered = 0;
    filtered = filtered*9/10 + temperature/10; 
    return filtered;
 }

.adc.c
[source,C]
 #include "configurations.h"
 void ConfigureTemperaturesAdc()
 {
    // configure ADC port 2 to do DMA BATCHSIZE values at a time
 }
 float GetTemperaturesFromAdc(int temperatures[]) 
 {
    for (i = 0; i<BATCHSIZE; i++) {
        temperature[i] = Port(2);  / pseudocode here for the port access
    }
 }

////
<1> function name is specific to this application, destroying it as a potential abstraction
<2> functions are collaborating to implement the 100 samples at a time requirement
<3> details from requirements appearing inside functions (all the constants), destroying potential abstractions
<4> function name doesn't describe an abstraction
<5> function has three responsibilities, process 100 samples at a time, convert to Celsius, and Filtering
<6> function composition in wrong level (only the application knows this needs doing
<7> function composition too deep (function composition should be shallow)
<8> Temporal problems - if adc readings take 1 ms, main loop time is 100 ms
////

At first this code wont look that bad, only because the whole program is so small.

As we are taught to do, different responsibilities of the thermometer implementation have been separated out into smaller pieces that we can understand, although ProcessTempertures appears to have three responsibilities. However, all the pieces are in some way collaborating to make a thermometer. They are all, therefore, coupled in some way, either explicitly or implicitly. So, we have to read all the code to understand the thermometer. Scale this up to 5000 lines of code, and we will have a big mess.


We are going to refactor the program using the ALA strategy:

* every piece of knowledge about 'being a thermometer' will be in one function
* That 'Thermometer' function will be at the top
* That function will do nothing else itself
* how to do things will be put into other functions
* those function will not know anything about thermometer
* those functions will, therefore, be more abstract than a thermometer 

==== Toward better code




.application.c
[source,C]
 #define BATCHSIZE 100
 void main()
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2
        for (i = 0; i<BATCHSIZE; i++) {
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        }
    }
 }



.offsetandscale.c - (domain abstraction)
[source,C]
 // offset and scale a value
 void OffsetAndScale(float data, float offset, float scale) 
 {
    return (data + offset) * scale;
 }



.filter.c - (domain abstraction)
[source,C] 
 // IIR 1st order filter, higher filterstrength is lower cutoff frequency 
 float Filter(float input, int strength)  
 {
    static float filtered = 0.0; 
    filtered = (filtered * (strength-1) + input) / strength
    return filtered;
 }



.resample.c - (domain abstraction)
[source,C] 
 // Returns true every n times it is called
 bool SampleEvery(int n)  
 {
    static counter = 0; 
    counter++;
    if (counter>=n)
    {
       counter = 0;
       rv = true;
    }
    else
    {
       rv =  false;
    }
    return rv;
 }


The code now begins to be arranged into two abstraction layers, the application layer and the domain abstractions layer. The application is now the only function that knows about being a thermometer. (It is still doing some logic work - the 'for loop' and 'if statement', which we we will address soon.) 

All the other functions are now more abstract - GetAdcReadings, OffsetAndScale, SampleEvery, Filter, FloatToString, and Display. Notice how the work thermometer is removed from their names, and none of them contains constants that are specific to a thermometer. 

These abstract functions give you four things:

* Abstract functions are way easier to learn and remember what they do
* Abstract functions give *design-time* encapsulation i.e. zero coupling. *Compile-time* encapsulations can still have a lot of intrinsic coupling (collaboration)
* Abstract function interfaces are way more stable - as stable as the concept of the abstraction itself
* Abstract functions are reusable


Now lets go one more step and create an abstraction to do what that for loop does: This may seem like a retrograde step, but we need to understand this mechanism to move to our final goal of pure composition of abstractions. We want to move the 'for loop' out into its own abstraction, but we don't want to move the code that's inside it. We accomplish this by putting the code inside in a function and passing it to the for loop as a function:  


.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2 
        foreach(adcs, func);
    }
 }
 void func(float adc)
 {  
    temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
    smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
    if (SampleEvery(15)) 
    {
        Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
    );
 }



.foreach.c
[source,C]
 void foreach(int values[], void (*f)(int))
 {
    for (i = 0; i<sizeof(values)/sizeof(*values); i++) {
        (*f)(values[i]);
    }
 }




Now we created a nasty symbolic indirection, func. Symbolic indirections that are not abstractions are bad. So lets go ahead and remove that by using an anonymous function directly as the second parameter of foreach: 




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2 
        foreach(adcs, (adc)=>{
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        });
    }
 }


It uses he lambda syntax '()=>{}', which if you are not already famiar with, is worth getting used to because we will end up using it a lot in ALA programs to get code into the right layers.

The next thing we want to do is get rid of the while loop, get rid of indenting, and stop handling the data that is being passed from one function to another. All those intermediate holding variables, adcs, temperatureCelcius, etc are too much like work, and not just composing our thermometer from abstractions.

The while loop and all the indenting are there only because we have execution flow tied in with our composition flow. 

For this we will use monads in an intermediate step. Don't worry if you don't understand monads, we don't really need this step to understand our final goal. But for those who do know monads, it is interesting to visit this step to see why the functional programming guys invented them. 

////
<1> The application function is readable in isolation (without having to go and read code inside any of the abstractions.
<2> The application describes the thermometer, has all the details of the thermometer, and does nothing else. It delegates all the actual work to the domain abstractions. The application knows nothing of how the abstractions work, only what they do.
<3> None of the abstractions know anything about each other or anything about the application. They don't know they are being used to make a thermometer. They are readable in isolation. It easy to remeber what they do. They are more stable. They are reusable.
<4> Application knows the detail of how many ADC readings to get at a time for performance, but not that the adc uses dma to do that. 
<5> Application knows the conversion factor from ADC to Celsius but not how to do offsetting and scaling.
<6> Application knows the amount of filtering needed to get a smooth thermometer but not how to do filtering.
<7> The emphasis is on 'abstraction' not on 'zero side effects'. Filter and SampleEvery are good abstractions despite having a side effect.

These are more properties of the abstraction layered version:

* The application can easily be rewired to do things like the following examples:
** swap the order of processing of the SampleEvery and the filtering to improve performance
** insert a new data processing operation between say the scaling and the filter
** add a logging output destination
** switch to a different type of ADC or display
** add adapters or wrappers for using 3rd party components

* If the requirements of the thermometer change, no domain abstractions would change - because they don't know anything specific about thermometers.  

* In this 'functional composition', at run-time, data comes up into the application code layer and back down into the domain abstractions layer at each step. That's why the application has some local variables to store the data temporarily at various points during the processing. In most other programming paradigms we will use, the data will not come up to the application layer at run-time. Instead, it will go directly between the instances of the domain abstractions. The application will be concerned with wiring them together, not with handling data.
////

////

==== Composing with lambda functions

In the previous code, the application code was handling the data at run-time. It was using those intermediate variables to store the data it received from each function, and then passing that data to the next function. But it wasn't doing anything with the data. It would be much nicer if the application just did the job of composing the functions, but the data passed directly from one to another at rin-time.

This can be accomplished (in a awkward manner) using anonymous lambda functions. Each function has the next function passed into it:




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()
 {
    ConfigureAdc(Port=2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(Port=2, DmaBatchSize=DMABATCHSIZE, (values) => 
            {
                foreach(values, (value)=> 
                    { 
                        OffsetAndScale(value, offset=4, slope=8.3, (value)=>
                            {
                                Filter(value, 10, (value)=>
                                    {
                                        SampleEvery(value, 15, Display);
                                    }
                                );
                            }
                        );
                    }
                );
            }
        );
    }
 }






It also allows us to take the for loop logic out of the application and use an abstraction instead, "foreach".
It gets us closer from a composition of abstractions point of view, but all that indenting is impractical. And we needed almost empty lambda functions just to contain the other functions. We need a fluent syntax to express the composition. Lets see how it looks using monads.

////

==== Composing with monads

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(port=2, batchSize=100)
    .foreach()
    .OffsetAndScale(offset=4, slope=8.3)
    .Filter(strength=10)
    .SampleEvery(15)
    .NumberToString(format="#.#")
    .Display();
    
    program.Run();
 }
....



Monads have allowed us to separate execution flow from composition flow. The composition flow in this case is the data-flow paradigm. Data will flow from the ADC to the display, so that is directly represented by the composition. How it executes is now separated out, but we will go into how that works shortly. Lets first understand the 'composition' and why this is so important.

Even if you don't understand how the monads work, you can see that syntactically the program is now very nice because all it does is compose instancesofabstarctions, and configure them with constants to be a thermometer. The composition is not declarative it is data-flow, because dataflow suits how to describe the thermometer.

////
It suits where a part of a program has all of these characteristics:

. dedicated CPU 
. process a job as fast as it can in computer time
. doesn't have to wait for anything while it is being done
. nothing else needs doing while this is happening
. the sequence is known ahead of time (proactive not reactive)


An 'algorithm' is an example of something that suits functional composition.

It is common to use multi-threading as the solution to the first four problems in the bullet list. That is a really bad and dangerous way to force what is fundamentally the wrong programming programming paradigm to do the job. Multiple threads are good to solve a small class of performance problems only. The programming paradigms we will use throughout the examples in this book are way better at expressing solutions than multiple concurrent threads exchanong messages. End of rant.

////

We are using the word 'composition' here to mean the things we are joining together in adjacent lines of code. It can also mean joining boxes with lines in a diagram. Think of a composition as analogous to the adjacent notes in a music score, which are always played successively. If the lines of code are statements or function calls, we are composing things for successive synchronous execution by the CPU. 

Here we are composing for successive processing of data, or Data-flow composition. How it actually executes has been abstracted away and is handled separately. 

Also notice that the first statement just builds the program. Then the second statement sets it running. This two stage aspect of monads is common in all the programming paradigms we will use in ALA. It is because the underlying execution flow is not the same as the flow of the program. We first wire it up, and then we tell it to 'execute'.

The while loop code version we had above handled the data itself. Each function returned the data which was then passed into the next function. The monad code doesn't do that. Instead, it creates and wires together objects which will, at run-time, send the data directly from one to another. This does not mean that the abstractions themselves know anything about each other - they are still zero coupled. 

Lastly two paragraphs about how monads actually execute - the execution model. Don't worry if this doesn't make sense. 

Each function in the program statement (the function after each dot) executes once when the program starts. They are not executed when the program is running. Each of these functions first instantiates an object (using new), and secondly wires that object to the previous object. 

The functions wire the objects together using a common abstract interface. Common interfaces used for this type of programming paradigm are like IEnumerable or IObservable. These interfaces support iteration of data, what we call a stream. If using the IEnumerable interface, there is a simple method in the interface that pulls data from the previous object. If using the IObseravble interface, there is a simple method in the interface that pushes data to the next object. 



==== Composing with objects


////
The most common programming paradigm we will likely want to use is Data-flow. When we compose domain abstractions together using this paradigm, we mean that at run-time data will pass between adjacently wired instances. There may be waits, thread swaps, or IO along the way. It may take days for the data to flow through. But the flow is directly expressed as adjacent lines of code. A Data-flow implementation used in functional programming is monads. We wont learn further about monads here (many have attempted to explain monads and failed), except to say that this is what the Thermometer example might look like using them. 
////

Here is the same program as above, but where we are using new ourselves to create the instances of abstractions, and explicitly wiring them together ourselves.  

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(port=2,batchSize=100)
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(strength=10))
        .wireIn(new SampleEvery(15))
        .WireIn(new NumberToString(format="#.#")
        .wireIn(new Display());
       
    program.Run();
 }
....

It's slightly longer than the monad version. You can see that we are using plain old objects. But we will have a big advantage by doing it this way soon. 

The wireIn method is doing dependency injection. 

The WireIn method returns the new object, so it is possible to string WireIns together. This is called fluent syntax. 

==== Composing using multiple programming paradigms:


Monads allowed us to compose using the data-flow programming paradigm. But what if we want to compose the UI? What if we want to compose the flow of navigation around an application? What if we want to compose transitions in a statemachine? ALA prescribes that we be able to do all this in the one application - whatever paradigms are the  best way to express the requirements. 

Some instances of abstraction will need to take part in multiple paradigms, such as both UI and dataflow. When we boil down the description of our application to pure composition, our composition will often be a network. And when you have a network, your composition is best described by a diagram. 

To illustrate this let's add some UI to our thermometer:

image::ThermometerDiagram.png[ThermometerDiagram.png,500, title="Thermometer application complete with UI"]


The diagram has a UI composition as well. Once we have this diagram, it is easy to conceive how we might add features. For example, we could add a button into the UI, and wire it a switcher abstraction that changes between Celcius and faranheit.

For UI part of the composition, the lines obviously don't mean data-flow - they mean 'display inside'. So now different lines in our diagram have different meanings. Here is how that diagram is represented as text. 

.application.c
[source,C]
....
 void main()
 {
    FloatField temperature;
 
    program = new ADC()
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(10))
        .wireIn(new SampleEvery(100))
        .WireIn(new NumberToString()
        .wireIn(temperature = new FloatField());
    
    mainwindow = new Window()
       .wireTo(new Label("Temperture:"))
       .wireTo(temperature);
    
    mainwindow.Run();
 }
....

There are two programming paradigms here - the meaning of the wiring is data-flow in some parts, and UI layout in other parts. This is all done in the one cohesive piece of code that represents the thermometer application, and has all details which could be associated with the concept of a thermometer.

The example projects in later chapter will use a range of different programming paradigms and consequently 'composition' will mean different things. Sometimes we will use custom programming paradigms - whatever allows us to describe those requirements in the best way.


